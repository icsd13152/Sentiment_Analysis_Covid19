{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icsd13152/Sentiment_Analysis_Covid19/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYWafIIAZxKE",
        "outputId": "56ace3e5-70be-4c10-9285-bd437518fd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn import feature_extraction, model_selection\n",
        "# !pip install transformers\n",
        "from transformers import BertTokenizer,BertModel, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "# !pip install --upgrade tensorflow_hub\n",
        "import tensorflow_hub as hub\n",
        "# !pip install tensorflow-text\n",
        "import nltk\n",
        "#import tensorflow_text as text\n",
        "from nltk.corpus import  wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ltWyfU9rPr",
        "outputId": "d60171ba-04d8-4332-a3b2-ca61d853c8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pulWIJl7aibI",
        "outputId": "64c2006f-a463-4098-f720-31b301c9df4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   UserName  ScreenName   Location     TweetAt  \\\n",
            "0      3799       48751     London  16-03-2020   \n",
            "1      3800       48752         UK  16-03-2020   \n",
            "2      3801       48753  Vagabonds  16-03-2020   \n",
            "3      3802       48754        NaN  16-03-2020   \n",
            "4      3803       48755        NaN  16-03-2020   \n",
            "\n",
            "                                       OriginalTweet           Sentiment  \n",
            "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
            "1  advice Talk to your neighbours family to excha...            Positive  \n",
            "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
            "3  My food stock is not the only one which is emp...            Positive  \n",
            "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(r\"/content/drive/My Drive/NLP/Project/Corona_NLP_train.csv\",encoding='latin-1')\n",
        "print(data.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "w44PU-MucYLS",
        "outputId": "ebb4b5ed-bdc7-40bf-e0ef-ca5f94f48f3f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "data[\"Sentiment\"] = data[\"Sentiment\"].replace('Extremely Negative', 'Negative', regex=True)\n",
        "\n",
        "data[\"Sentiment\"] = data[\"Sentiment\"].replace('Extremely Positive', 'Positive', regex=True)\n",
        "\n",
        "#transform Sentiment to number\n",
        "#negative=0\n",
        "#postive=1\n",
        "#neutral=2\n",
        "data[\"Sentiment\"]=data[\"Sentiment\"].replace('Negative', 2, regex=True)\n",
        "data[\"Sentiment\"]=data[\"Sentiment\"].replace('Positive', 1, regex=True)\n",
        "data[\"Sentiment\"]=data[\"Sentiment\"].replace('Neutral', 0, regex=True)\n",
        "\n",
        "\n",
        "plt.hist(data[\"Sentiment\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FG_TcIQclht"
      },
      "outputs": [],
      "source": [
        "#short words/apostrophe lookup\n",
        "contraction_dict1 = {\"Â\":\"\",\"’\":\"'\",\"Ã\":\"\"}\n",
        "contraction_dict2 = {\"Â\":\"\",\"’\":\"'\",\"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\"don't\": \"do not\",\"Don't\":\"Do not\",\n",
        "                     \"I'll\":\"I will\",\"Didn't\":\"Did not\",\"hasn't\":\"has not\",\"NYC\":\"New York City\",\"16MAR20\":\"\",\n",
        "                     \"I'd\":\"I would\",\"I've\":\"I have\",\"you're\":\"you are\",\"I'm\":\"I am\",\"it's\":\"it is\",\n",
        "                     \"#NZ\":\"\",\"they'll\":\"they will\",\"they're\":\"they are\",\"can't\":\"can not\",\"Y'all\":\"You All\",\n",
        "                     \"I m\":\"I am\",\"can't\":\"can not\",\"don t\":\"do not\",\"I ve\":\"I have\",\"we're\":\"we are\",\n",
        "                     \"LOL\":\"lough out loud\",\"lol\":\"lough out loud\",\"FYI\":\"For your information\",\"OFC\":\"Of Course\",\"ofc\":\"Of Course\",\n",
        "                     \"#coronavirÃ¼s\":\"coronavirus\",\"pls\":\"please\",\"#stayhomesavelives\":\"stay home save lives\",\n",
        "                     \"hasn't\": 'has not',\"haven't\": 'have not',\"he'd\": 'he had / he would',\"he'd've\": 'he would have',\n",
        "                     \"he'll\": 'he shall / he will',\"he'll've\": 'he shall have / he will have',\n",
        "                     \"he's\": 'he has / he is',\"how'd\": 'how did', \"how'd'y\": 'how do you', \"how'll\": 'how will',\n",
        "                     \"how's\": 'how has / how is', \"i'd\": 'I had / I would',\"i'd've\": 'I would have',  \"i'll\": 'I shall / I will',\n",
        "                     \"i'll've\": 'I shall have / I will have',\"i'm\": 'I am', \"i've\": 'I have', \"isn't\": 'is not', \"it'd\": 'it had / it would',\n",
        "                     \"it'd've\": 'it would have', \"it'll\": 'it shall / it will',\n",
        "                     \"it'll've\": 'it shall have / it will have',\"it's\": 'it has / it is', \"let's\": 'let us',\n",
        "                     \"ma'am\": 'madam', \"mayn't\": 'may not',\n",
        "                     \"might've\": 'might have', \"mightn't\": 'might not',\n",
        "                     \"mightn't've\": 'might not have', \"must've\": 'must have',\"mustn't\": 'must not',\n",
        "                     \"mustn't've\": 'must not have', \"needn't\": 'need not',\n",
        "                     \"needn't've\": 'need not have', \"o'clock\": 'of the clock',\n",
        "                     \"oughtn't\": 'ought not', \"oughtn't've\": 'ought not have',\n",
        "                     \"shan't\": 'shall not', \"sha'n't\": 'shall not',\n",
        "                     \"shan't've\": 'shall not have', \"she'd\": 'she had / she would',\n",
        "                     \"she'd've\": 'she would have', \"she'll\": 'she shall / she will',\n",
        "                     \"she'll've\": 'she shall have / she will have',\n",
        "                     \"she's\": 'she has / she is', \"should've\": 'should have',\n",
        "                     \"shouldn't\": 'should not',\"shouldn't've\": 'should not have',\n",
        "                     \"so've\": 'so have', \"so's\": 'so as / so is',\n",
        "                     \"that'd\": 'that would / that had',\"that'd've\": 'that would have',\n",
        "                     \"that's\": 'that has / that is', \"there'd\": 'there had / there would',\n",
        "                     \"there'd've\": 'there would have', \"there's\": 'there has / there is',\n",
        "                     \"they'd\": 'they had / they would',  \"they'd've\": 'they would have',\n",
        "                     \"they'll\": 'they shall / they will', \"they'll've\": 'they shall have / they will have',\n",
        "                     \"they're\": 'they are',  \"they've\": 'they have',\n",
        "                     \"to've\": 'to have', \"wasn't\": 'was not',\n",
        "                     \"we'd\": 'we had / we would',  \"we'd've\": 'we would have',\n",
        "                     \"we'll\": 'we will', \"we'll've\": 'we will have',\n",
        "                     \"we're\": 'we are', \"we've\": 'we have',\n",
        "                     \"weren't\": 'were not', \"what'll\": 'what shall / what will',\n",
        "                     \"what'll've\": 'what shall have / what will have',\n",
        "                     \"what're\": 'what are', \"what's\": 'what has / what is',\n",
        "                     \"what've\": 'what have',\"when's\": 'when has / when is',\n",
        "                     \"when've\": 'when have', \"where'd\": 'where did',\n",
        "                     \"where's\": 'where has / where is',\n",
        "                     \"where've\": 'where have', \"who'll\": 'who shall / who will',\n",
        "                     \"who'll've\": 'who shall have / who will have',\n",
        "                     \"who's\": 'who has / who is', \"who've\": 'who have',\n",
        "                     \"why's\": 'why has / why is', \"why've\": 'why have',\n",
        "                     \"will've\": 'will have', \"won't\": 'will not',\"won't've\": 'will not have',\n",
        "                     \"would've\": 'would have',\"wouldn't\": 'would not',\"wouldn't've\": 'would not have',\n",
        "                     \"y'all\": 'you all', \"y'all'd\": 'you all would',\n",
        "                     \"y'all'd've\": 'you all would have', \"y'all're\": 'you all are',\n",
        "                     \"y'all've\": 'you all have', \"you'd\": 'you had / you would',\n",
        "                     \"you'd've\": 'you would have',\"&amp\":\"and\",\"btc\":\"bitcoin\",\"irs\":\"\",\"spx\":\"\",\"📍\":\"\",\"✅\":\"\",\"ive\":\"i have\",\n",
        "                     \"coo\":\"\",\"lka\":\"\", \"nyc\":\"\",\"ktla\":\"\",\"ppc\":\"pay per click\",\"wjhl\":\"\",\"plzzz\":\"please\",\"orlf\":\"\",\"etc\":\"\",\n",
        "                     \"ktvu\":\"\",\"amidst\":\"\",\"biz\":\"business\",\"djt\":\"\",\"ict\":\"information communications technology\",\"yep\":\"yes\",\n",
        "                     \"yeap\":\"yes\",\"letâs\":\"let\",\"didn't\":\"did not\",\"regionâs\":\"regions\",\"covid-19\":\"covid\",\"iâm\":\"I am\",\"coronavir¼\":\"coronavirus\",\n",
        "                     \"weÃ¢ve\":\"we have\",\"Ã¢today\":\"today\",\"deliveriesÃ¢as\":\"deliveries\",\"canÃ¢t\":\"can not\",\"itÃ¢s\":\"it is\",\"thereÃ¢s\":\"thereÃ¢s\",\n",
        "                     \"donÃ¢t\":\"do not\",\"iÃ¢ve\":\"i have\",\"consumerÃ¢s\":\"consumer\",\"didnÃ¢t\":\"did not\",\"billÃ¢\":\"bill\",\"thatÃ¢s\":\"that is\"\n",
        "                     }\n",
        "\n",
        "emoticons={':)': 'happy', ':‑)': 'happy',\n",
        " ':-]': 'happy', ':-3': 'happy',\n",
        " ':->': 'happy', '8-)': 'happy',\n",
        " ':-}': 'happy', ':o)': 'happy',\n",
        " ':c)': 'happy', ':^)': 'happy',\n",
        " '=]': 'happy', '=)': 'happy',\n",
        " '<3': 'happy', ':-(': 'sad',\n",
        " ':(': 'sad', ':c': 'sad',\n",
        " ':<': 'sad', ':[': 'sad',\n",
        " '>:[': 'sad', ':{': 'sad',\n",
        " '>:(': 'sad', ':-c': 'sad',\n",
        " ':-< ': 'sad', ':-[': 'sad',\n",
        " ':-||': 'sad',\n",
        "  '😢':'sad'         }\n",
        "\n",
        "myOwnStopWords={'price':\"\",\n",
        "               'store':\"\",\n",
        "               'supermarket':\"\",\n",
        "               'food':\"\",\n",
        "               'grocery':\"\",\n",
        "               'people':\"\",\n",
        "               'go':\"\",\n",
        "               'consumer':\"\",\n",
        "                'usdjpy':\"\", 'gbpusd':\"\", 'usdcnh':\"\", 'xauusd':\"\", 'wti':\"\", 'spx':\"\",'iave':\"\",\"aiave\":\"\",\"itâs\":\"it is\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oeCCRQKcoGR"
      },
      "outputs": [],
      "source": [
        "def lookup_dict(text, dictionary):\n",
        "    if isinstance(text, float) == False and text is not None:\n",
        "        for word in text.split():\n",
        "            if word.lower() in dictionary:\n",
        "                if word.lower() in text.split():\n",
        "                    text = text.replace(word, dictionary[word.lower()])\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JnWGtkycuEE",
        "outputId": "7ca2b144-d8c1-4843-8891-86eefe56fedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    UserName  ScreenName                   Location     TweetAt  \\\n",
            "0       3800       48752                         UK  16-03-2020   \n",
            "1       3801       48753                  Vagabonds  16-03-2020   \n",
            "2       3802       48754                        NaN  16-03-2020   \n",
            "3       3803       48755                        NaN  16-03-2020   \n",
            "4       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
            "5       3805       48757       35.926541,-78.753267  16-03-2020   \n",
            "6       3806       48758                    Austria  16-03-2020   \n",
            "7       3807       48759            Atlanta, GA USA  16-03-2020   \n",
            "8       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
            "9       3809       48761             Makati, Manila  16-03-2020   \n",
            "10      3810       48762  Pitt Meadows, BC, Canada   16-03-2020   \n",
            "11      3811       48763                 Horningsea  16-03-2020   \n",
            "12      3812       48764                Chicago, IL  16-03-2020   \n",
            "13      3813       48765                        NaN  16-03-2020   \n",
            "14      3814       48766             Houston, Texas  16-03-2020   \n",
            "15      3816       48768            Ontario, Canada  16-03-2020   \n",
            "16      3817       48769              North America  16-03-2020   \n",
            "17      3818       48770                 Denver, CO  16-03-2020   \n",
            "18      3819       48771       southampton soxx xxx  16-03-2020   \n",
            "19      3820       48772                     Global  16-03-2020   \n",
            "\n",
            "                                        OriginalTweet Sentiment data_type  \n",
            "0   advice talk neighbour family exchange phone nu...         1     train  \n",
            "1   coronavirus australia woolworth give elderly d...         1       val  \n",
            "2   stock one emptyplease panic enough everyone ta...         1     train  \n",
            "3   ready covid outbreaknot paranoid stock littera...         2     train  \n",
            "4   news region first confirm covid case come sull...         1       val  \n",
            "5   cashier share insight covid prove credibility ...         1       val  \n",
            "6   today buy toilet paper rebeltoiletpapercrisis ...         0     train  \n",
            "7   due covid retail classroom atlanta open walkin...         1     train  \n",
            "8   corona prevention stop buy thing cash use onli...         2     train  \n",
            "9   month crowd restaurant however reduce hour clo...         0     train  \n",
            "10  due covid situation increase demand product wa...         1     train  \n",
            "11  horningsea care community let look less capabl...         1     train  \n",
            "12  need stock shall amazon deliver whatever need ...         1     train  \n",
            "13  adara release covid resource center travel bra...         1       val  \n",
            "14  line unpredictable eat safe alternative find w...         1     train  \n",
            "15  mar russia surveillance watchdog report case h...         0     train  \n",
            "16  amazon glitch stymy whole fresh deliveriesâas ...         1     train  \n",
            "17  struggle please consider donate bank nonprofit...         1       val  \n",
            "18  nation inficted covid world must play fair chi...         2     train  \n",
            "19  covid coronavirus pandemic impact shop behavio...         0     train  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data[\"OriginalTweet\"] = data[\"OriginalTweet\"].apply(lambda x: lookup_dict(x,emoticons))\n",
        "\n",
        "data['OriginalTweet']=data['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict1))\n",
        "data['OriginalTweet']=data['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict2))\n",
        "data['OriginalTweet']  = data['OriginalTweet'].str.lower()\n",
        "data['OriginalTweet']=data['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict2))\n",
        "data['OriginalTweet'] = data['OriginalTweet'].apply(lambda x: ''.join(''.join(s)[:2] for _, s in itertools.groupby(x)))\n",
        "\n",
        "\n",
        "#to lower case\n",
        "data['OriginalTweet']  = data['OriginalTweet'].str.lower()\n",
        "#remove numbers\n",
        "data[\"OriginalTweet\"] = data[\"OriginalTweet\"].replace('[0-9]', '', regex=True)\n",
        "\n",
        "#remove mentions\n",
        "data[\"OriginalTweet\"] = data[\"OriginalTweet\"].replace('@([a-zA-Z0-9_]{1,50})', '', regex=True)\n",
        "\n",
        "#remove hashtags\n",
        "data[\"OriginalTweet\"] = data[\"OriginalTweet\"].replace('#', '', regex=True)\n",
        "\n",
        "#remove urls\n",
        "data[\"OriginalTweet\"] = data[\"OriginalTweet\"].replace('http\\S+', '', regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"_\", \"\", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\",\", \" \", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"   \", \" \", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"  \", \" \", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"\\?\", \" \", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"pmmodi\", \"\", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"amp\", \"and\", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"btc\", \"bitcoin\", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"hand\", \"\", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].fillna(0)\n",
        "data['OriginalTweet']=data['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict2))\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"\\r\\r\\n\", \"\", regex=True)\n",
        "# # #remove all remaining bad chars\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace('[^\\\\w\\\\s]', '', regex=True)\n",
        "data['OriginalTweet']  = data['OriginalTweet'].str.strip()\n",
        "data['OriginalTweet'].fillna(value='', inplace=True)\n",
        "#Tokenize the tweets\n",
        "tokenized_tweets = data[\"OriginalTweet\"].apply(lambda x: x.split())\n",
        "\n",
        "#remove stopword(for example and,to at etc)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokenized_tweets = tokenized_tweets.apply(lambda x: [word for word in x if not word in stop_words])\n",
        "\n",
        "#Stemming the words\n",
        "# stemmer = PorterStemmer()#language='english'\n",
        "# tokenized_tweets= tokenized_tweets.apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "\n",
        "def get_pos( word ):\n",
        "    w_synsets = wordnet.synsets(word)\n",
        "\n",
        "    pos_counts = nltk.Counter()\n",
        "    pos_counts[\"n\"] = len(  [ item for item in w_synsets if item.pos()==\"n\"]  )\n",
        "    pos_counts[\"v\"] = len(  [ item for item in w_synsets if item.pos()==\"v\"]  )\n",
        "    pos_counts[\"a\"] = len(  [ item for item in w_synsets if item.pos()==\"a\"]  )\n",
        "    pos_counts[\"r\"] = len(  [ item for item in w_synsets if item.pos()==\"r\"]  )\n",
        "\n",
        "    most_common_pos_list = pos_counts.most_common(3)\n",
        "    return most_common_pos_list[0][0]\n",
        "#get the lemma\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "tokenized_tweets = tokenized_tweets.apply(lambda x: [lemmatizer.lemmatize(i,get_pos( i )) for i in x])\n",
        "\n",
        "# tokenized_tweets = tokenized_tweets.apply(lambda x: [word for word in x if len(word)>2 or word=='go'])\n",
        "\n",
        "\n",
        "#Joining the tokenized tweets\n",
        "for i in range(len(tokenized_tweets)):\n",
        "    tokenized_tweets[i] = ' '.join(tokenized_tweets[i])\n",
        "data[\"OriginalTweet\"] = tokenized_tweets\n",
        "\n",
        "\n",
        "data['OriginalTweet']=data['OriginalTweet'].apply(lambda x:lookup_dict(x,myOwnStopWords))\n",
        "all_words = []\n",
        "for line in list(data['OriginalTweet']):\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        all_words.append(word.lower())\n",
        "\n",
        "\n",
        "\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\"  \", \" \", regex=True)\n",
        "data[\"OriginalTweet\"]=data[\"OriginalTweet\"].replace(\" +\", \" \", regex=True)\n",
        "data['OriginalTweet']  = data['OriginalTweet'].str.strip()\n",
        "\n",
        "data.drop_duplicates(subset =\"OriginalTweet\",\n",
        "                         keep = 'last', inplace = True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "print(data.head(20))\n",
        "data.to_csv('raw_data2.csv', index=False)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data['OriginalTweet'],data['Sentiment'], test_size=0.25,shuffle=True, stratify=data['Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1rdNTE0dTnG"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(data.index.values,data['Sentiment'], test_size=0.25,stratify=data['Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGhoyCYBelPK"
      },
      "outputs": [],
      "source": [
        "data['data_type'] = ['not_set'] * data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQExJkkmesdT",
        "outputId": "0a444866-082c-4027-cee1-1c84295b8ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       UserName  ScreenName                      Location     TweetAt  \\\n",
            "0          3800       48752                            UK  16-03-2020   \n",
            "1          3801       48753                     Vagabonds  16-03-2020   \n",
            "2          3802       48754                           NaN  16-03-2020   \n",
            "3          3803       48755                           NaN  16-03-2020   \n",
            "4          3804       48756     ÃT: 36.319708,-82.363649  16-03-2020   \n",
            "...         ...         ...                           ...         ...   \n",
            "40858     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
            "40859     44952       89904                           NaN  14-04-2020   \n",
            "40860     44953       89905                           NaN  14-04-2020   \n",
            "40861     44954       89906                           NaN  14-04-2020   \n",
            "40862     44955       89907  i love you so much || he/him  14-04-2020   \n",
            "\n",
            "                                           OriginalTweet Sentiment data_type  \n",
            "0      advice talk neighbour family exchange phone nu...         1   not_set  \n",
            "1      coronavirus australia woolworth give elderly d...         1   not_set  \n",
            "2      stock one emptyplease panic enough everyone ta...         1   not_set  \n",
            "3      ready covid outbreaknot paranoid stock littera...         2   not_set  \n",
            "4      news region first confirm covid case come sull...         1   not_set  \n",
            "...                                                  ...       ...       ...  \n",
            "40858  airline pilot offer stock shelf nz lockdown covid         0   not_set  \n",
            "40859  response complaint provide cite covid relate d...         2   not_set  \n",
            "40860  know itâs get tough ration toilet paper corona...         1   not_set  \n",
            "40861  wrong smell sanitizer start turn coronavirus c...         0   not_set  \n",
            "40862  well newused rift amazon rn although normal ma...         2   not_set  \n",
            "\n",
            "[40863 rows x 7 columns]\n",
            "       UserName  ScreenName                      Location     TweetAt  \\\n",
            "0          3800       48752                            UK  16-03-2020   \n",
            "1          3801       48753                     Vagabonds  16-03-2020   \n",
            "2          3802       48754                           NaN  16-03-2020   \n",
            "3          3803       48755                           NaN  16-03-2020   \n",
            "4          3804       48756     ÃT: 36.319708,-82.363649  16-03-2020   \n",
            "...         ...         ...                           ...         ...   \n",
            "40858     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
            "40859     44952       89904                           NaN  14-04-2020   \n",
            "40860     44953       89905                           NaN  14-04-2020   \n",
            "40861     44954       89906                           NaN  14-04-2020   \n",
            "40862     44955       89907  i love you so much || he/him  14-04-2020   \n",
            "\n",
            "                                           OriginalTweet Sentiment data_type  \n",
            "0      advice talk neighbour family exchange phone nu...         1       val  \n",
            "1      coronavirus australia woolworth give elderly d...         1       val  \n",
            "2      stock one emptyplease panic enough everyone ta...         1     train  \n",
            "3      ready covid outbreaknot paranoid stock littera...         2     train  \n",
            "4      news region first confirm covid case come sull...         1     train  \n",
            "...                                                  ...       ...       ...  \n",
            "40858  airline pilot offer stock shelf nz lockdown covid         0     train  \n",
            "40859  response complaint provide cite covid relate d...         2     train  \n",
            "40860  know itâs get tough ration toilet paper corona...         1       val  \n",
            "40861  wrong smell sanitizer start turn coronavirus c...         0     train  \n",
            "40862  well newused rift amazon rn although normal ma...         2     train  \n",
            "\n",
            "[40863 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "print(data)\n",
        "data.loc[X_train, 'data_type'] = 'train'\n",
        "data.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#groupby count\n",
        "data.groupby(['Sentiment','data_type']).count()\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSr-hHMqgOeo"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                         do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUUzBudFgkvI",
        "outputId": "1b24419a-1826-4192-f642-baeb0f25d439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "#encode train set\n",
        "encoded_data_train = tokenizer.batch_encode_plus(data[data.data_type == 'train'].OriginalTweet.values,\n",
        "                                                # add_special_tokes = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 64,\n",
        "                                                return_tensors = 'pt')\n",
        "                                                \n",
        "#encode validation set\n",
        "encoded_data_val = tokenizer.batch_encode_plus(data[data.data_type == 'val'].OriginalTweet.values,\n",
        "                                                # add_special_tokes = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 64,\n",
        "                                                return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8hcYbJcg9BJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdfa2f3-e7a1-46d3-c43e-0a3ad005f94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 1 ... 2 0 2]\n",
            "tensor([1, 2, 1,  ..., 2, 0, 2])\n"
          ]
        }
      ],
      "source": [
        "#train set\n",
        "import torch\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "print(data[data.data_type == 'train'].Sentiment.values)\n",
        "labels_train = torch.tensor(data[data.data_type == 'train'].Sentiment.values.astype(int))\n",
        "\n",
        "#validation set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(data[data.data_type == 'val'].Sentiment.values.astype(int))\n",
        "print(labels_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = 3,\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "a89b3ed0c15c4aa3af82f15902e1eb68",
            "b93941568a9845e1afcb9573e378a886",
            "d9eb02e90852485eaeb1247ede433e63",
            "5f1464887c534609b62210b5f69ce59e",
            "65c3c13e452047c7b865d6857ff101a3",
            "6445feabecef43b2bc9bdf3bb3390869",
            "646f6aeb67f943cc81e1c95cd91b3e99",
            "c6a9a036879d4af787df77af6c9e43aa",
            "795a4b0e9ec044c9af2873cbbb681e65",
            "5f4c02b97d36413d811f4fffc281c196",
            "11fc3b7ea8594688a5b87ebb092a7521"
          ]
        },
        "id": "g87q9aZ8ilz3",
        "outputId": "2330362c-d07d-47dc-eed3-b2733760b193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a89b3ed0c15c4aa3af82f15902e1eb68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#train set\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "#validation set\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ],
      "metadata": {
        "id": "Fa_Q8qwRiokX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#validation set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = 32)"
      ],
      "metadata": {
        "id": "3iR0LoYxiuDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# optimizer = AdamW(model.parameters(),\n",
        "#                  lr = 1e-5,\n",
        "#                  eps = 1e-8) #2e-5 > 5e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 10\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps = len(dataloader_train)*epochs)"
      ],
      "metadata": {
        "id": "kQHK7TiCizt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# def avg_fscore(n_model, data, labels):\n",
        "#     device = next(model.parameters()).device\n",
        "#     with torch.no_grad():\n",
        "#         output = n_model(data.to(device))\n",
        "#     softmax = torch.exp(output)\n",
        "#     #prob = list(softmax.numpy())\n",
        "#     predictions = torch.argmax(softmax, -1)\n",
        "#     return f1_score(labels.cpu().data.numpy(), predictions.cpu().data.numpy(), average='macro')\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    valF1 = list()\n",
        "    predictions, true_vals = [], []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    progress_bar = tqdm(dataloader_val, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "        progress_bar.set_postfix({'validation_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    # valF1.append(avg_fscore(model, **inputs, true_vals))\n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "metadata": {
        "id": "BfCSEpf9i3mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from sklearn.metrics import f1_score\n",
        "# def convert_to_array(seq):\n",
        "#     return np.array(seq)\n",
        "\n",
        "# def f1_score_func(preds, labels):\n",
        "#     preds_flat = np.argmax(preds, axis = 1).flatten().numpy()\n",
        "#     print(preds_flat)\n",
        "#     labels_flat = labels.flatten().numpy()\n",
        "#     print(labels_flat)\n",
        "#     return f1_score(labels_flat, preds, average = 'weighted')\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "class F1Score:\n",
        "    \"\"\"\n",
        "    Class for f1 calculation in Pytorch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, average: str = 'weighted'):\n",
        "        \"\"\"\n",
        "        Init.\n",
        "\n",
        "        Args:\n",
        "            average: averaging method\n",
        "        \"\"\"\n",
        "        self.average = average\n",
        "        if average not in [None, 'micro', 'macro', 'weighted']:\n",
        "            raise ValueError('Wrong value of average parameter')\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_f1_micro(predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate f1 micro.\n",
        "\n",
        "        Args:\n",
        "            predictions: tensor with predictions\n",
        "            labels: tensor with original labels\n",
        "\n",
        "        Returns:\n",
        "            f1 score\n",
        "        \"\"\"\n",
        "        true_positive = torch.eq(labels, predictions).sum().float()\n",
        "        f1_score = torch.div(true_positive, len(labels))\n",
        "        return f1_score\n",
        "\n",
        "    @staticmethod\n",
        "    def calc_f1_count_for_label(predictions: torch.Tensor,\n",
        "                                labels: torch.Tensor, label_id: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Calculate f1 and true count for the label\n",
        "\n",
        "        Args:\n",
        "            predictions: tensor with predictions\n",
        "            labels: tensor with original labels\n",
        "            label_id: id of current label\n",
        "\n",
        "        Returns:\n",
        "            f1 score and true count for label\n",
        "        \"\"\"\n",
        "        # label count\n",
        "        true_count = torch.eq(labels, label_id).sum()\n",
        "\n",
        "        # true positives: labels equal to prediction and to label_id\n",
        "        true_positive = torch.logical_and(torch.eq(labels, predictions),\n",
        "                                          torch.eq(labels, label_id)).sum().float()\n",
        "        # precision for label\n",
        "        precision = torch.div(true_positive, torch.eq(predictions, label_id).sum().float())\n",
        "        # replace nan values with 0\n",
        "        precision = torch.where(torch.isnan(precision),\n",
        "                                torch.zeros_like(precision).type_as(true_positive),\n",
        "                                precision)\n",
        "\n",
        "        # recall for label\n",
        "        recall = torch.div(true_positive, true_count)\n",
        "        # f1\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "        # replace nan values with 0\n",
        "        f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1).type_as(true_positive), f1)\n",
        "        return f1, true_count\n",
        "\n",
        "    def __call__(self, predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Calculate f1 score based on averaging method defined in init.\n",
        "\n",
        "        Args:\n",
        "            predictions: tensor with predictions\n",
        "            labels: tensor with original labels\n",
        "\n",
        "        Returns:\n",
        "            f1 score\n",
        "        \"\"\"\n",
        "\n",
        "        # simpler calculation for micro\n",
        "        if self.average == 'micro':\n",
        "            return self.calc_f1_micro(predictions, labels)\n",
        "\n",
        "        f1_score = 0\n",
        "        for label_id in range(1, 3 + 1):\n",
        "            f1, true_count = self.calc_f1_count_for_label(predictions, labels, label_id)\n",
        "\n",
        "            if self.average == 'weighted':\n",
        "                f1_score += f1 * true_count\n",
        "            elif self.average == 'macro':\n",
        "                f1_score += f1\n",
        "\n",
        "        if self.average == 'weighted':\n",
        "            f1_score = torch.div(f1_score, len(labels))\n",
        "        elif self.average == 'macro':\n",
        "            f1_score = torch.div(f1_score, len(labels.unique()))\n",
        "\n",
        "        return f1_score\n",
        "\n",
        "f1_metric = F1Score('macro')\n",
        "# v = f1_score_func([0 1 2 2 1 1 0], [1 2 1 1 2 0 0])"
      ],
      "metadata": {
        "id": "6e-JtUZwi6ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(data['Sentiment']):\n",
        "    label_dict[possible_label] = index\n",
        "print(label_dict)\n",
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {k: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)} - {len(y_preds[y_preds==label])/len(y_true)} \\n')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfKikgvpi8fF",
        "outputId": "6c5ce261-688a-480c-bd2d-0248a4267c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 40860, 2: 40862, 0: 40861}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "lossTrain = list()\n",
        "lossVal = list()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "epochs = 10\n",
        "minValLoss = 2\n",
        "since_last_best = 0\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "    \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids': batch[0], \n",
        "                  'attention_mask': batch[1], \n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "        \n",
        "    torch.save(model.state_dict(), f'Models/ BERT_ft_epoch{epoch}.model')\n",
        "    \n",
        "    tqdm.write(f'\\n Epoch {epoch}')\n",
        "    \n",
        "    loss_train_ave = loss_train_total / len(dataloader_train)\n",
        "    lossTrain.append(loss_train_ave)\n",
        "    tqdm.write(f'Training loss: {loss_train_ave}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    lossVal.append(val_loss)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    since_last_best += 1\n",
        "    if val_loss <= minValLoss:\n",
        "       minValLoss = val_loss\n",
        "       since_last_best = 0\n",
        "       torch.save(model.state_dict(), f'Models/ BERT_ft_epoch{epoch}.model') \n",
        "    if since_last_best > 2:\n",
        "        break\n",
        "    # val_f1 = f1_score_func(predictions, true_vals)\n",
        "    # val_f1 = f1_metric(predictions, true_vals)\n",
        "    \n",
        "    # tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MwSrJ15ui-nP",
        "outputId": "d44e5c65-add0-4170-f208-e682323ae477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/958 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/958 [00:00<?, ?it/s, training_loss=0.004]\u001b[A\n",
            "Epoch 1:   0%|          | 1/958 [00:00<06:53,  2.31it/s, training_loss=0.004]\u001b[A\n",
            "Epoch 1:   0%|          | 1/958 [00:00<06:53,  2.31it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:   0%|          | 2/958 [00:00<06:09,  2.58it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:   0%|          | 2/958 [00:01<06:09,  2.58it/s, training_loss=0.729]\u001b[A\n",
            "Epoch 1:   0%|          | 3/958 [00:01<05:56,  2.68it/s, training_loss=0.729]\u001b[A\n",
            "Epoch 1:   0%|          | 3/958 [00:01<05:56,  2.68it/s, training_loss=0.488]\u001b[A\n",
            "Epoch 1:   0%|          | 4/958 [00:01<05:51,  2.71it/s, training_loss=0.488]\u001b[A\n",
            "Epoch 1:   0%|          | 4/958 [00:01<05:51,  2.71it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 1:   1%|          | 5/958 [00:01<05:50,  2.72it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 1:   1%|          | 5/958 [00:02<05:50,  2.72it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:   1%|          | 6/958 [00:02<05:46,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:   1%|          | 6/958 [00:02<05:46,  2.75it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:   1%|          | 7/958 [00:02<05:45,  2.76it/s, training_loss=0.335]\u001b[A\n",
            "Epoch 1:   1%|          | 7/958 [00:02<05:45,  2.76it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:   1%|          | 8/958 [00:02<05:44,  2.76it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:   1%|          | 8/958 [00:03<05:44,  2.76it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 1:   1%|          | 9/958 [00:03<05:43,  2.76it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 1:   1%|          | 9/958 [00:03<05:43,  2.76it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:   1%|          | 10/958 [00:03<05:42,  2.77it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:   1%|          | 10/958 [00:04<05:42,  2.77it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:   1%|          | 11/958 [00:04<05:41,  2.78it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:   1%|          | 11/958 [00:04<05:41,  2.78it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:   1%|▏         | 12/958 [00:04<05:41,  2.77it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:   1%|▏         | 12/958 [00:04<05:41,  2.77it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:   1%|▏         | 13/958 [00:04<05:40,  2.78it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:   1%|▏         | 13/958 [00:05<05:40,  2.78it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:   1%|▏         | 14/958 [00:05<05:42,  2.75it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:   1%|▏         | 14/958 [00:05<05:42,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:   2%|▏         | 15/958 [00:05<05:41,  2.76it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:   2%|▏         | 15/958 [00:05<05:41,  2.76it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 1:   2%|▏         | 16/958 [00:05<05:41,  2.76it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 1:   2%|▏         | 16/958 [00:06<05:41,  2.76it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:   2%|▏         | 17/958 [00:06<05:41,  2.76it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:   2%|▏         | 17/958 [00:06<05:41,  2.76it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:   2%|▏         | 18/958 [00:06<05:40,  2.76it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:   2%|▏         | 18/958 [00:06<05:40,  2.76it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:   2%|▏         | 19/958 [00:06<05:39,  2.76it/s, training_loss=0.301]\u001b[A\n",
            "Epoch 1:   2%|▏         | 19/958 [00:07<05:39,  2.76it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:   2%|▏         | 20/958 [00:07<05:39,  2.76it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:   2%|▏         | 20/958 [00:07<05:39,  2.76it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:   2%|▏         | 21/958 [00:07<05:40,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:   2%|▏         | 21/958 [00:08<05:40,  2.75it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:   2%|▏         | 22/958 [00:08<05:39,  2.76it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:   2%|▏         | 22/958 [00:08<05:39,  2.76it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:   2%|▏         | 23/958 [00:08<05:40,  2.75it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:   2%|▏         | 23/958 [00:08<05:40,  2.75it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:   3%|▎         | 24/958 [00:08<05:42,  2.73it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:   3%|▎         | 24/958 [00:09<05:42,  2.73it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:   3%|▎         | 25/958 [00:09<05:43,  2.72it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:   3%|▎         | 25/958 [00:09<05:43,  2.72it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:   3%|▎         | 26/958 [00:09<05:38,  2.76it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:   3%|▎         | 26/958 [00:09<05:38,  2.76it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:   3%|▎         | 27/958 [00:09<05:39,  2.74it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:   3%|▎         | 27/958 [00:10<05:39,  2.74it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:   3%|▎         | 28/958 [00:10<05:39,  2.74it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:   3%|▎         | 28/958 [00:10<05:39,  2.74it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:   3%|▎         | 29/958 [00:10<05:40,  2.73it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:   3%|▎         | 29/958 [00:10<05:40,  2.73it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:   3%|▎         | 30/958 [00:10<05:41,  2.72it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:   3%|▎         | 30/958 [00:11<05:41,  2.72it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:   3%|▎         | 31/958 [00:11<05:37,  2.74it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:   3%|▎         | 31/958 [00:11<05:37,  2.74it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:   3%|▎         | 32/958 [00:11<05:38,  2.74it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:   3%|▎         | 32/958 [00:12<05:38,  2.74it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 1:   3%|▎         | 33/958 [00:12<05:40,  2.72it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 1:   3%|▎         | 33/958 [00:12<05:40,  2.72it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:   4%|▎         | 34/958 [00:12<05:41,  2.71it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:   4%|▎         | 34/958 [00:12<05:41,  2.71it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:   4%|▎         | 35/958 [00:12<05:41,  2.70it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:   4%|▎         | 35/958 [00:13<05:41,  2.70it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:   4%|▍         | 36/958 [00:13<05:41,  2.70it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:   4%|▍         | 36/958 [00:13<05:41,  2.70it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:   4%|▍         | 37/958 [00:13<05:41,  2.70it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:   4%|▍         | 37/958 [00:13<05:41,  2.70it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:   4%|▍         | 38/958 [00:13<05:40,  2.70it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:   4%|▍         | 38/958 [00:14<05:40,  2.70it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:   4%|▍         | 39/958 [00:14<05:41,  2.69it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:   4%|▍         | 39/958 [00:14<05:41,  2.69it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 1:   4%|▍         | 40/958 [00:14<05:42,  2.68it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 1:   4%|▍         | 40/958 [00:15<05:42,  2.68it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:   4%|▍         | 41/958 [00:15<05:41,  2.68it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:   4%|▍         | 41/958 [00:15<05:41,  2.68it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:   4%|▍         | 42/958 [00:15<05:41,  2.68it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:   4%|▍         | 42/958 [00:15<05:41,  2.68it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:   4%|▍         | 43/958 [00:15<05:41,  2.68it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:   4%|▍         | 43/958 [00:16<05:41,  2.68it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:   5%|▍         | 44/958 [00:16<05:41,  2.68it/s, training_loss=0.262]\u001b[A\n",
            "Epoch 1:   5%|▍         | 44/958 [00:16<05:41,  2.68it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:   5%|▍         | 45/958 [00:16<05:41,  2.67it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:   5%|▍         | 45/958 [00:16<05:41,  2.67it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:   5%|▍         | 46/958 [00:16<05:40,  2.68it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:   5%|▍         | 46/958 [00:17<05:40,  2.68it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:   5%|▍         | 47/958 [00:17<05:39,  2.68it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:   5%|▍         | 47/958 [00:17<05:39,  2.68it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:   5%|▌         | 48/958 [00:17<05:39,  2.68it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:   5%|▌         | 48/958 [00:18<05:39,  2.68it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:   5%|▌         | 49/958 [00:18<05:39,  2.68it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:   5%|▌         | 49/958 [00:18<05:39,  2.68it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:   5%|▌         | 50/958 [00:18<05:38,  2.69it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:   5%|▌         | 50/958 [00:18<05:38,  2.69it/s, training_loss=0.026]\u001b[A\n",
            "Epoch 1:   5%|▌         | 51/958 [00:18<05:38,  2.68it/s, training_loss=0.026]\u001b[A\n",
            "Epoch 1:   5%|▌         | 51/958 [00:19<05:38,  2.68it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:   5%|▌         | 52/958 [00:19<05:38,  2.68it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:   5%|▌         | 52/958 [00:19<05:38,  2.68it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:   6%|▌         | 53/958 [00:19<05:40,  2.66it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:   6%|▌         | 53/958 [00:19<05:40,  2.66it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:   6%|▌         | 54/958 [00:19<05:39,  2.66it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:   6%|▌         | 54/958 [00:20<05:39,  2.66it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:   6%|▌         | 55/958 [00:20<05:39,  2.66it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:   6%|▌         | 55/958 [00:20<05:39,  2.66it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:   6%|▌         | 56/958 [00:20<05:39,  2.66it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:   6%|▌         | 56/958 [00:21<05:39,  2.66it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:   6%|▌         | 57/958 [00:21<05:38,  2.66it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:   6%|▌         | 57/958 [00:21<05:38,  2.66it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:   6%|▌         | 58/958 [00:21<05:40,  2.64it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:   6%|▌         | 58/958 [00:21<05:40,  2.64it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:   6%|▌         | 59/958 [00:21<05:40,  2.64it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:   6%|▌         | 59/958 [00:22<05:40,  2.64it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:   6%|▋         | 60/958 [00:22<05:41,  2.63it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:   6%|▋         | 60/958 [00:22<05:41,  2.63it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:   6%|▋         | 61/958 [00:22<05:39,  2.64it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:   6%|▋         | 61/958 [00:22<05:39,  2.64it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:   6%|▋         | 62/958 [00:22<05:38,  2.65it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:   6%|▋         | 62/958 [00:23<05:38,  2.65it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:   7%|▋         | 63/958 [00:23<05:40,  2.63it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:   7%|▋         | 63/958 [00:23<05:40,  2.63it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:   7%|▋         | 64/958 [00:23<05:39,  2.64it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:   7%|▋         | 64/958 [00:24<05:39,  2.64it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:   7%|▋         | 65/958 [00:24<05:37,  2.65it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:   7%|▋         | 65/958 [00:24<05:37,  2.65it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:   7%|▋         | 66/958 [00:24<05:38,  2.64it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:   7%|▋         | 66/958 [00:24<05:38,  2.64it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:   7%|▋         | 67/958 [00:24<05:37,  2.64it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:   7%|▋         | 67/958 [00:25<05:37,  2.64it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:   7%|▋         | 68/958 [00:25<05:36,  2.65it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:   7%|▋         | 68/958 [00:25<05:36,  2.65it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:   7%|▋         | 69/958 [00:25<05:38,  2.63it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:   7%|▋         | 69/958 [00:25<05:38,  2.63it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:   7%|▋         | 70/958 [00:25<05:39,  2.61it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:   7%|▋         | 70/958 [00:26<05:39,  2.61it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:   7%|▋         | 71/958 [00:26<05:39,  2.61it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:   7%|▋         | 71/958 [00:26<05:39,  2.61it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:   8%|▊         | 72/958 [00:26<05:38,  2.62it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:   8%|▊         | 72/958 [00:27<05:38,  2.62it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:   8%|▊         | 73/958 [00:27<05:38,  2.62it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:   8%|▊         | 73/958 [00:27<05:38,  2.62it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:   8%|▊         | 74/958 [00:27<05:36,  2.63it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:   8%|▊         | 74/958 [00:27<05:36,  2.63it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:   8%|▊         | 75/958 [00:27<05:35,  2.63it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:   8%|▊         | 75/958 [00:28<05:35,  2.63it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:   8%|▊         | 76/958 [00:28<05:33,  2.64it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:   8%|▊         | 76/958 [00:28<05:33,  2.64it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:   8%|▊         | 77/958 [00:28<05:34,  2.63it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:   8%|▊         | 77/958 [00:29<05:34,  2.63it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:   8%|▊         | 78/958 [00:29<05:34,  2.63it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:   8%|▊         | 78/958 [00:29<05:34,  2.63it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 1:   8%|▊         | 79/958 [00:29<05:34,  2.63it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 1:   8%|▊         | 79/958 [00:29<05:34,  2.63it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:   8%|▊         | 80/958 [00:29<05:33,  2.63it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:   8%|▊         | 80/958 [00:30<05:33,  2.63it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:   8%|▊         | 81/958 [00:30<05:32,  2.64it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:   8%|▊         | 81/958 [00:30<05:32,  2.64it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:   9%|▊         | 82/958 [00:30<05:31,  2.64it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:   9%|▊         | 82/958 [00:30<05:31,  2.64it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:   9%|▊         | 83/958 [00:30<05:30,  2.65it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:   9%|▊         | 83/958 [00:31<05:30,  2.65it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   9%|▉         | 84/958 [00:31<05:27,  2.67it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:   9%|▉         | 84/958 [00:31<05:27,  2.67it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:   9%|▉         | 85/958 [00:31<05:28,  2.66it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:   9%|▉         | 85/958 [00:32<05:28,  2.66it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:   9%|▉         | 86/958 [00:32<05:27,  2.66it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:   9%|▉         | 86/958 [00:32<05:27,  2.66it/s, training_loss=0.020]\u001b[A\n",
            "Epoch 1:   9%|▉         | 87/958 [00:32<05:27,  2.66it/s, training_loss=0.020]\u001b[A\n",
            "Epoch 1:   9%|▉         | 87/958 [00:32<05:27,  2.66it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:   9%|▉         | 88/958 [00:32<05:28,  2.65it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:   9%|▉         | 88/958 [00:33<05:28,  2.65it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:   9%|▉         | 89/958 [00:33<05:26,  2.66it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:   9%|▉         | 89/958 [00:33<05:26,  2.66it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:   9%|▉         | 90/958 [00:33<05:27,  2.65it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:   9%|▉         | 90/958 [00:33<05:27,  2.65it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:   9%|▉         | 91/958 [00:33<05:25,  2.66it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:   9%|▉         | 91/958 [00:34<05:25,  2.66it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  10%|▉         | 92/958 [00:34<05:24,  2.67it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  10%|▉         | 92/958 [00:34<05:24,  2.67it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  10%|▉         | 93/958 [00:34<05:22,  2.68it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  10%|▉         | 93/958 [00:35<05:22,  2.68it/s, training_loss=0.010]\u001b[A\n",
            "Epoch 1:  10%|▉         | 94/958 [00:35<05:22,  2.68it/s, training_loss=0.010]\u001b[A\n",
            "Epoch 1:  10%|▉         | 94/958 [00:35<05:22,  2.68it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  10%|▉         | 95/958 [00:35<05:19,  2.70it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  10%|▉         | 95/958 [00:35<05:19,  2.70it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  10%|█         | 96/958 [00:35<05:21,  2.68it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  10%|█         | 96/958 [00:36<05:21,  2.68it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  10%|█         | 97/958 [00:36<05:20,  2.69it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  10%|█         | 97/958 [00:36<05:20,  2.69it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  10%|█         | 98/958 [00:36<05:19,  2.69it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  10%|█         | 98/958 [00:36<05:19,  2.69it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  10%|█         | 99/958 [00:36<05:20,  2.68it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  10%|█         | 99/958 [00:37<05:20,  2.68it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  10%|█         | 100/958 [00:37<05:18,  2.70it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  10%|█         | 100/958 [00:37<05:18,  2.70it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 1:  11%|█         | 101/958 [00:37<05:19,  2.69it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 1:  11%|█         | 101/958 [00:37<05:19,  2.69it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  11%|█         | 102/958 [00:37<05:18,  2.69it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  11%|█         | 102/958 [00:38<05:18,  2.69it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  11%|█         | 103/958 [00:38<05:16,  2.70it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  11%|█         | 103/958 [00:38<05:16,  2.70it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  11%|█         | 104/958 [00:38<05:16,  2.70it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  11%|█         | 104/958 [00:39<05:16,  2.70it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  11%|█         | 105/958 [00:39<05:17,  2.69it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  11%|█         | 105/958 [00:39<05:17,  2.69it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  11%|█         | 106/958 [00:39<05:15,  2.70it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  11%|█         | 106/958 [00:39<05:15,  2.70it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  11%|█         | 107/958 [00:39<05:14,  2.71it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  11%|█         | 107/958 [00:40<05:14,  2.71it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 108/958 [00:40<05:14,  2.70it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 108/958 [00:40<05:14,  2.70it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 109/958 [00:40<05:14,  2.70it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 109/958 [00:40<05:14,  2.70it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 110/958 [00:40<05:13,  2.70it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 110/958 [00:41<05:13,  2.70it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 111/958 [00:41<05:12,  2.71it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 111/958 [00:41<05:12,  2.71it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 112/958 [00:41<05:13,  2.70it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 112/958 [00:42<05:13,  2.70it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 113/958 [00:42<05:13,  2.70it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 113/958 [00:42<05:13,  2.70it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 114/958 [00:42<05:12,  2.70it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 114/958 [00:42<05:12,  2.70it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 115/958 [00:42<05:10,  2.71it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 115/958 [00:43<05:10,  2.71it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 116/958 [00:43<05:11,  2.70it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 116/958 [00:43<05:11,  2.70it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 117/958 [00:43<05:11,  2.70it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 117/958 [00:43<05:11,  2.70it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 118/958 [00:43<05:09,  2.71it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 118/958 [00:44<05:09,  2.71it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 119/958 [00:44<05:08,  2.72it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 119/958 [00:44<05:08,  2.72it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 120/958 [00:44<05:09,  2.71it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 120/958 [00:45<05:09,  2.71it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 121/958 [00:45<05:07,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 121/958 [00:45<05:07,  2.73it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 122/958 [00:45<05:06,  2.73it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 122/958 [00:45<05:06,  2.73it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 123/958 [00:45<05:06,  2.73it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 123/958 [00:46<05:06,  2.73it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 124/958 [00:46<05:05,  2.73it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 124/958 [00:46<05:05,  2.73it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 125/958 [00:46<05:04,  2.73it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 125/958 [00:46<05:04,  2.73it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 126/958 [00:46<05:05,  2.73it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 126/958 [00:47<05:05,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 127/958 [00:47<05:05,  2.72it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 127/958 [00:47<05:05,  2.72it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 128/958 [00:47<05:03,  2.73it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 128/958 [00:47<05:03,  2.73it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 129/958 [00:47<05:02,  2.74it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 129/958 [00:48<05:02,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 130/958 [00:48<05:03,  2.73it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 130/958 [00:48<05:03,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 131/958 [00:48<05:03,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 131/958 [00:49<05:03,  2.73it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 132/958 [00:49<05:02,  2.74it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 132/958 [00:49<05:02,  2.74it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 133/958 [00:49<05:02,  2.72it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 133/958 [00:49<05:02,  2.72it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 134/958 [00:49<05:02,  2.73it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 134/958 [00:50<05:02,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 135/958 [00:50<05:00,  2.74it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 135/958 [00:50<05:00,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 136/958 [00:50<04:59,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 136/958 [00:50<04:59,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 137/958 [00:50<04:57,  2.76it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 137/958 [00:51<04:57,  2.76it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 138/958 [00:51<04:58,  2.75it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 138/958 [00:51<04:58,  2.75it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 139/958 [00:51<04:57,  2.75it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 139/958 [00:51<04:57,  2.75it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 140/958 [00:51<04:58,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 140/958 [00:52<04:58,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 141/958 [00:52<04:58,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 141/958 [00:52<04:58,  2.74it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 142/958 [00:52<04:57,  2.75it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 142/958 [00:53<04:57,  2.75it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 143/958 [00:53<04:57,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 143/958 [00:53<04:57,  2.74it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 144/958 [00:53<04:56,  2.74it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 144/958 [00:53<04:56,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 145/958 [00:53<04:56,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 145/958 [00:54<04:56,  2.74it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 146/958 [00:54<04:56,  2.74it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 146/958 [00:54<04:56,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 147/958 [00:54<04:56,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 147/958 [00:54<04:56,  2.73it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 148/958 [00:54<04:57,  2.72it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 148/958 [00:55<04:57,  2.72it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 149/958 [00:55<04:54,  2.75it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 149/958 [00:55<04:54,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 150/958 [00:55<04:53,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 150/958 [00:55<04:53,  2.75it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 151/958 [00:55<04:53,  2.75it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 151/958 [00:56<04:53,  2.75it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 152/958 [00:56<04:50,  2.77it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 152/958 [00:56<04:50,  2.77it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 153/958 [00:56<04:52,  2.76it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 153/958 [00:57<04:52,  2.76it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 154/958 [00:57<04:51,  2.76it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 154/958 [00:57<04:51,  2.76it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 155/958 [00:57<04:50,  2.76it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 155/958 [00:57<04:50,  2.76it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 156/958 [00:57<04:49,  2.77it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 156/958 [00:58<04:49,  2.77it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 157/958 [00:58<04:49,  2.77it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 157/958 [00:58<04:49,  2.77it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 158/958 [00:58<04:49,  2.76it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 158/958 [00:58<04:49,  2.76it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 159/958 [00:58<04:49,  2.76it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 159/958 [00:59<04:49,  2.76it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 160/958 [00:59<04:46,  2.79it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 160/958 [00:59<04:46,  2.79it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 161/958 [00:59<04:47,  2.77it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 161/958 [00:59<04:47,  2.77it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 162/958 [00:59<04:45,  2.79it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 162/958 [01:00<04:45,  2.79it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 163/958 [01:00<04:44,  2.79it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 163/958 [01:00<04:44,  2.79it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 164/958 [01:00<04:45,  2.78it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 164/958 [01:00<04:45,  2.78it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 165/958 [01:01<04:44,  2.79it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 165/958 [01:01<04:44,  2.79it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 166/958 [01:01<04:44,  2.78it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 166/958 [01:01<04:44,  2.78it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 167/958 [01:01<04:45,  2.77it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 167/958 [01:02<04:45,  2.77it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 168/958 [01:02<04:44,  2.78it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 168/958 [01:02<04:44,  2.78it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 169/958 [01:02<04:44,  2.77it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 169/958 [01:02<04:44,  2.77it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 170/958 [01:02<04:43,  2.78it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 170/958 [01:03<04:43,  2.78it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 171/958 [01:03<04:43,  2.78it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 171/958 [01:03<04:43,  2.78it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 172/958 [01:03<04:43,  2.77it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 172/958 [01:03<04:43,  2.77it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 173/958 [01:03<04:42,  2.78it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 173/958 [01:04<04:42,  2.78it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 174/958 [01:04<04:41,  2.78it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 174/958 [01:04<04:41,  2.78it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 175/958 [01:04<04:43,  2.77it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 175/958 [01:04<04:43,  2.77it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 176/958 [01:04<04:42,  2.76it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 176/958 [01:05<04:42,  2.76it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 177/958 [01:05<04:41,  2.77it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 177/958 [01:05<04:41,  2.77it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 178/958 [01:05<04:41,  2.77it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 178/958 [01:06<04:41,  2.77it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 179/958 [01:06<04:39,  2.78it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 179/958 [01:06<04:39,  2.78it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 180/958 [01:06<04:40,  2.78it/s, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 180/958 [01:06<04:40,  2.78it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 181/958 [01:06<04:40,  2.77it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 181/958 [01:07<04:40,  2.77it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 182/958 [01:07<04:40,  2.77it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 182/958 [01:07<04:40,  2.77it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 183/958 [01:07<04:38,  2.78it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 183/958 [01:07<04:38,  2.78it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 184/958 [01:07<04:37,  2.79it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 184/958 [01:08<04:37,  2.79it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 185/958 [01:08<04:38,  2.77it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 185/958 [01:08<04:38,  2.77it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 186/958 [01:08<04:37,  2.78it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 186/958 [01:08<04:37,  2.78it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 187/958 [01:08<04:36,  2.79it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 187/958 [01:09<04:36,  2.79it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 188/958 [01:09<04:37,  2.77it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 188/958 [01:09<04:37,  2.77it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 189/958 [01:09<04:37,  2.77it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 189/958 [01:10<04:37,  2.77it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 190/958 [01:10<04:36,  2.78it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 190/958 [01:10<04:36,  2.78it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 191/958 [01:10<04:37,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 191/958 [01:10<04:37,  2.76it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  20%|██        | 192/958 [01:10<04:38,  2.75it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  20%|██        | 192/958 [01:11<04:38,  2.75it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  20%|██        | 193/958 [01:11<04:35,  2.77it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  20%|██        | 193/958 [01:11<04:35,  2.77it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  20%|██        | 194/958 [01:11<04:35,  2.77it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  20%|██        | 194/958 [01:11<04:35,  2.77it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  20%|██        | 195/958 [01:11<04:34,  2.78it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  20%|██        | 195/958 [01:12<04:34,  2.78it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  20%|██        | 196/958 [01:12<04:34,  2.77it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  20%|██        | 196/958 [01:12<04:34,  2.77it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  21%|██        | 197/958 [01:12<04:35,  2.76it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  21%|██        | 197/958 [01:12<04:35,  2.76it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  21%|██        | 198/958 [01:12<04:34,  2.77it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  21%|██        | 198/958 [01:13<04:34,  2.77it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  21%|██        | 199/958 [01:13<04:32,  2.78it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  21%|██        | 199/958 [01:13<04:32,  2.78it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  21%|██        | 200/958 [01:13<04:33,  2.77it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  21%|██        | 200/958 [01:13<04:33,  2.77it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  21%|██        | 201/958 [01:13<04:31,  2.79it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  21%|██        | 201/958 [01:14<04:31,  2.79it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  21%|██        | 202/958 [01:14<04:32,  2.78it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  21%|██        | 202/958 [01:14<04:32,  2.78it/s, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  21%|██        | 203/958 [01:14<04:32,  2.77it/s, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  21%|██        | 203/958 [01:15<04:32,  2.77it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 204/958 [01:15<04:31,  2.78it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 204/958 [01:15<04:31,  2.78it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 205/958 [01:15<04:31,  2.77it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 205/958 [01:15<04:31,  2.77it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 206/958 [01:15<04:30,  2.78it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 206/958 [01:16<04:30,  2.78it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 207/958 [01:16<04:29,  2.78it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 207/958 [01:16<04:29,  2.78it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 208/958 [01:16<04:30,  2.77it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 208/958 [01:16<04:30,  2.77it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 209/958 [01:16<04:30,  2.77it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 209/958 [01:17<04:30,  2.77it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 210/958 [01:17<04:29,  2.78it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 210/958 [01:17<04:29,  2.78it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 211/958 [01:17<04:29,  2.77it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 211/958 [01:17<04:29,  2.77it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 212/958 [01:17<04:30,  2.76it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 212/958 [01:18<04:30,  2.76it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 213/958 [01:18<04:29,  2.76it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 213/958 [01:18<04:29,  2.76it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 214/958 [01:18<04:28,  2.77it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 214/958 [01:19<04:28,  2.77it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 215/958 [01:19<04:29,  2.76it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 215/958 [01:19<04:29,  2.76it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 216/958 [01:19<04:27,  2.77it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 216/958 [01:19<04:27,  2.77it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 217/958 [01:19<04:27,  2.77it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 217/958 [01:20<04:27,  2.77it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 218/958 [01:20<04:26,  2.78it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 218/958 [01:20<04:26,  2.78it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 219/958 [01:20<04:25,  2.78it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 219/958 [01:20<04:25,  2.78it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 220/958 [01:20<04:26,  2.77it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 220/958 [01:21<04:26,  2.77it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 221/958 [01:21<04:26,  2.77it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 221/958 [01:21<04:26,  2.77it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 222/958 [01:21<04:25,  2.77it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 222/958 [01:21<04:25,  2.77it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 223/958 [01:21<04:26,  2.76it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 223/958 [01:22<04:26,  2.76it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 224/958 [01:22<04:25,  2.77it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 224/958 [01:22<04:25,  2.77it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 225/958 [01:22<04:25,  2.77it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 225/958 [01:22<04:25,  2.77it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 226/958 [01:23<04:23,  2.78it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 226/958 [01:23<04:23,  2.78it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 227/958 [01:23<04:22,  2.78it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 227/958 [01:23<04:22,  2.78it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 228/958 [01:23<04:23,  2.78it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 228/958 [01:24<04:23,  2.78it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 229/958 [01:24<04:22,  2.78it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 229/958 [01:24<04:22,  2.78it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 230/958 [01:24<04:22,  2.77it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 230/958 [01:24<04:22,  2.77it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 231/958 [01:24<04:22,  2.77it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 231/958 [01:25<04:22,  2.77it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 232/958 [01:25<04:22,  2.77it/s, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 232/958 [01:25<04:22,  2.77it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 233/958 [01:25<04:23,  2.75it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 233/958 [01:25<04:23,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 234/958 [01:25<04:23,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 234/958 [01:26<04:23,  2.75it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 235/958 [01:26<04:22,  2.76it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 235/958 [01:26<04:22,  2.76it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 236/958 [01:26<04:23,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 236/958 [01:26<04:23,  2.74it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 237/958 [01:26<04:21,  2.76it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 237/958 [01:27<04:21,  2.76it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 238/958 [01:27<04:19,  2.77it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 238/958 [01:27<04:19,  2.77it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 239/958 [01:27<04:19,  2.77it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 239/958 [01:28<04:19,  2.77it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 240/958 [01:28<04:20,  2.76it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 240/958 [01:28<04:20,  2.76it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 241/958 [01:28<04:19,  2.76it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 241/958 [01:28<04:19,  2.76it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 242/958 [01:28<04:19,  2.76it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 242/958 [01:29<04:19,  2.76it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 243/958 [01:29<04:20,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 243/958 [01:29<04:20,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 244/958 [01:29<04:20,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 244/958 [01:29<04:20,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 245/958 [01:29<04:19,  2.75it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 245/958 [01:30<04:19,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 246/958 [01:30<04:18,  2.76it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 246/958 [01:30<04:18,  2.76it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 247/958 [01:30<04:18,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 247/958 [01:30<04:18,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 248/958 [01:30<04:18,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 248/958 [01:31<04:18,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 249/958 [01:31<04:17,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 249/958 [01:31<04:17,  2.75it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 250/958 [01:31<04:18,  2.74it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 250/958 [01:32<04:18,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 251/958 [01:32<04:18,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 251/958 [01:32<04:18,  2.73it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 252/958 [01:32<04:16,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 252/958 [01:32<04:16,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 253/958 [01:32<04:16,  2.74it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 253/958 [01:33<04:16,  2.74it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 254/958 [01:33<04:16,  2.75it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 254/958 [01:33<04:16,  2.75it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 255/958 [01:33<04:14,  2.76it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 255/958 [01:33<04:14,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 256/958 [01:33<04:13,  2.77it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 256/958 [01:34<04:13,  2.77it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 257/958 [01:34<04:15,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 257/958 [01:34<04:15,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 258/958 [01:34<04:14,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 258/958 [01:34<04:14,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 259/958 [01:34<04:14,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 259/958 [01:35<04:14,  2.75it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 260/958 [01:35<04:14,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 260/958 [01:35<04:14,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 261/958 [01:35<04:14,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 261/958 [01:36<04:14,  2.74it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 262/958 [01:36<04:13,  2.74it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 262/958 [01:36<04:13,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 263/958 [01:36<04:12,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 263/958 [01:36<04:12,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 264/958 [01:36<04:12,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 264/958 [01:37<04:12,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 265/958 [01:37<04:13,  2.73it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 265/958 [01:37<04:13,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 266/958 [01:37<04:12,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 266/958 [01:37<04:12,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 267/958 [01:37<04:13,  2.73it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 267/958 [01:38<04:13,  2.73it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 268/958 [01:38<04:13,  2.72it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 268/958 [01:38<04:13,  2.72it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 269/958 [01:38<04:11,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 269/958 [01:38<04:11,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 270/958 [01:38<04:10,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 270/958 [01:39<04:10,  2.74it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 271/958 [01:39<04:10,  2.75it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 271/958 [01:39<04:10,  2.75it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 272/958 [01:39<04:10,  2.74it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 272/958 [01:40<04:10,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 273/958 [01:40<04:10,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 273/958 [01:40<04:10,  2.74it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 274/958 [01:40<04:11,  2.72it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 274/958 [01:40<04:11,  2.72it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 275/958 [01:40<04:11,  2.72it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 275/958 [01:41<04:11,  2.72it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 276/958 [01:41<04:10,  2.72it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 276/958 [01:41<04:10,  2.72it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 277/958 [01:41<04:09,  2.72it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 277/958 [01:41<04:09,  2.72it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 278/958 [01:41<04:10,  2.72it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 278/958 [01:42<04:10,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 279/958 [01:42<04:09,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 279/958 [01:42<04:09,  2.72it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 280/958 [01:42<04:08,  2.73it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 280/958 [01:43<04:08,  2.73it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 281/958 [01:43<04:08,  2.72it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 281/958 [01:43<04:08,  2.72it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 282/958 [01:43<04:09,  2.71it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 282/958 [01:43<04:09,  2.71it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 283/958 [01:43<04:07,  2.73it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 283/958 [01:44<04:07,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 284/958 [01:44<04:05,  2.74it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 284/958 [01:44<04:05,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 285/958 [01:44<04:05,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 285/958 [01:44<04:05,  2.74it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 286/958 [01:44<04:05,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 286/958 [01:45<04:05,  2.73it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 287/958 [01:45<04:05,  2.74it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 287/958 [01:45<04:05,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  30%|███       | 288/958 [01:45<04:04,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  30%|███       | 288/958 [01:45<04:04,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  30%|███       | 289/958 [01:45<04:04,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  30%|███       | 289/958 [01:46<04:04,  2.74it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  30%|███       | 290/958 [01:46<04:05,  2.72it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  30%|███       | 290/958 [01:46<04:05,  2.72it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  30%|███       | 291/958 [01:46<04:04,  2.73it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  30%|███       | 291/958 [01:47<04:04,  2.73it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  30%|███       | 292/958 [01:47<04:03,  2.74it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  30%|███       | 292/958 [01:47<04:03,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  31%|███       | 293/958 [01:47<04:03,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  31%|███       | 293/958 [01:47<04:03,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  31%|███       | 294/958 [01:47<04:01,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  31%|███       | 294/958 [01:48<04:01,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  31%|███       | 295/958 [01:48<04:01,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  31%|███       | 295/958 [01:48<04:01,  2.75it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  31%|███       | 296/958 [01:48<04:01,  2.74it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  31%|███       | 296/958 [01:48<04:01,  2.74it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  31%|███       | 297/958 [01:48<03:59,  2.75it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  31%|███       | 297/958 [01:49<03:59,  2.75it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  31%|███       | 298/958 [01:49<03:58,  2.76it/s, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  31%|███       | 298/958 [01:49<03:58,  2.76it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  31%|███       | 299/958 [01:49<04:01,  2.73it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  31%|███       | 299/958 [01:49<04:01,  2.73it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 300/958 [01:49<04:01,  2.73it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 300/958 [01:50<04:01,  2.73it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 301/958 [01:50<04:00,  2.74it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 301/958 [01:50<04:00,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 302/958 [01:50<03:58,  2.75it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 302/958 [01:51<03:58,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 303/958 [01:51<03:58,  2.74it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 303/958 [01:51<03:58,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 304/958 [01:51<03:58,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 304/958 [01:51<03:58,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 305/958 [01:51<03:57,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 305/958 [01:52<03:57,  2.75it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 306/958 [01:52<03:58,  2.73it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 306/958 [01:52<03:58,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 307/958 [01:52<03:58,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 307/958 [01:52<03:58,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 308/958 [01:52<03:56,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 308/958 [01:53<03:56,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 309/958 [01:53<03:56,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 309/958 [01:53<03:56,  2.75it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 310/958 [01:53<03:56,  2.74it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 310/958 [01:53<03:56,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 311/958 [01:54<03:57,  2.73it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 311/958 [01:54<03:57,  2.73it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 312/958 [01:54<03:59,  2.70it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 312/958 [01:54<03:59,  2.70it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 313/958 [01:54<03:58,  2.70it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 313/958 [01:55<03:58,  2.70it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 314/958 [01:55<03:56,  2.72it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 314/958 [01:55<03:56,  2.72it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 315/958 [01:55<03:57,  2.70it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 315/958 [01:55<03:57,  2.70it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 316/958 [01:55<03:57,  2.70it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 316/958 [01:56<03:57,  2.70it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 317/958 [01:56<03:58,  2.69it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 317/958 [01:56<03:58,  2.69it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 318/958 [01:56<03:57,  2.69it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 318/958 [01:56<03:57,  2.69it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 319/958 [01:56<03:55,  2.71it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 319/958 [01:57<03:55,  2.71it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 320/958 [01:57<03:55,  2.70it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 320/958 [01:57<03:55,  2.70it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 321/958 [01:57<03:53,  2.72it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 321/958 [01:58<03:53,  2.72it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 322/958 [01:58<03:52,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 322/958 [01:58<03:52,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 323/958 [01:58<03:53,  2.72it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 323/958 [01:58<03:53,  2.72it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 324/958 [01:58<03:52,  2.73it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 324/958 [01:59<03:52,  2.73it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 325/958 [01:59<03:52,  2.72it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 325/958 [01:59<03:52,  2.72it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 326/958 [01:59<03:52,  2.72it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 326/958 [01:59<03:52,  2.72it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 327/958 [01:59<03:51,  2.73it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 327/958 [02:00<03:51,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 328/958 [02:00<03:51,  2.72it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 328/958 [02:00<03:51,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 329/958 [02:00<03:50,  2.73it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 329/958 [02:00<03:50,  2.73it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 330/958 [02:00<03:49,  2.73it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 330/958 [02:01<03:49,  2.73it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 331/958 [02:01<03:49,  2.73it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 331/958 [02:01<03:49,  2.73it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 332/958 [02:01<03:49,  2.73it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 332/958 [02:02<03:49,  2.73it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 333/958 [02:02<03:49,  2.73it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 333/958 [02:02<03:49,  2.73it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 334/958 [02:02<03:49,  2.72it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 334/958 [02:02<03:49,  2.72it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 335/958 [02:02<03:48,  2.72it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 335/958 [02:03<03:48,  2.72it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 336/958 [02:03<03:48,  2.73it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 336/958 [02:03<03:48,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 337/958 [02:03<03:47,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 337/958 [02:03<03:47,  2.73it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 338/958 [02:03<03:45,  2.75it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 338/958 [02:04<03:45,  2.75it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 339/958 [02:04<03:46,  2.74it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 339/958 [02:04<03:46,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 340/958 [02:04<03:46,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 340/958 [02:05<03:46,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 341/958 [02:05<03:45,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 341/958 [02:05<03:45,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 342/958 [02:05<03:46,  2.71it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 342/958 [02:05<03:46,  2.71it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 343/958 [02:05<03:46,  2.72it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 343/958 [02:06<03:46,  2.72it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 344/958 [02:06<03:44,  2.73it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 344/958 [02:06<03:44,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 345/958 [02:06<03:44,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 345/958 [02:06<03:44,  2.73it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 346/958 [02:06<03:45,  2.72it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 346/958 [02:07<03:45,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 347/958 [02:07<03:44,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 347/958 [02:07<03:44,  2.72it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 348/958 [02:07<03:45,  2.71it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 348/958 [02:07<03:45,  2.71it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 349/958 [02:07<03:44,  2.71it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 349/958 [02:08<03:44,  2.71it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 350/958 [02:08<03:43,  2.72it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 350/958 [02:08<03:43,  2.72it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 351/958 [02:08<03:42,  2.72it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 351/958 [02:09<03:42,  2.72it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 352/958 [02:09<03:40,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 352/958 [02:09<03:40,  2.75it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 353/958 [02:09<03:40,  2.74it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 353/958 [02:09<03:40,  2.74it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 354/958 [02:09<03:39,  2.75it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 354/958 [02:10<03:39,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 355/958 [02:10<03:40,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 355/958 [02:10<03:40,  2.74it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 356/958 [02:10<03:40,  2.73it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 356/958 [02:10<03:40,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 357/958 [02:10<03:40,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 357/958 [02:11<03:40,  2.73it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 358/958 [02:11<03:39,  2.73it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 358/958 [02:11<03:39,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 359/958 [02:11<03:39,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 359/958 [02:11<03:39,  2.73it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 360/958 [02:11<03:38,  2.74it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 360/958 [02:12<03:38,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 361/958 [02:12<03:38,  2.73it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 361/958 [02:12<03:38,  2.73it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 362/958 [02:12<03:37,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 362/958 [02:13<03:37,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 363/958 [02:13<03:37,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 363/958 [02:13<03:37,  2.74it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 364/958 [02:13<03:36,  2.74it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 364/958 [02:13<03:36,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 365/958 [02:13<03:36,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 365/958 [02:14<03:36,  2.74it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 366/958 [02:14<03:34,  2.76it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 366/958 [02:14<03:34,  2.76it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 367/958 [02:14<03:35,  2.74it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 367/958 [02:14<03:35,  2.74it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 368/958 [02:14<03:35,  2.73it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 368/958 [02:15<03:35,  2.73it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 369/958 [02:15<03:34,  2.74it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 369/958 [02:15<03:34,  2.74it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 370/958 [02:15<03:35,  2.73it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 370/958 [02:15<03:35,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 371/958 [02:16<03:34,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 371/958 [02:16<03:34,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 372/958 [02:16<03:33,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 372/958 [02:16<03:33,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 373/958 [02:16<03:33,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 373/958 [02:17<03:33,  2.74it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 374/958 [02:17<03:33,  2.73it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 374/958 [02:17<03:33,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 375/958 [02:17<03:33,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 375/958 [02:17<03:33,  2.73it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 376/958 [02:17<03:32,  2.74it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 376/958 [02:18<03:32,  2.74it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 377/958 [02:18<03:31,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 377/958 [02:18<03:31,  2.75it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 378/958 [02:18<03:32,  2.73it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 378/958 [02:18<03:32,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 379/958 [02:18<03:31,  2.74it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 379/958 [02:19<03:31,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 380/958 [02:19<03:30,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 380/958 [02:19<03:30,  2.74it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 381/958 [02:19<03:31,  2.73it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 381/958 [02:20<03:31,  2.73it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 382/958 [02:20<03:31,  2.73it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 382/958 [02:20<03:31,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 383/958 [02:20<03:31,  2.72it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 383/958 [02:20<03:31,  2.72it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  40%|████      | 384/958 [02:20<03:30,  2.72it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  40%|████      | 384/958 [02:21<03:30,  2.72it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  40%|████      | 385/958 [02:21<03:28,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  40%|████      | 385/958 [02:21<03:28,  2.75it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  40%|████      | 386/958 [02:21<03:28,  2.74it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  40%|████      | 386/958 [02:21<03:28,  2.74it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  40%|████      | 387/958 [02:21<03:27,  2.75it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  40%|████      | 387/958 [02:22<03:27,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  41%|████      | 388/958 [02:22<03:27,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  41%|████      | 388/958 [02:22<03:27,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  41%|████      | 389/958 [02:22<03:28,  2.73it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  41%|████      | 389/958 [02:22<03:28,  2.73it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  41%|████      | 390/958 [02:22<03:28,  2.73it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  41%|████      | 390/958 [02:23<03:28,  2.73it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  41%|████      | 391/958 [02:23<03:27,  2.73it/s, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  41%|████      | 391/958 [02:23<03:27,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  41%|████      | 392/958 [02:23<03:27,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  41%|████      | 392/958 [02:24<03:27,  2.73it/s, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  41%|████      | 393/958 [02:24<03:28,  2.71it/s, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  41%|████      | 393/958 [02:24<03:28,  2.71it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  41%|████      | 394/958 [02:24<03:26,  2.73it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  41%|████      | 394/958 [02:24<03:26,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  41%|████      | 395/958 [02:24<03:25,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  41%|████      | 395/958 [02:25<03:25,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 396/958 [02:25<03:25,  2.73it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 396/958 [02:25<03:25,  2.73it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 397/958 [02:25<03:25,  2.73it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 397/958 [02:25<03:25,  2.73it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 398/958 [02:25<03:24,  2.74it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 398/958 [02:26<03:24,  2.74it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 399/958 [02:26<03:25,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 399/958 [02:26<03:25,  2.73it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 400/958 [02:26<03:23,  2.75it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 400/958 [02:26<03:23,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 401/958 [02:26<03:22,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 401/958 [02:27<03:22,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 402/958 [02:27<03:23,  2.73it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 402/958 [02:27<03:23,  2.73it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 403/958 [02:27<03:23,  2.73it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 403/958 [02:28<03:23,  2.73it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 404/958 [02:28<03:23,  2.72it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 404/958 [02:28<03:23,  2.72it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 405/958 [02:28<03:23,  2.72it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 405/958 [02:28<03:23,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 406/958 [02:28<03:22,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 406/958 [02:29<03:22,  2.72it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 407/958 [02:29<03:21,  2.74it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 407/958 [02:29<03:21,  2.74it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 408/958 [02:29<03:20,  2.75it/s, training_loss=0.266]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 408/958 [02:29<03:20,  2.75it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 409/958 [02:29<03:19,  2.75it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 409/958 [02:30<03:19,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 410/958 [02:30<03:19,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 410/958 [02:30<03:19,  2.75it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 411/958 [02:30<03:19,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 411/958 [02:30<03:19,  2.74it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 412/958 [02:30<03:18,  2.74it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 412/958 [02:31<03:18,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 413/958 [02:31<03:18,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 413/958 [02:31<03:18,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 414/958 [02:31<03:19,  2.73it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 414/958 [02:32<03:19,  2.73it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 415/958 [02:32<03:18,  2.74it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 415/958 [02:32<03:18,  2.74it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 416/958 [02:32<03:16,  2.75it/s, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 416/958 [02:32<03:16,  2.75it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 417/958 [02:32<03:18,  2.73it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 417/958 [02:33<03:18,  2.73it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 418/958 [02:33<03:16,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 418/958 [02:33<03:16,  2.75it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 419/958 [02:33<03:15,  2.76it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 419/958 [02:33<03:15,  2.76it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 420/958 [02:33<03:15,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 420/958 [02:34<03:15,  2.75it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 421/958 [02:34<03:15,  2.75it/s, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 421/958 [02:34<03:15,  2.75it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 422/958 [02:34<03:14,  2.76it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 422/958 [02:34<03:14,  2.76it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 423/958 [02:34<03:14,  2.75it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 423/958 [02:35<03:14,  2.75it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 424/958 [02:35<03:13,  2.76it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 424/958 [02:35<03:13,  2.76it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 425/958 [02:35<03:12,  2.76it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 425/958 [02:36<03:12,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 426/958 [02:36<03:13,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 426/958 [02:36<03:13,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 427/958 [02:36<03:12,  2.76it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 427/958 [02:36<03:12,  2.76it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 428/958 [02:36<03:12,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 428/958 [02:37<03:12,  2.75it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 429/958 [02:37<03:12,  2.75it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 429/958 [02:37<03:12,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 430/958 [02:37<03:12,  2.74it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 430/958 [02:37<03:12,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 431/958 [02:37<03:12,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 431/958 [02:38<03:12,  2.74it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 432/958 [02:38<03:13,  2.72it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 432/958 [02:38<03:13,  2.72it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 433/958 [02:38<03:11,  2.74it/s, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 433/958 [02:38<03:11,  2.74it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 434/958 [02:39<03:11,  2.74it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 434/958 [02:39<03:11,  2.74it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 435/958 [02:39<03:12,  2.72it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 435/958 [02:39<03:12,  2.72it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 436/958 [02:39<03:10,  2.74it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 436/958 [02:40<03:10,  2.74it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 437/958 [02:40<03:08,  2.76it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 437/958 [02:40<03:08,  2.76it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 438/958 [02:40<03:11,  2.72it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 438/958 [02:40<03:11,  2.72it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 439/958 [02:40<03:10,  2.73it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 439/958 [02:41<03:10,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 440/958 [02:41<03:10,  2.72it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 440/958 [02:41<03:10,  2.72it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 441/958 [02:41<03:10,  2.72it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 441/958 [02:41<03:10,  2.72it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 442/958 [02:41<03:10,  2.70it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 442/958 [02:42<03:10,  2.70it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 443/958 [02:42<03:08,  2.74it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 443/958 [02:42<03:08,  2.74it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 444/958 [02:42<03:08,  2.72it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 444/958 [02:43<03:08,  2.72it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 445/958 [02:43<03:08,  2.72it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 445/958 [02:43<03:08,  2.72it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 446/958 [02:43<03:07,  2.73it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 446/958 [02:43<03:07,  2.73it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 447/958 [02:43<03:07,  2.72it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 447/958 [02:44<03:07,  2.72it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 448/958 [02:44<03:05,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 448/958 [02:44<03:05,  2.75it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 449/958 [02:44<03:05,  2.75it/s, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 449/958 [02:44<03:05,  2.75it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 450/958 [02:44<03:04,  2.76it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 450/958 [02:45<03:04,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 451/958 [02:45<03:03,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 451/958 [02:45<03:03,  2.76it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 452/958 [02:45<03:02,  2.77it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 452/958 [02:45<03:02,  2.77it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 453/958 [02:45<03:02,  2.76it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 453/958 [02:46<03:02,  2.76it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 454/958 [02:46<03:02,  2.76it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 454/958 [02:46<03:02,  2.76it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 455/958 [02:46<03:03,  2.75it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 455/958 [02:47<03:03,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 456/958 [02:47<03:02,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 456/958 [02:47<03:02,  2.75it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 457/958 [02:47<03:01,  2.76it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 457/958 [02:47<03:01,  2.76it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 458/958 [02:47<03:01,  2.76it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 458/958 [02:48<03:01,  2.76it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 459/958 [02:48<03:01,  2.76it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 459/958 [02:48<03:01,  2.76it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 460/958 [02:48<03:00,  2.76it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 460/958 [02:48<03:00,  2.76it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 461/958 [02:48<02:59,  2.76it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 461/958 [02:49<02:59,  2.76it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 462/958 [02:49<03:00,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 462/958 [02:49<03:00,  2.75it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 463/958 [02:49<02:59,  2.76it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 463/958 [02:49<02:59,  2.76it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 464/958 [02:49<02:58,  2.77it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 464/958 [02:50<02:58,  2.77it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 465/958 [02:50<03:00,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 465/958 [02:50<03:00,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 466/958 [02:50<02:59,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 466/958 [02:51<02:59,  2.75it/s, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 467/958 [02:51<02:58,  2.75it/s, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 467/958 [02:51<02:58,  2.75it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 468/958 [02:51<02:58,  2.75it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 468/958 [02:51<02:58,  2.75it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 469/958 [02:51<02:58,  2.74it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 469/958 [02:52<02:58,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 470/958 [02:52<02:58,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 470/958 [02:52<02:58,  2.74it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 471/958 [02:52<02:58,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 471/958 [02:52<02:58,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 472/958 [02:52<02:56,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 472/958 [02:53<02:56,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 473/958 [02:53<02:55,  2.76it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 473/958 [02:53<02:55,  2.76it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 474/958 [02:53<02:56,  2.75it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 474/958 [02:53<02:56,  2.75it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 475/958 [02:53<02:55,  2.75it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 475/958 [02:54<02:55,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 476/958 [02:54<02:54,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 476/958 [02:54<02:54,  2.75it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 477/958 [02:54<02:57,  2.72it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 477/958 [02:55<02:57,  2.72it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 478/958 [02:55<02:55,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 478/958 [02:55<02:55,  2.73it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  50%|█████     | 479/958 [02:55<02:54,  2.75it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  50%|█████     | 479/958 [02:55<02:54,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  50%|█████     | 480/958 [02:55<02:54,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  50%|█████     | 480/958 [02:56<02:54,  2.74it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  50%|█████     | 481/958 [02:56<02:53,  2.74it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  50%|█████     | 481/958 [02:56<02:53,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  50%|█████     | 482/958 [02:56<02:52,  2.76it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  50%|█████     | 482/958 [02:56<02:52,  2.76it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  50%|█████     | 483/958 [02:56<02:53,  2.74it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  50%|█████     | 483/958 [02:57<02:53,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  51%|█████     | 484/958 [02:57<02:53,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  51%|█████     | 484/958 [02:57<02:53,  2.74it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  51%|█████     | 485/958 [02:57<02:53,  2.73it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  51%|█████     | 485/958 [02:57<02:53,  2.73it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  51%|█████     | 486/958 [02:57<02:54,  2.71it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  51%|█████     | 486/958 [02:58<02:54,  2.71it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  51%|█████     | 487/958 [02:58<02:53,  2.72it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  51%|█████     | 487/958 [02:58<02:53,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  51%|█████     | 488/958 [02:58<02:51,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  51%|█████     | 488/958 [02:59<02:51,  2.74it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  51%|█████     | 489/958 [02:59<02:50,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  51%|█████     | 489/958 [02:59<02:50,  2.75it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  51%|█████     | 490/958 [02:59<02:49,  2.76it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  51%|█████     | 490/958 [02:59<02:49,  2.76it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 491/958 [02:59<02:50,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 491/958 [03:00<02:50,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 492/958 [03:00<02:49,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 492/958 [03:00<02:49,  2.75it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 493/958 [03:00<02:50,  2.73it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 493/958 [03:00<02:50,  2.73it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 494/958 [03:00<02:50,  2.72it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 494/958 [03:01<02:50,  2.72it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 495/958 [03:01<02:49,  2.74it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 495/958 [03:01<02:49,  2.74it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 496/958 [03:01<02:49,  2.73it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 496/958 [03:01<02:49,  2.73it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 497/958 [03:01<02:49,  2.73it/s, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 497/958 [03:02<02:49,  2.73it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 498/958 [03:02<02:47,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 498/958 [03:02<02:47,  2.74it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 499/958 [03:02<02:47,  2.74it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 499/958 [03:03<02:47,  2.74it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 500/958 [03:03<02:47,  2.74it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 500/958 [03:03<02:47,  2.74it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 501/958 [03:03<02:47,  2.73it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 501/958 [03:03<02:47,  2.73it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 502/958 [03:03<02:46,  2.73it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 502/958 [03:04<02:46,  2.73it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 503/958 [03:04<02:46,  2.73it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 503/958 [03:04<02:46,  2.73it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 504/958 [03:04<02:45,  2.74it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 504/958 [03:04<02:45,  2.74it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 505/958 [03:04<02:45,  2.73it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 505/958 [03:05<02:45,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 506/958 [03:05<02:44,  2.74it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 506/958 [03:05<02:44,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 507/958 [03:05<02:44,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 507/958 [03:05<02:44,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 508/958 [03:05<02:42,  2.76it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 508/958 [03:06<02:42,  2.76it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 509/958 [03:06<02:42,  2.76it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 509/958 [03:06<02:42,  2.76it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 510/958 [03:06<02:42,  2.76it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 510/958 [03:07<02:42,  2.76it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 511/958 [03:07<02:42,  2.75it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 511/958 [03:07<02:42,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 512/958 [03:07<02:42,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 512/958 [03:07<02:42,  2.75it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 513/958 [03:07<02:41,  2.75it/s, training_loss=0.265]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 513/958 [03:08<02:41,  2.75it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 514/958 [03:08<02:41,  2.76it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 514/958 [03:08<02:41,  2.76it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 515/958 [03:08<02:40,  2.75it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 515/958 [03:08<02:40,  2.75it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 516/958 [03:08<02:40,  2.75it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 516/958 [03:09<02:40,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 517/958 [03:09<02:39,  2.76it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 517/958 [03:09<02:39,  2.76it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 518/958 [03:09<02:40,  2.75it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 518/958 [03:09<02:40,  2.75it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 519/958 [03:09<02:39,  2.76it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 519/958 [03:10<02:39,  2.76it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 520/958 [03:10<02:38,  2.75it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 520/958 [03:10<02:38,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 521/958 [03:10<02:38,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 521/958 [03:11<02:38,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 522/958 [03:11<02:38,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 522/958 [03:11<02:38,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 523/958 [03:11<02:38,  2.75it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 523/958 [03:11<02:38,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 524/958 [03:11<02:37,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 524/958 [03:12<02:37,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 525/958 [03:12<02:37,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 525/958 [03:12<02:37,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 526/958 [03:12<02:37,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 526/958 [03:12<02:37,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 527/958 [03:12<02:36,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 527/958 [03:13<02:36,  2.75it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 528/958 [03:13<02:37,  2.73it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 528/958 [03:13<02:37,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 529/958 [03:13<02:36,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 529/958 [03:13<02:36,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 530/958 [03:13<02:35,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 530/958 [03:14<02:35,  2.75it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 531/958 [03:14<02:36,  2.73it/s, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 531/958 [03:14<02:36,  2.73it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 532/958 [03:14<02:35,  2.73it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 532/958 [03:15<02:35,  2.73it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 533/958 [03:15<02:34,  2.75it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 533/958 [03:15<02:34,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 534/958 [03:15<02:33,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 534/958 [03:15<02:33,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 535/958 [03:15<02:33,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 535/958 [03:16<02:33,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 536/958 [03:16<02:33,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 536/958 [03:16<02:33,  2.75it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 537/958 [03:16<02:33,  2.75it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 537/958 [03:16<02:33,  2.75it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 538/958 [03:16<02:32,  2.75it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 538/958 [03:17<02:32,  2.75it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 539/958 [03:17<02:31,  2.76it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 539/958 [03:17<02:31,  2.76it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 540/958 [03:17<02:31,  2.76it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 540/958 [03:17<02:31,  2.76it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 541/958 [03:17<02:31,  2.76it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 541/958 [03:18<02:31,  2.76it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 542/958 [03:18<02:31,  2.75it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 542/958 [03:18<02:31,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 543/958 [03:18<02:30,  2.76it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 543/958 [03:19<02:30,  2.76it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 544/958 [03:19<02:31,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 544/958 [03:19<02:31,  2.73it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 545/958 [03:19<02:30,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 545/958 [03:19<02:30,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 546/958 [03:19<02:29,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 546/958 [03:20<02:29,  2.75it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 547/958 [03:20<02:30,  2.73it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 547/958 [03:20<02:30,  2.73it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 548/958 [03:20<02:29,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 548/958 [03:20<02:29,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 549/958 [03:20<02:29,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 549/958 [03:21<02:29,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 550/958 [03:21<02:28,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 550/958 [03:21<02:28,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 551/958 [03:21<02:28,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 551/958 [03:21<02:28,  2.74it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 552/958 [03:22<02:27,  2.75it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 552/958 [03:22<02:27,  2.75it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 553/958 [03:22<02:28,  2.74it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 553/958 [03:22<02:28,  2.74it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 554/958 [03:22<02:27,  2.74it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 554/958 [03:23<02:27,  2.74it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 555/958 [03:23<02:27,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 555/958 [03:23<02:27,  2.73it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 556/958 [03:23<02:26,  2.74it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 556/958 [03:23<02:26,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 557/958 [03:23<02:26,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 557/958 [03:24<02:26,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 558/958 [03:24<02:25,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 558/958 [03:24<02:25,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 559/958 [03:24<02:24,  2.75it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 559/958 [03:24<02:24,  2.75it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 560/958 [03:24<02:24,  2.75it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 560/958 [03:25<02:24,  2.75it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 561/958 [03:25<02:25,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 561/958 [03:25<02:25,  2.73it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 562/958 [03:25<02:24,  2.74it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 562/958 [03:26<02:24,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 563/958 [03:26<02:24,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 563/958 [03:26<02:24,  2.73it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 564/958 [03:26<02:24,  2.73it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 564/958 [03:26<02:24,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 565/958 [03:26<02:24,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 565/958 [03:27<02:24,  2.73it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 566/958 [03:27<02:22,  2.74it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 566/958 [03:27<02:22,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 567/958 [03:27<02:23,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 567/958 [03:27<02:23,  2.73it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 568/958 [03:27<02:22,  2.74it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 568/958 [03:28<02:22,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 569/958 [03:28<02:22,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 569/958 [03:28<02:22,  2.73it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 570/958 [03:28<02:22,  2.72it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 570/958 [03:28<02:22,  2.72it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 571/958 [03:28<02:21,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 571/958 [03:29<02:21,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 572/958 [03:29<02:21,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 572/958 [03:29<02:21,  2.73it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 573/958 [03:29<02:20,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 573/958 [03:30<02:20,  2.74it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 574/958 [03:30<02:21,  2.72it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 574/958 [03:30<02:21,  2.72it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  60%|██████    | 575/958 [03:30<02:20,  2.73it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  60%|██████    | 575/958 [03:30<02:20,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  60%|██████    | 576/958 [03:30<02:19,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  60%|██████    | 576/958 [03:31<02:19,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  60%|██████    | 577/958 [03:31<02:19,  2.73it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  60%|██████    | 577/958 [03:31<02:19,  2.73it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  60%|██████    | 578/958 [03:31<02:19,  2.71it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  60%|██████    | 578/958 [03:31<02:19,  2.71it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  60%|██████    | 579/958 [03:31<02:19,  2.73it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  60%|██████    | 579/958 [03:32<02:19,  2.73it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 1:  61%|██████    | 580/958 [03:32<02:18,  2.73it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 1:  61%|██████    | 580/958 [03:32<02:18,  2.73it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  61%|██████    | 581/958 [03:32<02:17,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  61%|██████    | 581/958 [03:32<02:17,  2.74it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  61%|██████    | 582/958 [03:32<02:17,  2.74it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  61%|██████    | 582/958 [03:33<02:17,  2.74it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  61%|██████    | 583/958 [03:33<02:16,  2.75it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  61%|██████    | 583/958 [03:33<02:16,  2.75it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  61%|██████    | 584/958 [03:33<02:17,  2.72it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  61%|██████    | 584/958 [03:34<02:17,  2.72it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  61%|██████    | 585/958 [03:34<02:15,  2.75it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  61%|██████    | 585/958 [03:34<02:15,  2.75it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  61%|██████    | 586/958 [03:34<02:14,  2.76it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  61%|██████    | 586/958 [03:34<02:14,  2.76it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 587/958 [03:34<02:14,  2.76it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 587/958 [03:35<02:14,  2.76it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 588/958 [03:35<02:14,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 588/958 [03:35<02:14,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 589/958 [03:35<02:14,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 589/958 [03:35<02:14,  2.75it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 590/958 [03:35<02:14,  2.74it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 590/958 [03:36<02:14,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 591/958 [03:36<02:14,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 591/958 [03:36<02:14,  2.73it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 592/958 [03:36<02:13,  2.74it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 592/958 [03:36<02:13,  2.74it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 593/958 [03:36<02:12,  2.74it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 593/958 [03:37<02:12,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 594/958 [03:37<02:13,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 594/958 [03:37<02:13,  2.73it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 595/958 [03:37<02:11,  2.75it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 595/958 [03:38<02:11,  2.75it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 596/958 [03:38<02:11,  2.75it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 596/958 [03:38<02:11,  2.75it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 597/958 [03:38<02:12,  2.73it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 597/958 [03:38<02:12,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 598/958 [03:38<02:12,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 598/958 [03:39<02:12,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 599/958 [03:39<02:11,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 599/958 [03:39<02:11,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 600/958 [03:39<02:11,  2.71it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 600/958 [03:39<02:11,  2.71it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 601/958 [03:39<02:11,  2.72it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 601/958 [03:40<02:11,  2.72it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 602/958 [03:40<02:11,  2.71it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 602/958 [03:40<02:11,  2.71it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 603/958 [03:40<02:10,  2.72it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 603/958 [03:41<02:10,  2.72it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 604/958 [03:41<02:10,  2.72it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 604/958 [03:41<02:10,  2.72it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 605/958 [03:41<02:08,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 605/958 [03:41<02:08,  2.74it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 606/958 [03:41<02:09,  2.73it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 606/958 [03:42<02:09,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 607/958 [03:42<02:07,  2.74it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 607/958 [03:42<02:07,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 608/958 [03:42<02:06,  2.76it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 608/958 [03:42<02:06,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 609/958 [03:42<02:07,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 609/958 [03:43<02:07,  2.74it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 610/958 [03:43<02:07,  2.73it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 610/958 [03:43<02:07,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 611/958 [03:43<02:07,  2.72it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 611/958 [03:43<02:07,  2.72it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 612/958 [03:43<02:07,  2.72it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 612/958 [03:44<02:07,  2.72it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 613/958 [03:44<02:06,  2.73it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 613/958 [03:44<02:06,  2.73it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 614/958 [03:44<02:05,  2.74it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 614/958 [03:45<02:05,  2.74it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 615/958 [03:45<02:04,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 615/958 [03:45<02:04,  2.75it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 616/958 [03:45<02:04,  2.75it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 616/958 [03:45<02:04,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 617/958 [03:45<02:04,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 617/958 [03:46<02:04,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 618/958 [03:46<02:04,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 618/958 [03:46<02:04,  2.74it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 619/958 [03:46<02:03,  2.74it/s, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 619/958 [03:46<02:03,  2.74it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 620/958 [03:46<02:02,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 620/958 [03:47<02:02,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 621/958 [03:47<02:02,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 621/958 [03:47<02:02,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 622/958 [03:47<02:03,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 622/958 [03:47<02:03,  2.73it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 623/958 [03:47<02:02,  2.73it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 623/958 [03:48<02:02,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 624/958 [03:48<02:02,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 624/958 [03:48<02:02,  2.73it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 625/958 [03:48<02:02,  2.71it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 625/958 [03:49<02:02,  2.71it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 626/958 [03:49<02:01,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 626/958 [03:49<02:01,  2.74it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 627/958 [03:49<02:01,  2.73it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 627/958 [03:49<02:01,  2.73it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 628/958 [03:49<02:00,  2.73it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 628/958 [03:50<02:00,  2.73it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 629/958 [03:50<02:00,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 629/958 [03:50<02:00,  2.74it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 630/958 [03:50<01:59,  2.74it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 630/958 [03:50<01:59,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 631/958 [03:50<01:59,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 631/958 [03:51<01:59,  2.73it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 632/958 [03:51<01:59,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 632/958 [03:51<01:59,  2.74it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 633/958 [03:51<01:58,  2.73it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 633/958 [03:51<01:58,  2.73it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 634/958 [03:51<01:59,  2.72it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 634/958 [03:52<01:59,  2.72it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 635/958 [03:52<01:57,  2.75it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 635/958 [03:52<01:57,  2.75it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 636/958 [03:52<01:57,  2.74it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 636/958 [03:53<01:57,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 637/958 [03:53<01:57,  2.73it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 637/958 [03:53<01:57,  2.73it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 638/958 [03:53<01:57,  2.72it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 638/958 [03:53<01:57,  2.72it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 639/958 [03:53<01:57,  2.71it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 639/958 [03:54<01:57,  2.71it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 640/958 [03:54<01:56,  2.72it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 640/958 [03:54<01:56,  2.72it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 641/958 [03:54<01:55,  2.74it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 641/958 [03:54<01:55,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 642/958 [03:54<01:55,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 642/958 [03:55<01:55,  2.74it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 643/958 [03:55<01:54,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 643/958 [03:55<01:54,  2.75it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 644/958 [03:55<01:54,  2.74it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 644/958 [03:56<01:54,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 645/958 [03:56<01:54,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 645/958 [03:56<01:54,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 646/958 [03:56<01:53,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 646/958 [03:56<01:53,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 647/958 [03:56<01:53,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 647/958 [03:57<01:53,  2.73it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 648/958 [03:57<01:52,  2.74it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 648/958 [03:57<01:52,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 649/958 [03:57<01:52,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 649/958 [03:57<01:52,  2.74it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 650/958 [03:57<01:52,  2.73it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 650/958 [03:58<01:52,  2.73it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 651/958 [03:58<01:52,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 651/958 [03:58<01:52,  2.74it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 652/958 [03:58<01:52,  2.73it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 652/958 [03:58<01:52,  2.73it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 653/958 [03:58<01:51,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 653/958 [03:59<01:51,  2.74it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 654/958 [03:59<01:50,  2.74it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 654/958 [03:59<01:50,  2.74it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 655/958 [03:59<01:50,  2.75it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 655/958 [04:00<01:50,  2.75it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 656/958 [04:00<01:50,  2.74it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 656/958 [04:00<01:50,  2.74it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 657/958 [04:00<01:49,  2.75it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 657/958 [04:00<01:49,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 658/958 [04:00<01:49,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 658/958 [04:01<01:49,  2.74it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 659/958 [04:01<01:49,  2.73it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 659/958 [04:01<01:49,  2.73it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 660/958 [04:01<01:48,  2.74it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 660/958 [04:01<01:48,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 661/958 [04:01<01:48,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 661/958 [04:02<01:48,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 662/958 [04:02<01:47,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 662/958 [04:02<01:47,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 663/958 [04:02<01:48,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 663/958 [04:02<01:48,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 664/958 [04:02<01:47,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 664/958 [04:03<01:47,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 665/958 [04:03<01:46,  2.74it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 665/958 [04:03<01:46,  2.74it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 666/958 [04:03<01:47,  2.72it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 666/958 [04:04<01:47,  2.72it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 667/958 [04:04<01:47,  2.72it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 667/958 [04:04<01:47,  2.72it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 668/958 [04:04<01:47,  2.71it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 668/958 [04:04<01:47,  2.71it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 669/958 [04:04<01:46,  2.71it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 669/958 [04:05<01:46,  2.71it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 670/958 [04:05<01:45,  2.72it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 670/958 [04:05<01:45,  2.72it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  70%|███████   | 671/958 [04:05<01:44,  2.75it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  70%|███████   | 671/958 [04:05<01:44,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  70%|███████   | 672/958 [04:05<01:44,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  70%|███████   | 672/958 [04:06<01:44,  2.73it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  70%|███████   | 673/958 [04:06<01:44,  2.72it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  70%|███████   | 673/958 [04:06<01:44,  2.72it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  70%|███████   | 674/958 [04:06<01:44,  2.72it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  70%|███████   | 674/958 [04:06<01:44,  2.72it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  70%|███████   | 675/958 [04:06<01:44,  2.72it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  70%|███████   | 675/958 [04:07<01:44,  2.72it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  71%|███████   | 676/958 [04:07<01:44,  2.70it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  71%|███████   | 676/958 [04:07<01:44,  2.70it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  71%|███████   | 677/958 [04:07<01:43,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  71%|███████   | 677/958 [04:08<01:43,  2.72it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  71%|███████   | 678/958 [04:08<01:43,  2.71it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  71%|███████   | 678/958 [04:08<01:43,  2.71it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 1:  71%|███████   | 679/958 [04:08<01:43,  2.70it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 1:  71%|███████   | 679/958 [04:08<01:43,  2.70it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  71%|███████   | 680/958 [04:08<01:42,  2.71it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  71%|███████   | 680/958 [04:09<01:42,  2.71it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  71%|███████   | 681/958 [04:09<01:42,  2.71it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  71%|███████   | 681/958 [04:09<01:42,  2.71it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  71%|███████   | 682/958 [04:09<01:41,  2.72it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  71%|███████   | 682/958 [04:09<01:41,  2.72it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 683/958 [04:09<01:41,  2.70it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 683/958 [04:10<01:41,  2.70it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 684/958 [04:10<01:40,  2.72it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 684/958 [04:10<01:40,  2.72it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 685/958 [04:10<01:39,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 685/958 [04:11<01:39,  2.73it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 686/958 [04:11<01:39,  2.75it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 686/958 [04:11<01:39,  2.75it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 687/958 [04:11<01:38,  2.74it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 687/958 [04:11<01:38,  2.74it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 688/958 [04:11<01:38,  2.76it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 688/958 [04:12<01:38,  2.76it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 689/958 [04:12<01:38,  2.74it/s, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 689/958 [04:12<01:38,  2.74it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 690/958 [04:12<01:38,  2.72it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 690/958 [04:12<01:38,  2.72it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 691/958 [04:12<01:37,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 691/958 [04:13<01:37,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 692/958 [04:13<01:36,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 692/958 [04:13<01:36,  2.75it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 693/958 [04:13<01:36,  2.75it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 693/958 [04:13<01:36,  2.75it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 694/958 [04:13<01:36,  2.73it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 694/958 [04:14<01:36,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 695/958 [04:14<01:35,  2.76it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 695/958 [04:14<01:35,  2.76it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 696/958 [04:14<01:35,  2.75it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 696/958 [04:15<01:35,  2.75it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 697/958 [04:15<01:35,  2.74it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 697/958 [04:15<01:35,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 698/958 [04:15<01:35,  2.73it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 698/958 [04:15<01:35,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 699/958 [04:15<01:34,  2.74it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 699/958 [04:16<01:34,  2.74it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 700/958 [04:16<01:34,  2.74it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 700/958 [04:16<01:34,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 701/958 [04:16<01:33,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 701/958 [04:16<01:33,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 702/958 [04:16<01:33,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 702/958 [04:17<01:33,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 703/958 [04:17<01:33,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 703/958 [04:17<01:33,  2.74it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 704/958 [04:17<01:32,  2.74it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 704/958 [04:17<01:32,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 705/958 [04:17<01:32,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 705/958 [04:18<01:32,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 706/958 [04:18<01:32,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 706/958 [04:18<01:32,  2.74it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 707/958 [04:18<01:32,  2.72it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 707/958 [04:19<01:32,  2.72it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 708/958 [04:19<01:31,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 708/958 [04:19<01:31,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 709/958 [04:19<01:31,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 709/958 [04:19<01:31,  2.73it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 710/958 [04:19<01:30,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 710/958 [04:20<01:30,  2.74it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 711/958 [04:20<01:30,  2.74it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 711/958 [04:20<01:30,  2.74it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 712/958 [04:20<01:29,  2.74it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 712/958 [04:20<01:29,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 713/958 [04:20<01:29,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 713/958 [04:21<01:29,  2.73it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 714/958 [04:21<01:29,  2.72it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 714/958 [04:21<01:29,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 715/958 [04:21<01:28,  2.74it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 715/958 [04:21<01:28,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 716/958 [04:21<01:27,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 716/958 [04:22<01:27,  2.75it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 717/958 [04:22<01:28,  2.73it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 717/958 [04:22<01:28,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 718/958 [04:22<01:27,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 718/958 [04:23<01:27,  2.74it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 719/958 [04:23<01:26,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 719/958 [04:23<01:26,  2.75it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 720/958 [04:23<01:26,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 720/958 [04:23<01:26,  2.74it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 721/958 [04:23<01:26,  2.75it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 721/958 [04:24<01:26,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 722/958 [04:24<01:25,  2.77it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 722/958 [04:24<01:25,  2.77it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 723/958 [04:24<01:25,  2.76it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 723/958 [04:24<01:25,  2.76it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 724/958 [04:24<01:24,  2.78it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 724/958 [04:25<01:24,  2.78it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 725/958 [04:25<01:24,  2.75it/s, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 725/958 [04:25<01:24,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 726/958 [04:25<01:24,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 726/958 [04:25<01:24,  2.75it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 727/958 [04:25<01:24,  2.75it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 727/958 [04:26<01:24,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 728/958 [04:26<01:23,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 728/958 [04:26<01:23,  2.74it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 729/958 [04:26<01:23,  2.75it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 729/958 [04:27<01:23,  2.75it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 730/958 [04:27<01:22,  2.75it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 730/958 [04:27<01:22,  2.75it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 731/958 [04:27<01:22,  2.75it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 731/958 [04:27<01:22,  2.75it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 732/958 [04:27<01:21,  2.76it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 732/958 [04:28<01:21,  2.76it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 733/958 [04:28<01:21,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 733/958 [04:28<01:21,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 734/958 [04:28<01:21,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 734/958 [04:28<01:21,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 735/958 [04:28<01:21,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 735/958 [04:29<01:21,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 736/958 [04:29<01:20,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 736/958 [04:29<01:20,  2.75it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 737/958 [04:29<01:20,  2.74it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 737/958 [04:29<01:20,  2.74it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 738/958 [04:29<01:19,  2.76it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 738/958 [04:30<01:19,  2.76it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 739/958 [04:30<01:19,  2.75it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 739/958 [04:30<01:19,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 740/958 [04:30<01:19,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 740/958 [04:31<01:19,  2.74it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 741/958 [04:31<01:18,  2.75it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 741/958 [04:31<01:18,  2.75it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 742/958 [04:31<01:19,  2.71it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 742/958 [04:31<01:19,  2.71it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 743/958 [04:31<01:18,  2.74it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 743/958 [04:32<01:18,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 744/958 [04:32<01:17,  2.76it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 744/958 [04:32<01:17,  2.76it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 745/958 [04:32<01:17,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 745/958 [04:32<01:17,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 746/958 [04:32<01:16,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 746/958 [04:33<01:16,  2.75it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 747/958 [04:33<01:17,  2.72it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 747/958 [04:33<01:17,  2.72it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 748/958 [04:33<01:17,  2.72it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 748/958 [04:33<01:17,  2.72it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 749/958 [04:34<01:16,  2.72it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 749/958 [04:34<01:16,  2.72it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 750/958 [04:34<01:16,  2.71it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 750/958 [04:34<01:16,  2.71it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 751/958 [04:34<01:16,  2.72it/s, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 751/958 [04:35<01:16,  2.72it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 752/958 [04:35<01:15,  2.74it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 752/958 [04:35<01:15,  2.74it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 753/958 [04:35<01:15,  2.73it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 753/958 [04:35<01:15,  2.73it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 754/958 [04:35<01:14,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 754/958 [04:36<01:14,  2.74it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 755/958 [04:36<01:14,  2.74it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 755/958 [04:36<01:14,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 756/958 [04:36<01:13,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 756/958 [04:36<01:13,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 757/958 [04:36<01:13,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 757/958 [04:37<01:13,  2.74it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 758/958 [04:37<01:12,  2.75it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 758/958 [04:37<01:12,  2.75it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 759/958 [04:37<01:12,  2.76it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 759/958 [04:38<01:12,  2.76it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 760/958 [04:38<01:12,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 760/958 [04:38<01:12,  2.74it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 761/958 [04:38<01:11,  2.75it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 761/958 [04:38<01:11,  2.75it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 762/958 [04:38<01:11,  2.74it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 762/958 [04:39<01:11,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 763/958 [04:39<01:11,  2.72it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 763/958 [04:39<01:11,  2.72it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 764/958 [04:39<01:11,  2.72it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 764/958 [04:39<01:11,  2.72it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 765/958 [04:39<01:10,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 765/958 [04:40<01:10,  2.74it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 766/958 [04:40<01:09,  2.75it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 766/958 [04:40<01:09,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  80%|████████  | 767/958 [04:40<01:09,  2.76it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  80%|████████  | 767/958 [04:40<01:09,  2.76it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 1:  80%|████████  | 768/958 [04:40<01:09,  2.72it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 1:  80%|████████  | 768/958 [04:41<01:09,  2.72it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  80%|████████  | 769/958 [04:41<01:09,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  80%|████████  | 769/958 [04:41<01:09,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  80%|████████  | 770/958 [04:41<01:08,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  80%|████████  | 770/958 [04:42<01:08,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  80%|████████  | 771/958 [04:42<01:08,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  80%|████████  | 771/958 [04:42<01:08,  2.73it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  81%|████████  | 772/958 [04:42<01:07,  2.74it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  81%|████████  | 772/958 [04:42<01:07,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  81%|████████  | 773/958 [04:42<01:07,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  81%|████████  | 773/958 [04:43<01:07,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  81%|████████  | 774/958 [04:43<01:07,  2.74it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  81%|████████  | 774/958 [04:43<01:07,  2.74it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  81%|████████  | 775/958 [04:43<01:06,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  81%|████████  | 775/958 [04:43<01:06,  2.75it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 1:  81%|████████  | 776/958 [04:43<01:06,  2.74it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 1:  81%|████████  | 776/958 [04:44<01:06,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  81%|████████  | 777/958 [04:44<01:06,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  81%|████████  | 777/958 [04:44<01:06,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  81%|████████  | 778/958 [04:44<01:05,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  81%|████████  | 778/958 [04:44<01:05,  2.74it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 779/958 [04:44<01:05,  2.73it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 779/958 [04:45<01:05,  2.73it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 780/958 [04:45<01:04,  2.76it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 780/958 [04:45<01:04,  2.76it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 781/958 [04:45<01:04,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 781/958 [04:46<01:04,  2.75it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 782/958 [04:46<01:04,  2.75it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 782/958 [04:46<01:04,  2.75it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 783/958 [04:46<01:03,  2.75it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 783/958 [04:46<01:03,  2.75it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 784/958 [04:46<01:03,  2.74it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 784/958 [04:47<01:03,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 785/958 [04:47<01:03,  2.73it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 785/958 [04:47<01:03,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 786/958 [04:47<01:02,  2.76it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 786/958 [04:47<01:02,  2.76it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 787/958 [04:47<01:02,  2.74it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 787/958 [04:48<01:02,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 788/958 [04:48<01:02,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 788/958 [04:48<01:02,  2.74it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 789/958 [04:48<01:01,  2.74it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 789/958 [04:48<01:01,  2.74it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 790/958 [04:48<01:01,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 790/958 [04:49<01:01,  2.73it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 791/958 [04:49<01:01,  2.74it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 791/958 [04:49<01:01,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 792/958 [04:49<01:00,  2.73it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 792/958 [04:50<01:00,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 793/958 [04:50<01:00,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 793/958 [04:50<01:00,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 794/958 [04:50<00:59,  2.76it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 794/958 [04:50<00:59,  2.76it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 795/958 [04:50<00:59,  2.75it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 795/958 [04:51<00:59,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 796/958 [04:51<00:59,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 796/958 [04:51<00:59,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 797/958 [04:51<00:59,  2.72it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 797/958 [04:51<00:59,  2.72it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 798/958 [04:51<00:58,  2.73it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 798/958 [04:52<00:58,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 799/958 [04:52<00:58,  2.72it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 799/958 [04:52<00:58,  2.72it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 800/958 [04:52<00:57,  2.73it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 800/958 [04:52<00:57,  2.73it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 801/958 [04:52<00:57,  2.72it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 801/958 [04:53<00:57,  2.72it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 802/958 [04:53<00:57,  2.70it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 802/958 [04:53<00:57,  2.70it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 803/958 [04:53<00:56,  2.73it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 803/958 [04:54<00:56,  2.73it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 804/958 [04:54<00:56,  2.72it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 804/958 [04:54<00:56,  2.72it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 805/958 [04:54<00:56,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 805/958 [04:54<00:56,  2.73it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 806/958 [04:54<00:55,  2.74it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 806/958 [04:55<00:55,  2.74it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 807/958 [04:55<00:54,  2.75it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 807/958 [04:55<00:54,  2.75it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 808/958 [04:55<00:54,  2.75it/s, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 808/958 [04:55<00:54,  2.75it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 809/958 [04:55<00:54,  2.75it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 809/958 [04:56<00:54,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 810/958 [04:56<00:53,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 810/958 [04:56<00:53,  2.75it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 811/958 [04:56<00:53,  2.77it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 811/958 [04:56<00:53,  2.77it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 812/958 [04:56<00:52,  2.76it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 812/958 [04:57<00:52,  2.76it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 813/958 [04:57<00:52,  2.76it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 813/958 [04:57<00:52,  2.76it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 814/958 [04:57<00:52,  2.76it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 814/958 [04:58<00:52,  2.76it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 815/958 [04:58<00:51,  2.76it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 815/958 [04:58<00:51,  2.76it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 816/958 [04:58<00:51,  2.73it/s, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 816/958 [04:58<00:51,  2.73it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 817/958 [04:58<00:51,  2.73it/s, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 817/958 [04:59<00:51,  2.73it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 818/958 [04:59<00:51,  2.73it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 818/958 [04:59<00:51,  2.73it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 819/958 [04:59<00:50,  2.74it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 819/958 [04:59<00:50,  2.74it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 820/958 [04:59<00:50,  2.75it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 820/958 [05:00<00:50,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 821/958 [05:00<00:49,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 821/958 [05:00<00:49,  2.76it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 822/958 [05:00<00:49,  2.76it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 822/958 [05:00<00:49,  2.76it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 823/958 [05:01<00:49,  2.75it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 823/958 [05:01<00:49,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 824/958 [05:01<00:48,  2.77it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 824/958 [05:01<00:48,  2.77it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 825/958 [05:01<00:48,  2.76it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 825/958 [05:02<00:48,  2.76it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 826/958 [05:02<00:47,  2.75it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 826/958 [05:02<00:47,  2.75it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 827/958 [05:02<00:47,  2.76it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 827/958 [05:02<00:47,  2.76it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 828/958 [05:02<00:46,  2.77it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 828/958 [05:03<00:46,  2.77it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 829/958 [05:03<00:46,  2.77it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 829/958 [05:03<00:46,  2.77it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 830/958 [05:03<00:46,  2.75it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 830/958 [05:03<00:46,  2.75it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 831/958 [05:03<00:46,  2.74it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 831/958 [05:04<00:46,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 832/958 [05:04<00:46,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 832/958 [05:04<00:46,  2.73it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 833/958 [05:04<00:45,  2.73it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 833/958 [05:04<00:45,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 834/958 [05:05<00:45,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 834/958 [05:05<00:45,  2.73it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 835/958 [05:05<00:45,  2.71it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 835/958 [05:05<00:45,  2.71it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 836/958 [05:05<00:44,  2.74it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 836/958 [05:06<00:44,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 837/958 [05:06<00:44,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 837/958 [05:06<00:44,  2.73it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 838/958 [05:06<00:43,  2.74it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 838/958 [05:06<00:43,  2.74it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 839/958 [05:06<00:43,  2.76it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 839/958 [05:07<00:43,  2.76it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 840/958 [05:07<00:42,  2.76it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 840/958 [05:07<00:42,  2.76it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 841/958 [05:07<00:42,  2.77it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 841/958 [05:07<00:42,  2.77it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 842/958 [05:07<00:41,  2.77it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 842/958 [05:08<00:41,  2.77it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 843/958 [05:08<00:41,  2.76it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 843/958 [05:08<00:41,  2.76it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 844/958 [05:08<00:41,  2.76it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 844/958 [05:08<00:41,  2.76it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 845/958 [05:08<00:40,  2.76it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 845/958 [05:09<00:40,  2.76it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 846/958 [05:09<00:40,  2.75it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 846/958 [05:09<00:40,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 847/958 [05:09<00:40,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 847/958 [05:10<00:40,  2.75it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 848/958 [05:10<00:39,  2.75it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 848/958 [05:10<00:39,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 849/958 [05:10<00:39,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 849/958 [05:10<00:39,  2.73it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 850/958 [05:10<00:39,  2.74it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 850/958 [05:11<00:39,  2.74it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 851/958 [05:11<00:38,  2.75it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 851/958 [05:11<00:38,  2.75it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 852/958 [05:11<00:38,  2.74it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 852/958 [05:11<00:38,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 853/958 [05:11<00:38,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 853/958 [05:12<00:38,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 854/958 [05:12<00:37,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 854/958 [05:12<00:37,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 855/958 [05:12<00:38,  2.71it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 855/958 [05:13<00:38,  2.71it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 856/958 [05:13<00:37,  2.72it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 856/958 [05:13<00:37,  2.72it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 857/958 [05:13<00:36,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 857/958 [05:13<00:36,  2.74it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 858/958 [05:13<00:36,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 858/958 [05:14<00:36,  2.75it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 859/958 [05:14<00:36,  2.75it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 859/958 [05:14<00:36,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 860/958 [05:14<00:35,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 860/958 [05:14<00:35,  2.74it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 861/958 [05:14<00:35,  2.73it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 861/958 [05:15<00:35,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 862/958 [05:15<00:35,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 862/958 [05:15<00:35,  2.74it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 863/958 [05:15<00:34,  2.73it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 863/958 [05:15<00:34,  2.73it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 864/958 [05:15<00:34,  2.74it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 864/958 [05:16<00:34,  2.74it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 865/958 [05:16<00:34,  2.72it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 865/958 [05:16<00:34,  2.72it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 866/958 [05:16<00:33,  2.73it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 866/958 [05:17<00:33,  2.73it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 867/958 [05:17<00:33,  2.73it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 867/958 [05:17<00:33,  2.73it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 868/958 [05:17<00:33,  2.72it/s, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 868/958 [05:17<00:33,  2.72it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 869/958 [05:17<00:32,  2.70it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 869/958 [05:18<00:32,  2.70it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 870/958 [05:18<00:32,  2.72it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 870/958 [05:18<00:32,  2.72it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 871/958 [05:18<00:32,  2.71it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 871/958 [05:18<00:32,  2.71it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 872/958 [05:18<00:32,  2.68it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 872/958 [05:19<00:32,  2.68it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 873/958 [05:19<00:31,  2.70it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 873/958 [05:19<00:31,  2.70it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 874/958 [05:19<00:30,  2.71it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 874/958 [05:19<00:30,  2.71it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 875/958 [05:19<00:30,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 875/958 [05:20<00:30,  2.74it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 876/958 [05:20<00:30,  2.72it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 876/958 [05:20<00:30,  2.72it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 877/958 [05:20<00:29,  2.71it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 877/958 [05:21<00:29,  2.71it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 878/958 [05:21<00:29,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 878/958 [05:21<00:29,  2.73it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 879/958 [05:21<00:29,  2.72it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 879/958 [05:21<00:29,  2.72it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 880/958 [05:21<00:28,  2.72it/s, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 880/958 [05:22<00:28,  2.72it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 881/958 [05:22<00:28,  2.72it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 881/958 [05:22<00:28,  2.72it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 882/958 [05:22<00:27,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 882/958 [05:22<00:27,  2.73it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 883/958 [05:22<00:27,  2.72it/s, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 883/958 [05:23<00:27,  2.72it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 884/958 [05:23<00:27,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 884/958 [05:23<00:27,  2.73it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 885/958 [05:23<00:26,  2.74it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 885/958 [05:24<00:26,  2.74it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 886/958 [05:24<00:26,  2.74it/s, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 886/958 [05:24<00:26,  2.74it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 887/958 [05:24<00:25,  2.76it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 887/958 [05:24<00:25,  2.76it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 888/958 [05:24<00:25,  2.74it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 888/958 [05:25<00:25,  2.74it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 889/958 [05:25<00:25,  2.75it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 889/958 [05:25<00:25,  2.75it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 890/958 [05:25<00:24,  2.73it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 890/958 [05:25<00:24,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 891/958 [05:25<00:24,  2.72it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 891/958 [05:26<00:24,  2.72it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 892/958 [05:26<00:24,  2.72it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 892/958 [05:26<00:24,  2.72it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 893/958 [05:26<00:23,  2.72it/s, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 893/958 [05:26<00:23,  2.72it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 894/958 [05:26<00:23,  2.71it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 894/958 [05:27<00:23,  2.71it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 895/958 [05:27<00:23,  2.71it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 895/958 [05:27<00:23,  2.71it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 896/958 [05:27<00:22,  2.71it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 896/958 [05:28<00:22,  2.71it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 897/958 [05:28<00:22,  2.71it/s, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 897/958 [05:28<00:22,  2.71it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 898/958 [05:28<00:22,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 898/958 [05:28<00:22,  2.73it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 899/958 [05:28<00:21,  2.73it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 899/958 [05:29<00:21,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 900/958 [05:29<00:21,  2.71it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 900/958 [05:29<00:21,  2.71it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 901/958 [05:29<00:20,  2.73it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 901/958 [05:29<00:20,  2.73it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 902/958 [05:29<00:20,  2.75it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 902/958 [05:30<00:20,  2.75it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 903/958 [05:30<00:20,  2.74it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 903/958 [05:30<00:20,  2.74it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 904/958 [05:30<00:19,  2.73it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 904/958 [05:30<00:19,  2.73it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 905/958 [05:30<00:19,  2.73it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 905/958 [05:31<00:19,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 906/958 [05:31<00:19,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 906/958 [05:31<00:19,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 907/958 [05:31<00:18,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 907/958 [05:32<00:18,  2.73it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 908/958 [05:32<00:18,  2.70it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 908/958 [05:32<00:18,  2.70it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 909/958 [05:32<00:17,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 909/958 [05:32<00:17,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 910/958 [05:32<00:17,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 910/958 [05:33<00:17,  2.73it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 911/958 [05:33<00:17,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 911/958 [05:33<00:17,  2.75it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 912/958 [05:33<00:16,  2.75it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 912/958 [05:33<00:16,  2.75it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 913/958 [05:33<00:16,  2.76it/s, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 913/958 [05:34<00:16,  2.76it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 914/958 [05:34<00:15,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 914/958 [05:34<00:15,  2.75it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 915/958 [05:34<00:15,  2.75it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 915/958 [05:35<00:15,  2.75it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 916/958 [05:35<00:15,  2.75it/s, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 916/958 [05:35<00:15,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 917/958 [05:35<00:14,  2.76it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 917/958 [05:35<00:14,  2.76it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 918/958 [05:35<00:14,  2.77it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 918/958 [05:36<00:14,  2.77it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 919/958 [05:36<00:14,  2.76it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 919/958 [05:36<00:14,  2.76it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 920/958 [05:36<00:13,  2.77it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 920/958 [05:36<00:13,  2.77it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 921/958 [05:36<00:13,  2.77it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 921/958 [05:37<00:13,  2.77it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 922/958 [05:37<00:12,  2.77it/s, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 922/958 [05:37<00:12,  2.77it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 923/958 [05:37<00:12,  2.77it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 923/958 [05:37<00:12,  2.77it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 924/958 [05:37<00:12,  2.76it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 924/958 [05:38<00:12,  2.76it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 925/958 [05:38<00:11,  2.77it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 925/958 [05:38<00:11,  2.77it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 926/958 [05:38<00:11,  2.77it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 926/958 [05:38<00:11,  2.77it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 927/958 [05:38<00:11,  2.76it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 927/958 [05:39<00:11,  2.76it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 928/958 [05:39<00:10,  2.75it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 928/958 [05:39<00:10,  2.75it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 929/958 [05:39<00:10,  2.76it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 929/958 [05:40<00:10,  2.76it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 930/958 [05:40<00:10,  2.74it/s, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 930/958 [05:40<00:10,  2.74it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 931/958 [05:40<00:09,  2.75it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 931/958 [05:40<00:09,  2.75it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 932/958 [05:40<00:09,  2.76it/s, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 932/958 [05:41<00:09,  2.76it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 933/958 [05:41<00:09,  2.72it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 933/958 [05:41<00:09,  2.72it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 934/958 [05:41<00:08,  2.72it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 934/958 [05:41<00:08,  2.72it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 935/958 [05:41<00:08,  2.71it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 935/958 [05:42<00:08,  2.71it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 936/958 [05:42<00:08,  2.71it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 936/958 [05:42<00:08,  2.71it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 937/958 [05:42<00:07,  2.71it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 937/958 [05:43<00:07,  2.71it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 938/958 [05:43<00:07,  2.70it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 938/958 [05:43<00:07,  2.70it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 939/958 [05:43<00:06,  2.73it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 939/958 [05:43<00:06,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 940/958 [05:43<00:06,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 940/958 [05:44<00:06,  2.74it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 941/958 [05:44<00:06,  2.74it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 941/958 [05:44<00:06,  2.74it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 942/958 [05:44<00:05,  2.76it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 942/958 [05:44<00:05,  2.76it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 943/958 [05:44<00:05,  2.76it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 943/958 [05:45<00:05,  2.76it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 944/958 [05:45<00:05,  2.75it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 944/958 [05:45<00:05,  2.75it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 945/958 [05:45<00:04,  2.76it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 945/958 [05:45<00:04,  2.76it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 946/958 [05:45<00:04,  2.76it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 946/958 [05:46<00:04,  2.76it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 947/958 [05:46<00:04,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 947/958 [05:46<00:04,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 948/958 [05:46<00:03,  2.73it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 948/958 [05:47<00:03,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 949/958 [05:47<00:03,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 949/958 [05:47<00:03,  2.73it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 950/958 [05:47<00:02,  2.72it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 950/958 [05:47<00:02,  2.72it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 951/958 [05:47<00:02,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 951/958 [05:48<00:02,  2.73it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 952/958 [05:48<00:02,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 952/958 [05:48<00:02,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 953/958 [05:48<00:01,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 953/958 [05:48<00:01,  2.74it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 954/958 [05:48<00:01,  2.75it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 954/958 [05:49<00:01,  2.75it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 955/958 [05:49<00:01,  2.73it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 955/958 [05:49<00:01,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 956/958 [05:49<00:00,  2.72it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 956/958 [05:49<00:00,  2.72it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 957/958 [05:49<00:00,  2.72it/s, training_loss=0.198]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 957/958 [05:50<00:00,  2.72it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 1: 100%|██████████| 958/958 [05:50<00:00,  2.86it/s, training_loss=0.103]\u001b[A\n",
            "  0%|          | 0/10 [05:51<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1\n",
            "Training loss: 0.44553214980538214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0%|          | 0/320 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.225]\u001b[A\n",
            "\n",
            "  0%|          | 1/320 [00:00<00:34,  9.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.206]\u001b[A\n",
            "\n",
            "  1%|          | 2/320 [00:00<00:36,  8.68it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.196]\u001b[A\n",
            "\n",
            "  1%|          | 3/320 [00:00<00:37,  8.55it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.240]\u001b[A\n",
            "\n",
            "  1%|▏         | 4/320 [00:00<00:37,  8.46it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            "  2%|▏         | 5/320 [00:00<00:37,  8.40it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.224]\u001b[A\n",
            "\n",
            "  2%|▏         | 6/320 [00:00<00:37,  8.41it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            "  2%|▏         | 7/320 [00:00<00:37,  8.37it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.211]\u001b[A\n",
            "\n",
            "  2%|▎         | 8/320 [00:00<00:38,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            "  3%|▎         | 9/320 [00:01<00:38,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.240]\u001b[A\n",
            "\n",
            "  3%|▎         | 10/320 [00:01<00:37,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.230]\u001b[A\n",
            "\n",
            "  3%|▎         | 11/320 [00:01<00:37,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.125]\u001b[A\n",
            "\n",
            "  4%|▍         | 12/320 [00:01<00:36,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.252]\u001b[A\n",
            "\n",
            "  4%|▍         | 13/320 [00:01<00:37,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.152]\u001b[A\n",
            "\n",
            "  4%|▍         | 14/320 [00:01<00:36,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.137]\u001b[A\n",
            "\n",
            "  5%|▍         | 15/320 [00:01<00:36,  8.37it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.086]\u001b[A\n",
            "\n",
            "  5%|▌         | 16/320 [00:01<00:36,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            "  5%|▌         | 17/320 [00:02<00:36,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.228]\u001b[A\n",
            "\n",
            "  6%|▌         | 18/320 [00:02<00:36,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.286]\u001b[A\n",
            "\n",
            "  6%|▌         | 19/320 [00:02<00:36,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.110]\u001b[A\n",
            "\n",
            "  6%|▋         | 20/320 [00:02<00:36,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.204]\u001b[A\n",
            "\n",
            "  7%|▋         | 21/320 [00:02<00:36,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.163]\u001b[A\n",
            "\n",
            "  7%|▋         | 22/320 [00:02<00:36,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.166]\u001b[A\n",
            "\n",
            "  7%|▋         | 23/320 [00:02<00:36,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.123]\u001b[A\n",
            "\n",
            "  8%|▊         | 24/320 [00:02<00:36,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.123]\u001b[A\n",
            "\n",
            "  8%|▊         | 25/320 [00:03<00:35,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.147]\u001b[A\n",
            "\n",
            "  8%|▊         | 26/320 [00:03<00:35,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.188]\u001b[A\n",
            "\n",
            "  8%|▊         | 27/320 [00:03<00:35,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            "  9%|▉         | 28/320 [00:03<00:35,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.209]\u001b[A\n",
            "\n",
            "  9%|▉         | 29/320 [00:03<00:35,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.165]\u001b[A\n",
            "\n",
            "  9%|▉         | 30/320 [00:03<00:35,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.225]\u001b[A\n",
            "\n",
            " 10%|▉         | 31/320 [00:03<00:35,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.101]\u001b[A\n",
            "\n",
            " 10%|█         | 32/320 [00:03<00:34,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.217]\u001b[A\n",
            "\n",
            " 10%|█         | 33/320 [00:03<00:34,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.244]\u001b[A\n",
            "\n",
            " 11%|█         | 34/320 [00:04<00:34,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.147]\u001b[A\n",
            "\n",
            " 11%|█         | 35/320 [00:04<00:34,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.075]\u001b[A\n",
            "\n",
            " 11%|█▏        | 36/320 [00:04<00:34,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.100]\u001b[A\n",
            "\n",
            " 12%|█▏        | 37/320 [00:04<00:34,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.147]\u001b[A\n",
            "\n",
            " 12%|█▏        | 38/320 [00:04<00:33,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.265]\u001b[A\n",
            "\n",
            " 12%|█▏        | 39/320 [00:04<00:33,  8.32it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.168]\u001b[A\n",
            "\n",
            " 12%|█▎        | 40/320 [00:04<00:33,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.090]\u001b[A\n",
            "\n",
            " 13%|█▎        | 41/320 [00:04<00:33,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.184]\u001b[A\n",
            "\n",
            " 13%|█▎        | 42/320 [00:05<00:33,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 13%|█▎        | 43/320 [00:05<00:33,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.097]\u001b[A\n",
            "\n",
            " 14%|█▍        | 44/320 [00:05<00:33,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.213]\u001b[A\n",
            "\n",
            " 14%|█▍        | 45/320 [00:05<00:33,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.063]\u001b[A\n",
            "\n",
            " 14%|█▍        | 46/320 [00:05<00:33,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.140]\u001b[A\n",
            "\n",
            " 15%|█▍        | 47/320 [00:05<00:33,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.223]\u001b[A\n",
            "\n",
            " 15%|█▌        | 48/320 [00:05<00:32,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.359]\u001b[A\n",
            "\n",
            " 15%|█▌        | 49/320 [00:05<00:32,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.218]\u001b[A\n",
            "\n",
            " 16%|█▌        | 50/320 [00:06<00:32,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.181]\u001b[A\n",
            "\n",
            " 16%|█▌        | 51/320 [00:06<00:32,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.160]\u001b[A\n",
            "\n",
            " 16%|█▋        | 52/320 [00:06<00:32,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.100]\u001b[A\n",
            "\n",
            " 17%|█▋        | 53/320 [00:06<00:32,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.240]\u001b[A\n",
            "\n",
            " 17%|█▋        | 54/320 [00:06<00:32,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.104]\u001b[A\n",
            "\n",
            " 17%|█▋        | 55/320 [00:06<00:32,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.164]\u001b[A\n",
            "\n",
            " 18%|█▊        | 56/320 [00:06<00:32,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.144]\u001b[A\n",
            "\n",
            " 18%|█▊        | 57/320 [00:06<00:31,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.170]\u001b[A\n",
            "\n",
            " 18%|█▊        | 58/320 [00:07<00:31,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.110]\u001b[A\n",
            "\n",
            " 18%|█▊        | 59/320 [00:07<00:31,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.153]\u001b[A\n",
            "\n",
            " 19%|█▉        | 60/320 [00:07<00:31,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.173]\u001b[A\n",
            "\n",
            " 19%|█▉        | 61/320 [00:07<00:31,  8.32it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.305]\u001b[A\n",
            "\n",
            " 19%|█▉        | 62/320 [00:07<00:31,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 20%|█▉        | 63/320 [00:07<00:31,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.213]\u001b[A\n",
            "\n",
            " 20%|██        | 64/320 [00:07<00:31,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            " 20%|██        | 65/320 [00:07<00:31,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.175]\u001b[A\n",
            "\n",
            " 21%|██        | 66/320 [00:07<00:30,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.109]\u001b[A\n",
            "\n",
            " 21%|██        | 67/320 [00:08<00:31,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.208]\u001b[A\n",
            "\n",
            " 21%|██▏       | 68/320 [00:08<00:30,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.155]\u001b[A\n",
            "\n",
            " 22%|██▏       | 69/320 [00:08<00:30,  8.32it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.294]\u001b[A\n",
            "\n",
            " 22%|██▏       | 70/320 [00:08<00:29,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.212]\u001b[A\n",
            "\n",
            " 22%|██▏       | 71/320 [00:08<00:30,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.156]\u001b[A\n",
            "\n",
            " 22%|██▎       | 72/320 [00:08<00:30,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.360]\u001b[A\n",
            "\n",
            " 23%|██▎       | 73/320 [00:08<00:30,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.140]\u001b[A\n",
            "\n",
            " 23%|██▎       | 74/320 [00:08<00:30,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            " 23%|██▎       | 75/320 [00:09<00:30,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.086]\u001b[A\n",
            "\n",
            " 24%|██▍       | 76/320 [00:09<00:29,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.108]\u001b[A\n",
            "\n",
            " 24%|██▍       | 77/320 [00:09<00:29,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.286]\u001b[A\n",
            "\n",
            " 24%|██▍       | 78/320 [00:09<00:29,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.251]\u001b[A\n",
            "\n",
            " 25%|██▍       | 79/320 [00:09<00:29,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.124]\u001b[A\n",
            "\n",
            " 25%|██▌       | 80/320 [00:09<00:29,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.138]\u001b[A\n",
            "\n",
            " 25%|██▌       | 81/320 [00:09<00:29,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.182]\u001b[A\n",
            "\n",
            " 26%|██▌       | 82/320 [00:09<00:29,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.130]\u001b[A\n",
            "\n",
            " 26%|██▌       | 83/320 [00:10<00:28,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.164]\u001b[A\n",
            "\n",
            " 26%|██▋       | 84/320 [00:10<00:28,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.226]\u001b[A\n",
            "\n",
            " 27%|██▋       | 85/320 [00:10<00:28,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.141]\u001b[A\n",
            "\n",
            " 27%|██▋       | 86/320 [00:10<00:28,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 27%|██▋       | 87/320 [00:10<00:28,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 28%|██▊       | 88/320 [00:10<00:28,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.115]\u001b[A\n",
            "\n",
            " 28%|██▊       | 89/320 [00:10<00:28,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.268]\u001b[A\n",
            "\n",
            " 28%|██▊       | 90/320 [00:10<00:27,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.260]\u001b[A\n",
            "\n",
            " 28%|██▊       | 91/320 [00:11<00:27,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.168]\u001b[A\n",
            "\n",
            " 29%|██▉       | 92/320 [00:11<00:27,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.158]\u001b[A\n",
            "\n",
            " 29%|██▉       | 93/320 [00:11<00:27,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.104]\u001b[A\n",
            "\n",
            " 29%|██▉       | 94/320 [00:11<00:27,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.173]\u001b[A\n",
            "\n",
            " 30%|██▉       | 95/320 [00:11<00:27,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.203]\u001b[A\n",
            "\n",
            " 30%|███       | 96/320 [00:11<00:27,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.150]\u001b[A\n",
            "\n",
            " 30%|███       | 97/320 [00:11<00:27,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.085]\u001b[A\n",
            "\n",
            " 31%|███       | 98/320 [00:11<00:26,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.145]\u001b[A\n",
            "\n",
            " 31%|███       | 99/320 [00:11<00:26,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.168]\u001b[A\n",
            "\n",
            " 31%|███▏      | 100/320 [00:12<00:26,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.205]\u001b[A\n",
            "\n",
            " 32%|███▏      | 101/320 [00:12<00:26,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.127]\u001b[A\n",
            "\n",
            " 32%|███▏      | 102/320 [00:12<00:26,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            " 32%|███▏      | 103/320 [00:12<00:26,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.143]\u001b[A\n",
            "\n",
            " 32%|███▎      | 104/320 [00:12<00:26,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.196]\u001b[A\n",
            "\n",
            " 33%|███▎      | 105/320 [00:12<00:26,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.130]\u001b[A\n",
            "\n",
            " 33%|███▎      | 106/320 [00:12<00:25,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.139]\u001b[A\n",
            "\n",
            " 33%|███▎      | 107/320 [00:12<00:26,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.227]\u001b[A\n",
            "\n",
            " 34%|███▍      | 108/320 [00:13<00:25,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            " 34%|███▍      | 109/320 [00:13<00:25,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.100]\u001b[A\n",
            "\n",
            " 34%|███▍      | 110/320 [00:13<00:25,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.115]\u001b[A\n",
            "\n",
            " 35%|███▍      | 111/320 [00:13<00:25,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.088]\u001b[A\n",
            "\n",
            " 35%|███▌      | 112/320 [00:13<00:25,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.183]\u001b[A\n",
            "\n",
            " 35%|███▌      | 113/320 [00:13<00:25,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.123]\u001b[A\n",
            "\n",
            " 36%|███▌      | 114/320 [00:13<00:25,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            " 36%|███▌      | 115/320 [00:13<00:25,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.225]\u001b[A\n",
            "\n",
            " 36%|███▋      | 116/320 [00:14<00:25,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.162]\u001b[A\n",
            "\n",
            " 37%|███▋      | 117/320 [00:14<00:25,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.057]\u001b[A\n",
            "\n",
            " 37%|███▋      | 118/320 [00:14<00:24,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.096]\u001b[A\n",
            "\n",
            " 37%|███▋      | 119/320 [00:14<00:24,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.146]\u001b[A\n",
            "\n",
            " 38%|███▊      | 120/320 [00:14<00:24,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.325]\u001b[A\n",
            "\n",
            " 38%|███▊      | 121/320 [00:14<00:24,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.210]\u001b[A\n",
            "\n",
            " 38%|███▊      | 122/320 [00:14<00:24,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.152]\u001b[A\n",
            "\n",
            " 38%|███▊      | 123/320 [00:14<00:24,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.190]\u001b[A\n",
            "\n",
            " 39%|███▉      | 124/320 [00:15<00:24,  8.04it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.237]\u001b[A\n",
            "\n",
            " 39%|███▉      | 125/320 [00:15<00:23,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 39%|███▉      | 126/320 [00:15<00:23,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.362]\u001b[A\n",
            "\n",
            " 40%|███▉      | 127/320 [00:15<00:23,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.223]\u001b[A\n",
            "\n",
            " 40%|████      | 128/320 [00:15<00:23,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.222]\u001b[A\n",
            "\n",
            " 40%|████      | 129/320 [00:15<00:23,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.244]\u001b[A\n",
            "\n",
            " 41%|████      | 130/320 [00:15<00:23,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.146]\u001b[A\n",
            "\n",
            " 41%|████      | 131/320 [00:15<00:23,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.180]\u001b[A\n",
            "\n",
            " 41%|████▏     | 132/320 [00:16<00:22,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.141]\u001b[A\n",
            "\n",
            " 42%|████▏     | 133/320 [00:16<00:22,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.170]\u001b[A\n",
            "\n",
            " 42%|████▏     | 134/320 [00:16<00:22,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.262]\u001b[A\n",
            "\n",
            " 42%|████▏     | 135/320 [00:16<00:22,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.254]\u001b[A\n",
            "\n",
            " 42%|████▎     | 136/320 [00:16<00:22,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.220]\u001b[A\n",
            "\n",
            " 43%|████▎     | 137/320 [00:16<00:22,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 43%|████▎     | 138/320 [00:16<00:22,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.151]\u001b[A\n",
            "\n",
            " 43%|████▎     | 139/320 [00:16<00:22,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.247]\u001b[A\n",
            "\n",
            " 44%|████▍     | 140/320 [00:17<00:22,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.210]\u001b[A\n",
            "\n",
            " 44%|████▍     | 141/320 [00:17<00:21,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.200]\u001b[A\n",
            "\n",
            " 44%|████▍     | 142/320 [00:17<00:21,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.093]\u001b[A\n",
            "\n",
            " 45%|████▍     | 143/320 [00:17<00:21,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 45%|████▌     | 144/320 [00:17<00:21,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.202]\u001b[A\n",
            "\n",
            " 45%|████▌     | 145/320 [00:17<00:21,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.194]\u001b[A\n",
            "\n",
            " 46%|████▌     | 146/320 [00:17<00:21,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.222]\u001b[A\n",
            "\n",
            " 46%|████▌     | 147/320 [00:17<00:20,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.128]\u001b[A\n",
            "\n",
            " 46%|████▋     | 148/320 [00:17<00:20,  8.32it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.116]\u001b[A\n",
            "\n",
            " 47%|████▋     | 149/320 [00:18<00:20,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.232]\u001b[A\n",
            "\n",
            " 47%|████▋     | 150/320 [00:18<00:20,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.170]\u001b[A\n",
            "\n",
            " 47%|████▋     | 151/320 [00:18<00:20,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 48%|████▊     | 152/320 [00:18<00:20,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.149]\u001b[A\n",
            "\n",
            " 48%|████▊     | 153/320 [00:18<00:20,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 48%|████▊     | 154/320 [00:18<00:20,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.273]\u001b[A\n",
            "\n",
            " 48%|████▊     | 155/320 [00:18<00:20,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.130]\u001b[A\n",
            "\n",
            " 49%|████▉     | 156/320 [00:18<00:19,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.314]\u001b[A\n",
            "\n",
            " 49%|████▉     | 157/320 [00:19<00:20,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.048]\u001b[A\n",
            "\n",
            " 49%|████▉     | 158/320 [00:19<00:19,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.213]\u001b[A\n",
            "\n",
            " 50%|████▉     | 159/320 [00:19<00:19,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.141]\u001b[A\n",
            "\n",
            " 50%|█████     | 160/320 [00:19<00:19,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 50%|█████     | 161/320 [00:19<00:19,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.175]\u001b[A\n",
            "\n",
            " 51%|█████     | 162/320 [00:19<00:19,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 51%|█████     | 163/320 [00:19<00:19,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 51%|█████▏    | 164/320 [00:19<00:19,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.049]\u001b[A\n",
            "\n",
            " 52%|█████▏    | 165/320 [00:20<00:18,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.126]\u001b[A\n",
            "\n",
            " 52%|█████▏    | 166/320 [00:20<00:18,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.248]\u001b[A\n",
            "\n",
            " 52%|█████▏    | 167/320 [00:20<00:18,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 52%|█████▎    | 168/320 [00:20<00:18,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.187]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 169/320 [00:20<00:18,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.219]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 170/320 [00:20<00:18,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.204]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 171/320 [00:20<00:17,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.198]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 172/320 [00:20<00:17,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.233]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 173/320 [00:21<00:17,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.180]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 174/320 [00:21<00:17,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.273]\u001b[A\n",
            "\n",
            " 55%|█████▍    | 175/320 [00:21<00:17,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 55%|█████▌    | 176/320 [00:21<00:17,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.210]\u001b[A\n",
            "\n",
            " 55%|█████▌    | 177/320 [00:21<00:17,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.107]\u001b[A\n",
            "\n",
            " 56%|█████▌    | 178/320 [00:21<00:17,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.193]\u001b[A\n",
            "\n",
            " 56%|█████▌    | 179/320 [00:21<00:17,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.117]\u001b[A\n",
            "\n",
            " 56%|█████▋    | 180/320 [00:21<00:17,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.233]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 181/320 [00:21<00:17,  8.06it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.195]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 182/320 [00:22<00:16,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.102]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 183/320 [00:22<00:16,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.235]\u001b[A\n",
            "\n",
            " 57%|█████▊    | 184/320 [00:22<00:16,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.207]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 185/320 [00:22<00:16,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.083]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 186/320 [00:22<00:16,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.075]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 187/320 [00:22<00:15,  8.39it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.164]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 188/320 [00:22<00:15,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 189/320 [00:22<00:15,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.242]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 190/320 [00:23<00:15,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.220]\u001b[A\n",
            "\n",
            " 60%|█████▉    | 191/320 [00:23<00:15,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.261]\u001b[A\n",
            "\n",
            " 60%|██████    | 192/320 [00:23<00:15,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.179]\u001b[A\n",
            "\n",
            " 60%|██████    | 193/320 [00:23<00:15,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.299]\u001b[A\n",
            "\n",
            " 61%|██████    | 194/320 [00:23<00:15,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.175]\u001b[A\n",
            "\n",
            " 61%|██████    | 195/320 [00:23<00:15,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.212]\u001b[A\n",
            "\n",
            " 61%|██████▏   | 196/320 [00:23<00:14,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.146]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 197/320 [00:23<00:14,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.129]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 198/320 [00:24<00:14,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.133]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 199/320 [00:24<00:14,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.217]\u001b[A\n",
            "\n",
            " 62%|██████▎   | 200/320 [00:24<00:14,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.198]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 201/320 [00:24<00:14,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.189]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 202/320 [00:24<00:14,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.272]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 203/320 [00:24<00:14,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.076]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 204/320 [00:24<00:14,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.230]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 205/320 [00:24<00:13,  8.32it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.063]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 206/320 [00:25<00:13,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.220]\u001b[A\n",
            "\n",
            " 65%|██████▍   | 207/320 [00:25<00:13,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.085]\u001b[A\n",
            "\n",
            " 65%|██████▌   | 208/320 [00:25<00:13,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.099]\u001b[A\n",
            "\n",
            " 65%|██████▌   | 209/320 [00:25<00:13,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.271]\u001b[A\n",
            "\n",
            " 66%|██████▌   | 210/320 [00:25<00:13,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.152]\u001b[A\n",
            "\n",
            " 66%|██████▌   | 211/320 [00:25<00:13,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.140]\u001b[A\n",
            "\n",
            " 66%|██████▋   | 212/320 [00:25<00:13,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.189]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 213/320 [00:25<00:12,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.127]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 214/320 [00:26<00:12,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.144]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 215/320 [00:26<00:12,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.100]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 216/320 [00:26<00:12,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.088]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 217/320 [00:26<00:12,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.102]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 218/320 [00:26<00:12,  8.01it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.157]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 219/320 [00:26<00:12,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.081]\u001b[A\n",
            "\n",
            " 69%|██████▉   | 220/320 [00:26<00:12,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.110]\u001b[A\n",
            "\n",
            " 69%|██████▉   | 221/320 [00:26<00:11,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.143]\u001b[A\n",
            "\n",
            " 69%|██████▉   | 222/320 [00:26<00:11,  8.36it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 70%|██████▉   | 223/320 [00:27<00:11,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.159]\u001b[A\n",
            "\n",
            " 70%|███████   | 224/320 [00:27<00:11,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.132]\u001b[A\n",
            "\n",
            " 70%|███████   | 225/320 [00:27<00:11,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.128]\u001b[A\n",
            "\n",
            " 71%|███████   | 226/320 [00:27<00:11,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.108]\u001b[A\n",
            "\n",
            " 71%|███████   | 227/320 [00:27<00:11,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.131]\u001b[A\n",
            "\n",
            " 71%|███████▏  | 228/320 [00:27<00:11,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 229/320 [00:27<00:11,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.305]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 230/320 [00:27<00:11,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.083]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 231/320 [00:28<00:10,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.159]\u001b[A\n",
            "\n",
            " 72%|███████▎  | 232/320 [00:28<00:10,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.145]\u001b[A\n",
            "\n",
            " 73%|███████▎  | 233/320 [00:28<00:10,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.176]\u001b[A\n",
            "\n",
            " 73%|███████▎  | 234/320 [00:28<00:10,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.139]\u001b[A\n",
            "\n",
            " 73%|███████▎  | 235/320 [00:28<00:10,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.174]\u001b[A\n",
            "\n",
            " 74%|███████▍  | 236/320 [00:28<00:10,  8.03it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.090]\u001b[A\n",
            "\n",
            " 74%|███████▍  | 237/320 [00:28<00:10,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.125]\u001b[A\n",
            "\n",
            " 74%|███████▍  | 238/320 [00:28<00:10,  8.06it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 75%|███████▍  | 239/320 [00:29<00:09,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.278]\u001b[A\n",
            "\n",
            " 75%|███████▌  | 240/320 [00:29<00:09,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.254]\u001b[A\n",
            "\n",
            " 75%|███████▌  | 241/320 [00:29<00:09,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.194]\u001b[A\n",
            "\n",
            " 76%|███████▌  | 242/320 [00:29<00:09,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.261]\u001b[A\n",
            "\n",
            " 76%|███████▌  | 243/320 [00:29<00:09,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.146]\u001b[A\n",
            "\n",
            " 76%|███████▋  | 244/320 [00:29<00:09,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 77%|███████▋  | 245/320 [00:29<00:09,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.256]\u001b[A\n",
            "\n",
            " 77%|███████▋  | 246/320 [00:29<00:09,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.097]\u001b[A\n",
            "\n",
            " 77%|███████▋  | 247/320 [00:30<00:08,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 248/320 [00:30<00:08,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 249/320 [00:30<00:08,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.092]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 250/320 [00:30<00:08,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.263]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 251/320 [00:30<00:08,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.125]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 252/320 [00:30<00:08,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.156]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 253/320 [00:30<00:08,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.194]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 254/320 [00:30<00:08,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.179]\u001b[A\n",
            "\n",
            " 80%|███████▉  | 255/320 [00:31<00:08,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.247]\u001b[A\n",
            "\n",
            " 80%|████████  | 256/320 [00:31<00:07,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.234]\u001b[A\n",
            "\n",
            " 80%|████████  | 257/320 [00:31<00:07,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.137]\u001b[A\n",
            "\n",
            " 81%|████████  | 258/320 [00:31<00:07,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.181]\u001b[A\n",
            "\n",
            " 81%|████████  | 259/320 [00:31<00:07,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.080]\u001b[A\n",
            "\n",
            " 81%|████████▏ | 260/320 [00:31<00:07,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.087]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 261/320 [00:31<00:07,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.214]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 262/320 [00:31<00:07,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 263/320 [00:31<00:06,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.208]\u001b[A\n",
            "\n",
            " 82%|████████▎ | 264/320 [00:32<00:06,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.158]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 265/320 [00:32<00:06,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 266/320 [00:32<00:06,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.152]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 267/320 [00:32<00:06,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.189]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 268/320 [00:32<00:06,  8.02it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.163]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 269/320 [00:32<00:06,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.126]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 270/320 [00:32<00:06,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.246]\u001b[A\n",
            "\n",
            " 85%|████████▍ | 271/320 [00:32<00:05,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.114]\u001b[A\n",
            "\n",
            " 85%|████████▌ | 272/320 [00:33<00:05,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.288]\u001b[A\n",
            "\n",
            " 85%|████████▌ | 273/320 [00:33<00:05,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.256]\u001b[A\n",
            "\n",
            " 86%|████████▌ | 274/320 [00:33<00:05,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.213]\u001b[A\n",
            "\n",
            " 86%|████████▌ | 275/320 [00:33<00:05,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.098]\u001b[A\n",
            "\n",
            " 86%|████████▋ | 276/320 [00:33<00:05,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.142]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 277/320 [00:33<00:05,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 278/320 [00:33<00:05,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.205]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 279/320 [00:33<00:04,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.108]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 280/320 [00:34<00:04,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.128]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 281/320 [00:34<00:04,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.141]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 282/320 [00:34<00:04,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.234]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 283/320 [00:34<00:04,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.158]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 284/320 [00:34<00:04,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.094]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 285/320 [00:34<00:04,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.320]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 286/320 [00:34<00:04,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            " 90%|████████▉ | 287/320 [00:34<00:04,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.079]\u001b[A\n",
            "\n",
            " 90%|█████████ | 288/320 [00:35<00:03,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 90%|█████████ | 289/320 [00:35<00:03,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.127]\u001b[A\n",
            "\n",
            " 91%|█████████ | 290/320 [00:35<00:03,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.158]\u001b[A\n",
            "\n",
            " 91%|█████████ | 291/320 [00:35<00:03,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.114]\u001b[A\n",
            "\n",
            " 91%|█████████▏| 292/320 [00:35<00:03,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.288]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 293/320 [00:35<00:03,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.173]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 294/320 [00:35<00:03,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.247]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 295/320 [00:35<00:03,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.197]\u001b[A\n",
            "\n",
            " 92%|█████████▎| 296/320 [00:35<00:02,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.130]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 297/320 [00:36<00:02,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.170]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 298/320 [00:36<00:02,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.266]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 299/320 [00:36<00:02,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.186]\u001b[A\n",
            "\n",
            " 94%|█████████▍| 300/320 [00:36<00:02,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.165]\u001b[A\n",
            "\n",
            " 94%|█████████▍| 301/320 [00:36<00:02,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 94%|█████████▍| 302/320 [00:36<00:02,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.201]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 303/320 [00:36<00:02,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.129]\u001b[A\n",
            "\n",
            " 95%|█████████▌| 304/320 [00:36<00:01,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.152]\u001b[A\n",
            "\n",
            " 95%|█████████▌| 305/320 [00:37<00:01,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.141]\u001b[A\n",
            "\n",
            " 96%|█████████▌| 306/320 [00:37<00:01,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.144]\u001b[A\n",
            "\n",
            " 96%|█████████▌| 307/320 [00:37<00:01,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.120]\u001b[A\n",
            "\n",
            " 96%|█████████▋| 308/320 [00:37<00:01,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.204]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 309/320 [00:37<00:01,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.194]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 310/320 [00:37<00:01,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.093]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 311/320 [00:37<00:01,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.167]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 312/320 [00:37<00:00,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.118]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 313/320 [00:38<00:00,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.232]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 314/320 [00:38<00:00,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.155]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 315/320 [00:38<00:00,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.135]\u001b[A\n",
            "\n",
            " 99%|█████████▉| 316/320 [00:38<00:00,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.176]\u001b[A\n",
            "\n",
            " 99%|█████████▉| 317/320 [00:38<00:00,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.142]\u001b[A\n",
            "\n",
            " 99%|█████████▉| 318/320 [00:38<00:00,  8.04it/s]\u001b[A\u001b[A\n",
            "Epoch 1:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.203]\u001b[A\n",
            "\n",
            "100%|█████████▉| 319/320 [00:38<00:00,  8.18it/s]\u001b[A\u001b[A\n",
            "100%|██████████| 320/320 [00:38<00:00,  8.24it/s]\n",
            "\n",
            "  0%|          | 0/10 [06:30<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.520963943330571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [06:32<58:48, 392.10s/it]\n",
            "Epoch 2:   0%|          | 0/958 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/958 [00:00<?, ?it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:   0%|          | 1/958 [00:00<05:44,  2.78it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:   0%|          | 1/958 [00:00<05:44,  2.78it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:   0%|          | 2/958 [00:00<05:41,  2.80it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:   0%|          | 2/958 [00:01<05:41,  2.80it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:   0%|          | 3/958 [00:01<05:46,  2.76it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:   0%|          | 3/958 [00:01<05:46,  2.76it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:   0%|          | 4/958 [00:01<05:45,  2.76it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:   0%|          | 4/958 [00:01<05:45,  2.76it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:   1%|          | 5/958 [00:01<05:42,  2.78it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:   1%|          | 5/958 [00:02<05:42,  2.78it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   1%|          | 6/958 [00:02<05:44,  2.77it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   1%|          | 6/958 [00:02<05:44,  2.77it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:   1%|          | 7/958 [00:02<05:46,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:   1%|          | 7/958 [00:02<05:46,  2.75it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:   1%|          | 8/958 [00:02<05:46,  2.74it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:   1%|          | 8/958 [00:03<05:46,  2.74it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   1%|          | 9/958 [00:03<05:46,  2.74it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   1%|          | 9/958 [00:03<05:46,  2.74it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:   1%|          | 10/958 [00:03<05:46,  2.74it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:   1%|          | 10/958 [00:03<05:46,  2.74it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   1%|          | 11/958 [00:03<05:44,  2.75it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   1%|          | 11/958 [00:04<05:44,  2.75it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   1%|▏         | 12/958 [00:04<05:45,  2.74it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   1%|▏         | 12/958 [00:04<05:45,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   1%|▏         | 13/958 [00:04<05:46,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   1%|▏         | 13/958 [00:05<05:46,  2.73it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   1%|▏         | 14/958 [00:05<05:46,  2.72it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   1%|▏         | 14/958 [00:05<05:46,  2.72it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:   2%|▏         | 15/958 [00:05<05:46,  2.72it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:   2%|▏         | 15/958 [00:05<05:46,  2.72it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:   2%|▏         | 16/958 [00:05<05:45,  2.73it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:   2%|▏         | 16/958 [00:06<05:45,  2.73it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:   2%|▏         | 17/958 [00:06<05:44,  2.73it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:   2%|▏         | 17/958 [00:06<05:44,  2.73it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:   2%|▏         | 18/958 [00:06<05:43,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:   2%|▏         | 18/958 [00:06<05:43,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:   2%|▏         | 19/958 [00:06<05:42,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:   2%|▏         | 19/958 [00:07<05:42,  2.74it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 2:   2%|▏         | 20/958 [00:07<05:42,  2.74it/s, training_loss=0.261]\u001b[A\n",
            "Epoch 2:   2%|▏         | 20/958 [00:07<05:42,  2.74it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   2%|▏         | 21/958 [00:07<05:43,  2.73it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   2%|▏         | 21/958 [00:08<05:43,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:   2%|▏         | 22/958 [00:08<05:41,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:   2%|▏         | 22/958 [00:08<05:41,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:   2%|▏         | 23/958 [00:08<05:41,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:   2%|▏         | 23/958 [00:08<05:41,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   3%|▎         | 24/958 [00:08<05:41,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   3%|▎         | 24/958 [00:09<05:41,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   3%|▎         | 25/958 [00:09<05:43,  2.72it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   3%|▎         | 25/958 [00:09<05:43,  2.72it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:   3%|▎         | 26/958 [00:09<05:43,  2.71it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:   3%|▎         | 26/958 [00:09<05:43,  2.71it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   3%|▎         | 27/958 [00:09<05:43,  2.71it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   3%|▎         | 27/958 [00:10<05:43,  2.71it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   3%|▎         | 28/958 [00:10<05:41,  2.72it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:   3%|▎         | 28/958 [00:10<05:41,  2.72it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:   3%|▎         | 29/958 [00:10<05:41,  2.72it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:   3%|▎         | 29/958 [00:10<05:41,  2.72it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:   3%|▎         | 30/958 [00:10<05:40,  2.73it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:   3%|▎         | 30/958 [00:11<05:40,  2.73it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:   3%|▎         | 31/958 [00:11<05:41,  2.72it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:   3%|▎         | 31/958 [00:11<05:41,  2.72it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:   3%|▎         | 32/958 [00:11<05:42,  2.70it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:   3%|▎         | 32/958 [00:12<05:42,  2.70it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:   3%|▎         | 33/958 [00:12<05:40,  2.72it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:   3%|▎         | 33/958 [00:12<05:40,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:   4%|▎         | 34/958 [00:12<05:39,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:   4%|▎         | 34/958 [00:12<05:39,  2.72it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:   4%|▎         | 35/958 [00:12<05:39,  2.72it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:   4%|▎         | 35/958 [00:13<05:39,  2.72it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:   4%|▍         | 36/958 [00:13<05:38,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:   4%|▍         | 36/958 [00:13<05:38,  2.73it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   4%|▍         | 37/958 [00:13<05:37,  2.73it/s, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   4%|▍         | 37/958 [00:13<05:37,  2.73it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:   4%|▍         | 38/958 [00:13<05:38,  2.72it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:   4%|▍         | 38/958 [00:14<05:38,  2.72it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:   4%|▍         | 39/958 [00:14<05:37,  2.72it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:   4%|▍         | 39/958 [00:14<05:37,  2.72it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   4%|▍         | 40/958 [00:14<05:36,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   4%|▍         | 40/958 [00:14<05:36,  2.73it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:   4%|▍         | 41/958 [00:15<05:35,  2.74it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:   4%|▍         | 41/958 [00:15<05:35,  2.74it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:   4%|▍         | 42/958 [00:15<05:33,  2.75it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:   4%|▍         | 42/958 [00:15<05:33,  2.75it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:   4%|▍         | 43/958 [00:15<05:33,  2.75it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:   4%|▍         | 43/958 [00:16<05:33,  2.75it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:   5%|▍         | 44/958 [00:16<05:34,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:   5%|▍         | 44/958 [00:16<05:34,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:   5%|▍         | 45/958 [00:16<05:36,  2.71it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:   5%|▍         | 45/958 [00:16<05:36,  2.71it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   5%|▍         | 46/958 [00:16<05:36,  2.71it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   5%|▍         | 46/958 [00:17<05:36,  2.71it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:   5%|▍         | 47/958 [00:17<05:35,  2.71it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:   5%|▍         | 47/958 [00:17<05:35,  2.71it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:   5%|▌         | 48/958 [00:17<05:35,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:   5%|▌         | 48/958 [00:17<05:35,  2.72it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:   5%|▌         | 49/958 [00:17<05:35,  2.71it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:   5%|▌         | 49/958 [00:18<05:35,  2.71it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:   5%|▌         | 50/958 [00:18<05:33,  2.72it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:   5%|▌         | 50/958 [00:18<05:33,  2.72it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:   5%|▌         | 51/958 [00:18<05:32,  2.73it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:   5%|▌         | 51/958 [00:19<05:32,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   5%|▌         | 52/958 [00:19<05:32,  2.72it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:   5%|▌         | 52/958 [00:19<05:32,  2.72it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:   6%|▌         | 53/958 [00:19<05:33,  2.72it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:   6%|▌         | 53/958 [00:19<05:33,  2.72it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:   6%|▌         | 54/958 [00:19<05:34,  2.70it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:   6%|▌         | 54/958 [00:20<05:34,  2.70it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   6%|▌         | 55/958 [00:20<05:33,  2.71it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   6%|▌         | 55/958 [00:20<05:33,  2.71it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   6%|▌         | 56/958 [00:20<05:31,  2.72it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   6%|▌         | 56/958 [00:20<05:31,  2.72it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:   6%|▌         | 57/958 [00:20<05:29,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:   6%|▌         | 57/958 [00:21<05:29,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:   6%|▌         | 58/958 [00:21<05:27,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:   6%|▌         | 58/958 [00:21<05:27,  2.74it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:   6%|▌         | 59/958 [00:21<05:29,  2.73it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:   6%|▌         | 59/958 [00:21<05:29,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:   6%|▋         | 60/958 [00:21<05:28,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:   6%|▋         | 60/958 [00:22<05:28,  2.73it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   6%|▋         | 61/958 [00:22<05:26,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   6%|▋         | 61/958 [00:22<05:26,  2.75it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   6%|▋         | 62/958 [00:22<05:26,  2.75it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   6%|▋         | 62/958 [00:23<05:26,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:   7%|▋         | 63/958 [00:23<05:24,  2.76it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:   7%|▋         | 63/958 [00:23<05:24,  2.76it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:   7%|▋         | 64/958 [00:23<05:24,  2.75it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:   7%|▋         | 64/958 [00:23<05:24,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:   7%|▋         | 65/958 [00:23<05:26,  2.73it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:   7%|▋         | 65/958 [00:24<05:26,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   7%|▋         | 66/958 [00:24<05:24,  2.75it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:   7%|▋         | 66/958 [00:24<05:24,  2.75it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:   7%|▋         | 67/958 [00:24<05:25,  2.74it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:   7%|▋         | 67/958 [00:24<05:25,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:   7%|▋         | 68/958 [00:24<05:28,  2.71it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:   7%|▋         | 68/958 [00:25<05:28,  2.71it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   7%|▋         | 69/958 [00:25<05:26,  2.72it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   7%|▋         | 69/958 [00:25<05:26,  2.72it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:   7%|▋         | 70/958 [00:25<05:24,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:   7%|▋         | 70/958 [00:25<05:24,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:   7%|▋         | 71/958 [00:26<05:24,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:   7%|▋         | 71/958 [00:26<05:24,  2.73it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:   8%|▊         | 72/958 [00:26<05:24,  2.73it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:   8%|▊         | 72/958 [00:26<05:24,  2.73it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:   8%|▊         | 73/958 [00:26<05:24,  2.73it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:   8%|▊         | 73/958 [00:27<05:24,  2.73it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:   8%|▊         | 74/958 [00:27<05:24,  2.73it/s, training_loss=0.257]\u001b[A\n",
            "Epoch 2:   8%|▊         | 74/958 [00:27<05:24,  2.73it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   8%|▊         | 75/958 [00:27<05:23,  2.73it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   8%|▊         | 75/958 [00:27<05:23,  2.73it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   8%|▊         | 76/958 [00:27<05:22,  2.73it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   8%|▊         | 76/958 [00:28<05:22,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   8%|▊         | 77/958 [00:28<05:21,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:   8%|▊         | 77/958 [00:28<05:21,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   8%|▊         | 78/958 [00:28<05:22,  2.72it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   8%|▊         | 78/958 [00:28<05:22,  2.72it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   8%|▊         | 79/958 [00:28<05:23,  2.72it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:   8%|▊         | 79/958 [00:29<05:23,  2.72it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:   8%|▊         | 80/958 [00:29<05:23,  2.72it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:   8%|▊         | 80/958 [00:29<05:23,  2.72it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:   8%|▊         | 81/958 [00:29<05:23,  2.71it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:   8%|▊         | 81/958 [00:30<05:23,  2.71it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:   9%|▊         | 82/958 [00:30<05:22,  2.72it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:   9%|▊         | 82/958 [00:30<05:22,  2.72it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:   9%|▊         | 83/958 [00:30<05:20,  2.73it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:   9%|▊         | 83/958 [00:30<05:20,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:   9%|▉         | 84/958 [00:30<05:20,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:   9%|▉         | 84/958 [00:31<05:20,  2.73it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   9%|▉         | 85/958 [00:31<05:20,  2.72it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   9%|▉         | 85/958 [00:31<05:20,  2.72it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:   9%|▉         | 86/958 [00:31<05:22,  2.71it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:   9%|▉         | 86/958 [00:31<05:22,  2.71it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:   9%|▉         | 87/958 [00:31<05:19,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:   9%|▉         | 87/958 [00:32<05:19,  2.73it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   9%|▉         | 88/958 [00:32<05:22,  2.70it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   9%|▉         | 88/958 [00:32<05:22,  2.70it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:   9%|▉         | 89/958 [00:32<05:24,  2.68it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:   9%|▉         | 89/958 [00:32<05:24,  2.68it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:   9%|▉         | 90/958 [00:33<05:23,  2.68it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:   9%|▉         | 90/958 [00:33<05:23,  2.68it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   9%|▉         | 91/958 [00:33<05:23,  2.68it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   9%|▉         | 91/958 [00:33<05:23,  2.68it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  10%|▉         | 92/958 [00:33<05:22,  2.69it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  10%|▉         | 92/958 [00:34<05:22,  2.69it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  10%|▉         | 93/958 [00:34<05:20,  2.70it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  10%|▉         | 93/958 [00:34<05:20,  2.70it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  10%|▉         | 94/958 [00:34<05:20,  2.70it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  10%|▉         | 94/958 [00:34<05:20,  2.70it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  10%|▉         | 95/958 [00:34<05:20,  2.69it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  10%|▉         | 95/958 [00:35<05:20,  2.69it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  10%|█         | 96/958 [00:35<05:18,  2.70it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  10%|█         | 96/958 [00:35<05:18,  2.70it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  10%|█         | 97/958 [00:35<05:15,  2.73it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  10%|█         | 97/958 [00:35<05:15,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  10%|█         | 98/958 [00:35<05:15,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  10%|█         | 98/958 [00:36<05:15,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  10%|█         | 99/958 [00:36<05:13,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  10%|█         | 99/958 [00:36<05:13,  2.74it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  10%|█         | 100/958 [00:36<05:11,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  10%|█         | 100/958 [00:37<05:11,  2.75it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  11%|█         | 101/958 [00:37<05:15,  2.72it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  11%|█         | 101/958 [00:37<05:15,  2.72it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  11%|█         | 102/958 [00:37<05:13,  2.73it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  11%|█         | 102/958 [00:37<05:13,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  11%|█         | 103/958 [00:37<05:13,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  11%|█         | 103/958 [00:38<05:13,  2.73it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  11%|█         | 104/958 [00:38<05:13,  2.72it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  11%|█         | 104/958 [00:38<05:13,  2.72it/s, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  11%|█         | 105/958 [00:38<05:13,  2.72it/s, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  11%|█         | 105/958 [00:38<05:13,  2.72it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  11%|█         | 106/958 [00:38<05:12,  2.73it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  11%|█         | 106/958 [00:39<05:12,  2.73it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  11%|█         | 107/958 [00:39<05:14,  2.71it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  11%|█         | 107/958 [00:39<05:14,  2.71it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 108/958 [00:39<05:13,  2.71it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 108/958 [00:39<05:13,  2.71it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 109/958 [00:39<05:12,  2.72it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 109/958 [00:40<05:12,  2.72it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 110/958 [00:40<05:14,  2.70it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 110/958 [00:40<05:14,  2.70it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 111/958 [00:40<05:12,  2.71it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 111/958 [00:41<05:12,  2.71it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 112/958 [00:41<05:11,  2.72it/s, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 112/958 [00:41<05:11,  2.72it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 113/958 [00:41<05:12,  2.70it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 113/958 [00:41<05:12,  2.70it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 114/958 [00:41<05:11,  2.71it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 114/958 [00:42<05:11,  2.71it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 115/958 [00:42<05:10,  2.71it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 115/958 [00:42<05:10,  2.71it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 116/958 [00:42<05:10,  2.71it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 116/958 [00:42<05:10,  2.71it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 117/958 [00:42<05:08,  2.73it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 117/958 [00:43<05:08,  2.73it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 118/958 [00:43<05:06,  2.74it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 118/958 [00:43<05:06,  2.74it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 119/958 [00:43<05:05,  2.75it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 119/958 [00:44<05:05,  2.75it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 120/958 [00:44<05:06,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 120/958 [00:44<05:06,  2.73it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 121/958 [00:44<05:06,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 121/958 [00:44<05:06,  2.74it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 122/958 [00:44<05:06,  2.73it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 122/958 [00:45<05:06,  2.73it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 123/958 [00:45<05:06,  2.72it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 123/958 [00:45<05:06,  2.72it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 124/958 [00:45<05:05,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 124/958 [00:45<05:05,  2.73it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 125/958 [00:45<05:05,  2.72it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 125/958 [00:46<05:05,  2.72it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 126/958 [00:46<05:05,  2.73it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 126/958 [00:46<05:05,  2.73it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 127/958 [00:46<05:03,  2.74it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 127/958 [00:46<05:03,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 128/958 [00:46<05:02,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 128/958 [00:47<05:02,  2.75it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 129/958 [00:47<05:04,  2.73it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 129/958 [00:47<05:04,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 130/958 [00:47<05:00,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 130/958 [00:48<05:00,  2.75it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 131/958 [00:48<05:00,  2.75it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 131/958 [00:48<05:00,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 132/958 [00:48<05:02,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 132/958 [00:48<05:02,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 133/958 [00:48<05:01,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 133/958 [00:49<05:01,  2.74it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 134/958 [00:49<05:01,  2.74it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 134/958 [00:49<05:01,  2.74it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 135/958 [00:49<05:01,  2.73it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 135/958 [00:49<05:01,  2.73it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 136/958 [00:49<04:59,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 136/958 [00:50<04:59,  2.74it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 137/958 [00:50<05:02,  2.71it/s, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 137/958 [00:50<05:02,  2.71it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 138/958 [00:50<05:02,  2.71it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 138/958 [00:50<05:02,  2.71it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 139/958 [00:51<05:00,  2.73it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 139/958 [00:51<05:00,  2.73it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 140/958 [00:51<05:01,  2.71it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 140/958 [00:51<05:01,  2.71it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 141/958 [00:51<05:00,  2.72it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 141/958 [00:52<05:00,  2.72it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 142/958 [00:52<05:00,  2.71it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 142/958 [00:52<05:00,  2.71it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 143/958 [00:52<05:00,  2.71it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 143/958 [00:52<05:00,  2.71it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 144/958 [00:52<05:00,  2.71it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 144/958 [00:53<05:00,  2.71it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 145/958 [00:53<04:58,  2.72it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 145/958 [00:53<04:58,  2.72it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 146/958 [00:53<04:58,  2.72it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 146/958 [00:53<04:58,  2.72it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 147/958 [00:53<04:56,  2.73it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 147/958 [00:54<04:56,  2.73it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 148/958 [00:54<04:57,  2.73it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 148/958 [00:54<04:57,  2.73it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 149/958 [00:54<04:57,  2.72it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 149/958 [00:55<04:57,  2.72it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 150/958 [00:55<04:56,  2.73it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 150/958 [00:55<04:56,  2.73it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 151/958 [00:55<04:54,  2.74it/s, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 151/958 [00:55<04:54,  2.74it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 152/958 [00:55<04:52,  2.75it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 152/958 [00:56<04:52,  2.75it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 153/958 [00:56<04:52,  2.75it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 153/958 [00:56<04:52,  2.75it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 154/958 [00:56<04:51,  2.76it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 154/958 [00:56<04:51,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 155/958 [00:56<04:52,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 155/958 [00:57<04:52,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 156/958 [00:57<04:52,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 156/958 [00:57<04:52,  2.74it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 157/958 [00:57<04:53,  2.73it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 157/958 [00:57<04:53,  2.73it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 158/958 [00:57<04:50,  2.75it/s, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 158/958 [00:58<04:50,  2.75it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 159/958 [00:58<04:50,  2.75it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 159/958 [00:58<04:50,  2.75it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 160/958 [00:58<04:50,  2.75it/s, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 160/958 [00:59<04:50,  2.75it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 161/958 [00:59<04:48,  2.76it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 161/958 [00:59<04:48,  2.76it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 162/958 [00:59<04:49,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 162/958 [00:59<04:49,  2.75it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 163/958 [00:59<04:51,  2.73it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 163/958 [01:00<04:51,  2.73it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 164/958 [01:00<04:51,  2.72it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 164/958 [01:00<04:51,  2.72it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 165/958 [01:00<04:49,  2.74it/s, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 165/958 [01:00<04:49,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 166/958 [01:00<04:51,  2.72it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 166/958 [01:01<04:51,  2.72it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 167/958 [01:01<04:51,  2.72it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 167/958 [01:01<04:51,  2.72it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 168/958 [01:01<04:50,  2.72it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 168/958 [01:01<04:50,  2.72it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 169/958 [01:01<04:48,  2.73it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 169/958 [01:02<04:48,  2.73it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 170/958 [01:02<04:49,  2.72it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 170/958 [01:02<04:49,  2.72it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 171/958 [01:02<04:49,  2.72it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 171/958 [01:03<04:49,  2.72it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 172/958 [01:03<04:48,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 172/958 [01:03<04:48,  2.73it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 173/958 [01:03<04:46,  2.74it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 173/958 [01:03<04:46,  2.74it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 174/958 [01:03<04:45,  2.74it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 174/958 [01:04<04:45,  2.74it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 175/958 [01:04<04:45,  2.74it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 175/958 [01:04<04:45,  2.74it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 176/958 [01:04<04:43,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 176/958 [01:04<04:43,  2.75it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 177/958 [01:04<04:44,  2.74it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 177/958 [01:05<04:44,  2.74it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 178/958 [01:05<04:42,  2.76it/s, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 178/958 [01:05<04:42,  2.76it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 179/958 [01:05<04:42,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 179/958 [01:05<04:42,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 180/958 [01:05<04:43,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 180/958 [01:06<04:43,  2.75it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 181/958 [01:06<04:42,  2.75it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 181/958 [01:06<04:42,  2.75it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 182/958 [01:06<04:43,  2.73it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 182/958 [01:07<04:43,  2.73it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 183/958 [01:07<04:42,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 183/958 [01:07<04:42,  2.74it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 184/958 [01:07<04:40,  2.76it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 184/958 [01:07<04:40,  2.76it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 185/958 [01:07<04:39,  2.77it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 185/958 [01:08<04:39,  2.77it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 186/958 [01:08<04:38,  2.77it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 186/958 [01:08<04:38,  2.77it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 187/958 [01:08<04:39,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 187/958 [01:08<04:39,  2.76it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 188/958 [01:08<04:39,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 188/958 [01:09<04:39,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 189/958 [01:09<04:39,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 189/958 [01:09<04:39,  2.76it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 190/958 [01:09<04:38,  2.76it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 190/958 [01:09<04:38,  2.76it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 191/958 [01:09<04:38,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 191/958 [01:10<04:38,  2.75it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  20%|██        | 192/958 [01:10<04:38,  2.75it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  20%|██        | 192/958 [01:10<04:38,  2.75it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  20%|██        | 193/958 [01:10<04:39,  2.74it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  20%|██        | 193/958 [01:11<04:39,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  20%|██        | 194/958 [01:11<04:38,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  20%|██        | 194/958 [01:11<04:38,  2.74it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  20%|██        | 195/958 [01:11<04:38,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  20%|██        | 195/958 [01:11<04:38,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  20%|██        | 196/958 [01:11<04:37,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  20%|██        | 196/958 [01:12<04:37,  2.74it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  21%|██        | 197/958 [01:12<04:37,  2.74it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  21%|██        | 197/958 [01:12<04:37,  2.74it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  21%|██        | 198/958 [01:12<04:36,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  21%|██        | 198/958 [01:12<04:36,  2.75it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  21%|██        | 199/958 [01:12<04:35,  2.75it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  21%|██        | 199/958 [01:13<04:35,  2.75it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  21%|██        | 200/958 [01:13<04:36,  2.74it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  21%|██        | 200/958 [01:13<04:36,  2.74it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  21%|██        | 201/958 [01:13<04:38,  2.72it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  21%|██        | 201/958 [01:13<04:38,  2.72it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  21%|██        | 202/958 [01:13<04:38,  2.72it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  21%|██        | 202/958 [01:14<04:38,  2.72it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  21%|██        | 203/958 [01:14<04:36,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  21%|██        | 203/958 [01:14<04:36,  2.73it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 204/958 [01:14<04:36,  2.73it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 204/958 [01:15<04:36,  2.73it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 205/958 [01:15<04:35,  2.73it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 205/958 [01:15<04:35,  2.73it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 206/958 [01:15<04:35,  2.73it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 206/958 [01:15<04:35,  2.73it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 207/958 [01:15<04:34,  2.73it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 207/958 [01:16<04:34,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 208/958 [01:16<04:35,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 208/958 [01:16<04:35,  2.73it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 209/958 [01:16<04:34,  2.73it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 209/958 [01:16<04:34,  2.73it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 210/958 [01:16<04:32,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 210/958 [01:17<04:32,  2.75it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 211/958 [01:17<04:32,  2.75it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 211/958 [01:17<04:32,  2.75it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 212/958 [01:17<04:31,  2.75it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 212/958 [01:17<04:31,  2.75it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 213/958 [01:18<04:30,  2.76it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 213/958 [01:18<04:30,  2.76it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 214/958 [01:18<04:31,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 214/958 [01:18<04:31,  2.74it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 215/958 [01:18<04:31,  2.73it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 215/958 [01:19<04:31,  2.73it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 216/958 [01:19<04:31,  2.74it/s, training_loss=0.296]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 216/958 [01:19<04:31,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 217/958 [01:19<04:29,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 217/958 [01:19<04:29,  2.75it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 218/958 [01:19<04:29,  2.74it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 218/958 [01:20<04:29,  2.74it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 219/958 [01:20<04:28,  2.75it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 219/958 [01:20<04:28,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 220/958 [01:20<04:27,  2.76it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 220/958 [01:20<04:27,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 221/958 [01:20<04:28,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 221/958 [01:21<04:28,  2.75it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 222/958 [01:21<04:27,  2.75it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 222/958 [01:21<04:27,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 223/958 [01:21<04:26,  2.76it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 223/958 [01:22<04:26,  2.76it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 224/958 [01:22<04:27,  2.74it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 224/958 [01:22<04:27,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 225/958 [01:22<04:27,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 225/958 [01:22<04:27,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 226/958 [01:22<04:24,  2.76it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 226/958 [01:23<04:24,  2.76it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 227/958 [01:23<04:24,  2.76it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 227/958 [01:23<04:24,  2.76it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 228/958 [01:23<04:23,  2.77it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 228/958 [01:23<04:23,  2.77it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 229/958 [01:23<04:22,  2.78it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 229/958 [01:24<04:22,  2.78it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 230/958 [01:24<04:22,  2.78it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 230/958 [01:24<04:22,  2.78it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 231/958 [01:24<04:21,  2.78it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 231/958 [01:24<04:21,  2.78it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 232/958 [01:24<04:22,  2.76it/s, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 232/958 [01:25<04:22,  2.76it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 233/958 [01:25<04:23,  2.75it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 233/958 [01:25<04:23,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 234/958 [01:25<04:23,  2.74it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 234/958 [01:25<04:23,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 235/958 [01:26<04:22,  2.75it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 235/958 [01:26<04:22,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 236/958 [01:26<04:24,  2.73it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 236/958 [01:26<04:24,  2.73it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 237/958 [01:26<04:24,  2.73it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 237/958 [01:27<04:24,  2.73it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 238/958 [01:27<04:25,  2.72it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 238/958 [01:27<04:25,  2.72it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 239/958 [01:27<04:25,  2.70it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 239/958 [01:27<04:25,  2.70it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 240/958 [01:27<04:25,  2.71it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 240/958 [01:28<04:25,  2.71it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 241/958 [01:28<04:23,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 241/958 [01:28<04:23,  2.72it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 242/958 [01:28<04:24,  2.71it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 242/958 [01:28<04:24,  2.71it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 243/958 [01:28<04:23,  2.71it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 243/958 [01:29<04:23,  2.71it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 244/958 [01:29<04:25,  2.69it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 244/958 [01:29<04:25,  2.69it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 245/958 [01:29<04:22,  2.72it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 245/958 [01:30<04:22,  2.72it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 246/958 [01:30<04:19,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 246/958 [01:30<04:19,  2.74it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 247/958 [01:30<04:19,  2.74it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 247/958 [01:30<04:19,  2.74it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 248/958 [01:30<04:17,  2.75it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 248/958 [01:31<04:17,  2.75it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 249/958 [01:31<04:19,  2.74it/s, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 249/958 [01:31<04:19,  2.74it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 250/958 [01:31<04:18,  2.74it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 250/958 [01:31<04:18,  2.74it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 251/958 [01:31<04:15,  2.76it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 251/958 [01:32<04:15,  2.76it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 252/958 [01:32<04:15,  2.76it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 252/958 [01:32<04:15,  2.76it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 253/958 [01:32<04:16,  2.75it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 253/958 [01:32<04:16,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 254/958 [01:32<04:15,  2.76it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 254/958 [01:33<04:15,  2.76it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 255/958 [01:33<04:15,  2.75it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 255/958 [01:33<04:15,  2.75it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 256/958 [01:33<04:15,  2.75it/s, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 256/958 [01:34<04:15,  2.75it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 257/958 [01:34<04:15,  2.75it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 257/958 [01:34<04:15,  2.75it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 258/958 [01:34<04:18,  2.71it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 258/958 [01:34<04:18,  2.71it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 259/958 [01:34<04:16,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 259/958 [01:35<04:16,  2.73it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 260/958 [01:35<04:16,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 260/958 [01:35<04:16,  2.72it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 261/958 [01:35<04:17,  2.71it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 261/958 [01:35<04:17,  2.71it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 262/958 [01:35<04:14,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 262/958 [01:36<04:14,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 263/958 [01:36<04:12,  2.75it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 263/958 [01:36<04:12,  2.75it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 264/958 [01:36<04:13,  2.74it/s, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 264/958 [01:36<04:13,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 265/958 [01:36<04:12,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 265/958 [01:37<04:12,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 266/958 [01:37<04:11,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 266/958 [01:37<04:11,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 267/958 [01:37<04:11,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 267/958 [01:38<04:11,  2.75it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 268/958 [01:38<04:10,  2.75it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 268/958 [01:38<04:10,  2.75it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 269/958 [01:38<04:10,  2.75it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 269/958 [01:38<04:10,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 270/958 [01:38<04:10,  2.75it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 270/958 [01:39<04:10,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 271/958 [01:39<04:10,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 271/958 [01:39<04:10,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 272/958 [01:39<04:10,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 272/958 [01:39<04:10,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 273/958 [01:39<04:09,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 273/958 [01:40<04:09,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 274/958 [01:40<04:09,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 274/958 [01:40<04:09,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 275/958 [01:40<04:09,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 275/958 [01:40<04:09,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 276/958 [01:40<04:08,  2.75it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 276/958 [01:41<04:08,  2.75it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 277/958 [01:41<04:08,  2.74it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 277/958 [01:41<04:08,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 278/958 [01:41<04:08,  2.73it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 278/958 [01:42<04:08,  2.73it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 279/958 [01:42<04:06,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 279/958 [01:42<04:06,  2.75it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 280/958 [01:42<04:05,  2.76it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 280/958 [01:42<04:05,  2.76it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 281/958 [01:42<04:05,  2.76it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 281/958 [01:43<04:05,  2.76it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 282/958 [01:43<04:05,  2.76it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 282/958 [01:43<04:05,  2.76it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 283/958 [01:43<04:06,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 283/958 [01:43<04:06,  2.74it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 284/958 [01:43<04:07,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 284/958 [01:44<04:07,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 285/958 [01:44<04:06,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 285/958 [01:44<04:06,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 286/958 [01:44<04:06,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 286/958 [01:44<04:06,  2.73it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 287/958 [01:45<04:04,  2.74it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 287/958 [01:45<04:04,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  30%|███       | 288/958 [01:45<04:03,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  30%|███       | 288/958 [01:45<04:03,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  30%|███       | 289/958 [01:45<04:04,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  30%|███       | 289/958 [01:46<04:04,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  30%|███       | 290/958 [01:46<04:04,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  30%|███       | 290/958 [01:46<04:04,  2.73it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  30%|███       | 291/958 [01:46<04:05,  2.72it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  30%|███       | 291/958 [01:46<04:05,  2.72it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  30%|███       | 292/958 [01:46<04:03,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  30%|███       | 292/958 [01:47<04:03,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  31%|███       | 293/958 [01:47<04:02,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  31%|███       | 293/958 [01:47<04:02,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  31%|███       | 294/958 [01:47<04:01,  2.75it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  31%|███       | 294/958 [01:47<04:01,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  31%|███       | 295/958 [01:47<03:59,  2.76it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  31%|███       | 295/958 [01:48<03:59,  2.76it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  31%|███       | 296/958 [01:48<03:59,  2.76it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  31%|███       | 296/958 [01:48<03:59,  2.76it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  31%|███       | 297/958 [01:48<03:59,  2.76it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  31%|███       | 297/958 [01:48<03:59,  2.76it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  31%|███       | 298/958 [01:49<03:59,  2.76it/s, training_loss=0.293]\u001b[A\n",
            "Epoch 2:  31%|███       | 298/958 [01:49<03:59,  2.76it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  31%|███       | 299/958 [01:49<03:59,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  31%|███       | 299/958 [01:49<03:59,  2.75it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 300/958 [01:49<03:58,  2.76it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 300/958 [01:50<03:58,  2.76it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 301/958 [01:50<03:59,  2.75it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 301/958 [01:50<03:59,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 302/958 [01:50<03:59,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 302/958 [01:50<03:59,  2.74it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 303/958 [01:50<03:58,  2.75it/s, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 303/958 [01:51<03:58,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 304/958 [01:51<03:58,  2.74it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 304/958 [01:51<03:58,  2.74it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 305/958 [01:51<03:58,  2.74it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 305/958 [01:51<03:58,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 306/958 [01:51<03:57,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 306/958 [01:52<03:57,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 307/958 [01:52<03:56,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 307/958 [01:52<03:56,  2.75it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 308/958 [01:52<03:57,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 308/958 [01:53<03:57,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 309/958 [01:53<03:57,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 309/958 [01:53<03:57,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 310/958 [01:53<03:56,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 310/958 [01:53<03:56,  2.74it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 311/958 [01:53<03:55,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 311/958 [01:54<03:55,  2.75it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 312/958 [01:54<03:55,  2.75it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 312/958 [01:54<03:55,  2.75it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 313/958 [01:54<03:55,  2.74it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 313/958 [01:54<03:55,  2.74it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 314/958 [01:54<03:56,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 314/958 [01:55<03:56,  2.73it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 315/958 [01:55<03:53,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 315/958 [01:55<03:53,  2.75it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 316/958 [01:55<03:54,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 316/958 [01:55<03:54,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 317/958 [01:55<03:53,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 317/958 [01:56<03:53,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 318/958 [01:56<03:52,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 318/958 [01:56<03:52,  2.75it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 319/958 [01:56<03:53,  2.74it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 319/958 [01:57<03:53,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 320/958 [01:57<03:54,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 320/958 [01:57<03:54,  2.73it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 321/958 [01:57<03:53,  2.72it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 321/958 [01:57<03:53,  2.72it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 322/958 [01:57<03:52,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 322/958 [01:58<03:52,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 323/958 [01:58<03:51,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 323/958 [01:58<03:51,  2.74it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 324/958 [01:58<03:51,  2.74it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 324/958 [01:58<03:51,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 325/958 [01:58<03:51,  2.73it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 325/958 [01:59<03:51,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 326/958 [01:59<03:50,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 326/958 [01:59<03:50,  2.74it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 327/958 [01:59<03:51,  2.72it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 327/958 [01:59<03:51,  2.72it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 328/958 [01:59<03:50,  2.73it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 328/958 [02:00<03:50,  2.73it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 329/958 [02:00<03:49,  2.74it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 329/958 [02:00<03:49,  2.74it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 330/958 [02:00<03:49,  2.74it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 330/958 [02:01<03:49,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 331/958 [02:01<03:48,  2.75it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 331/958 [02:01<03:48,  2.75it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 332/958 [02:01<03:48,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 332/958 [02:01<03:48,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 333/958 [02:01<03:47,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 333/958 [02:02<03:47,  2.74it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 334/958 [02:02<03:48,  2.73it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 334/958 [02:02<03:48,  2.73it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 335/958 [02:02<03:48,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 335/958 [02:02<03:48,  2.72it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 336/958 [02:02<03:48,  2.72it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 336/958 [02:03<03:48,  2.72it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 337/958 [02:03<03:49,  2.71it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 337/958 [02:03<03:49,  2.71it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 338/958 [02:03<03:46,  2.74it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 338/958 [02:03<03:46,  2.74it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 339/958 [02:03<03:45,  2.75it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 339/958 [02:04<03:45,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 340/958 [02:04<03:46,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 340/958 [02:04<03:46,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 341/958 [02:04<03:44,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 341/958 [02:05<03:44,  2.75it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 342/958 [02:05<03:44,  2.74it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 342/958 [02:05<03:44,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 343/958 [02:05<03:45,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 343/958 [02:05<03:45,  2.73it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 344/958 [02:05<03:43,  2.75it/s, training_loss=0.264]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 344/958 [02:06<03:43,  2.75it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 345/958 [02:06<03:44,  2.73it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 345/958 [02:06<03:44,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 346/958 [02:06<03:43,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 346/958 [02:06<03:43,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 347/958 [02:06<03:43,  2.73it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 347/958 [02:07<03:43,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 348/958 [02:07<03:42,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 348/958 [02:07<03:42,  2.74it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 349/958 [02:07<03:41,  2.75it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 349/958 [02:07<03:41,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 350/958 [02:07<03:42,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 350/958 [02:08<03:42,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 351/958 [02:08<03:42,  2.73it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 351/958 [02:08<03:42,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 352/958 [02:08<03:41,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 352/958 [02:09<03:41,  2.74it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 353/958 [02:09<03:39,  2.75it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 353/958 [02:09<03:39,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 354/958 [02:09<03:38,  2.76it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 354/958 [02:09<03:38,  2.76it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 355/958 [02:09<03:37,  2.77it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 355/958 [02:10<03:37,  2.77it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 356/958 [02:10<03:39,  2.74it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 356/958 [02:10<03:39,  2.74it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 357/958 [02:10<03:39,  2.73it/s, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 357/958 [02:10<03:39,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 358/958 [02:10<03:38,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 358/958 [02:11<03:38,  2.74it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 359/958 [02:11<03:38,  2.75it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 359/958 [02:11<03:38,  2.75it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 360/958 [02:11<03:36,  2.76it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 360/958 [02:11<03:36,  2.76it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 361/958 [02:11<03:35,  2.76it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 361/958 [02:12<03:35,  2.76it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 362/958 [02:12<03:36,  2.75it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 362/958 [02:12<03:36,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 363/958 [02:12<03:36,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 363/958 [02:13<03:36,  2.75it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 364/958 [02:13<03:37,  2.74it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 364/958 [02:13<03:37,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 365/958 [02:13<03:38,  2.71it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 365/958 [02:13<03:38,  2.71it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 366/958 [02:13<03:37,  2.72it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 366/958 [02:14<03:37,  2.72it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 367/958 [02:14<03:37,  2.72it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 367/958 [02:14<03:37,  2.72it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 368/958 [02:14<03:37,  2.72it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 368/958 [02:14<03:37,  2.72it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 369/958 [02:14<03:36,  2.72it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 369/958 [02:15<03:36,  2.72it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 370/958 [02:15<03:37,  2.71it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 370/958 [02:15<03:37,  2.71it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 371/958 [02:15<03:35,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 371/958 [02:16<03:35,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 372/958 [02:16<03:36,  2.71it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 372/958 [02:16<03:36,  2.71it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 373/958 [02:16<03:34,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 373/958 [02:16<03:34,  2.73it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 374/958 [02:16<03:32,  2.74it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 374/958 [02:17<03:32,  2.74it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 375/958 [02:17<03:33,  2.73it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 375/958 [02:17<03:33,  2.73it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 376/958 [02:17<03:33,  2.73it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 376/958 [02:17<03:33,  2.73it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 377/958 [02:17<03:31,  2.75it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 377/958 [02:18<03:31,  2.75it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 378/958 [02:18<03:32,  2.73it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 378/958 [02:18<03:32,  2.73it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 379/958 [02:18<03:33,  2.72it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 379/958 [02:18<03:33,  2.72it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 380/958 [02:18<03:31,  2.73it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 380/958 [02:19<03:31,  2.73it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 381/958 [02:19<03:30,  2.74it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 381/958 [02:19<03:30,  2.74it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 382/958 [02:19<03:30,  2.73it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 382/958 [02:20<03:30,  2.73it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 383/958 [02:20<03:30,  2.73it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 383/958 [02:20<03:30,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  40%|████      | 384/958 [02:20<03:28,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  40%|████      | 384/958 [02:20<03:28,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  40%|████      | 385/958 [02:20<03:30,  2.73it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  40%|████      | 385/958 [02:21<03:30,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  40%|████      | 386/958 [02:21<03:29,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  40%|████      | 386/958 [02:21<03:29,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  40%|████      | 387/958 [02:21<03:29,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  40%|████      | 387/958 [02:21<03:29,  2.73it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  41%|████      | 388/958 [02:21<03:28,  2.73it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  41%|████      | 388/958 [02:22<03:28,  2.73it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  41%|████      | 389/958 [02:22<03:28,  2.73it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  41%|████      | 389/958 [02:22<03:28,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  41%|████      | 390/958 [02:22<03:27,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  41%|████      | 390/958 [02:22<03:27,  2.74it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  41%|████      | 391/958 [02:22<03:26,  2.75it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  41%|████      | 391/958 [02:23<03:26,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  41%|████      | 392/958 [02:23<03:26,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  41%|████      | 392/958 [02:23<03:26,  2.73it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  41%|████      | 393/958 [02:23<03:26,  2.74it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  41%|████      | 393/958 [02:24<03:26,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  41%|████      | 394/958 [02:24<03:26,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  41%|████      | 394/958 [02:24<03:26,  2.74it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  41%|████      | 395/958 [02:24<03:26,  2.72it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  41%|████      | 395/958 [02:24<03:26,  2.72it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 396/958 [02:24<03:24,  2.74it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 396/958 [02:25<03:24,  2.74it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 397/958 [02:25<03:24,  2.74it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 397/958 [02:25<03:24,  2.74it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 398/958 [02:25<03:24,  2.74it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 398/958 [02:25<03:24,  2.74it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 399/958 [02:25<03:23,  2.75it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 399/958 [02:26<03:23,  2.75it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 400/958 [02:26<03:22,  2.75it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 400/958 [02:26<03:22,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 401/958 [02:26<03:22,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 401/958 [02:26<03:22,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 402/958 [02:26<03:22,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 402/958 [02:27<03:22,  2.75it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 403/958 [02:27<03:21,  2.75it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 403/958 [02:27<03:21,  2.75it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 404/958 [02:27<03:22,  2.74it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 404/958 [02:28<03:22,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 405/958 [02:28<03:21,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 405/958 [02:28<03:21,  2.74it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 406/958 [02:28<03:21,  2.74it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 406/958 [02:28<03:21,  2.74it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 407/958 [02:28<03:22,  2.73it/s, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 407/958 [02:29<03:22,  2.73it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 408/958 [02:29<03:20,  2.74it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 408/958 [02:29<03:20,  2.74it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 409/958 [02:29<03:19,  2.75it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 409/958 [02:29<03:19,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 410/958 [02:29<03:19,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 410/958 [02:30<03:19,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 411/958 [02:30<03:20,  2.72it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 411/958 [02:30<03:20,  2.72it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 412/958 [02:30<03:19,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 412/958 [02:31<03:19,  2.74it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 413/958 [02:31<03:18,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 413/958 [02:31<03:18,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 414/958 [02:31<03:17,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 414/958 [02:31<03:17,  2.76it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 415/958 [02:31<03:16,  2.76it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 415/958 [02:32<03:16,  2.76it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 416/958 [02:32<03:16,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 416/958 [02:32<03:16,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 417/958 [02:32<03:16,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 417/958 [02:32<03:16,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 418/958 [02:32<03:16,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 418/958 [02:33<03:16,  2.75it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 419/958 [02:33<03:15,  2.75it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 419/958 [02:33<03:15,  2.75it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 420/958 [02:33<03:16,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 420/958 [02:33<03:16,  2.74it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 421/958 [02:33<03:15,  2.75it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 421/958 [02:34<03:15,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 422/958 [02:34<03:16,  2.73it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 422/958 [02:34<03:16,  2.73it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 423/958 [02:34<03:16,  2.72it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 423/958 [02:35<03:16,  2.72it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 424/958 [02:35<03:15,  2.73it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 424/958 [02:35<03:15,  2.73it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 425/958 [02:35<03:15,  2.72it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 425/958 [02:35<03:15,  2.72it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 426/958 [02:35<03:16,  2.71it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 426/958 [02:36<03:16,  2.71it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 427/958 [02:36<03:15,  2.72it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 427/958 [02:36<03:15,  2.72it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 428/958 [02:36<03:15,  2.71it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 428/958 [02:36<03:15,  2.71it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 429/958 [02:36<03:14,  2.72it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 429/958 [02:37<03:14,  2.72it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 430/958 [02:37<03:12,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 430/958 [02:37<03:12,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 431/958 [02:37<03:12,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 431/958 [02:37<03:12,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 432/958 [02:37<03:10,  2.76it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 432/958 [02:38<03:10,  2.76it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 433/958 [02:38<03:10,  2.76it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 433/958 [02:38<03:10,  2.76it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 434/958 [02:38<03:11,  2.74it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 434/958 [02:39<03:11,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 435/958 [02:39<03:10,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 435/958 [02:39<03:10,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 436/958 [02:39<03:10,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 436/958 [02:39<03:10,  2.74it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 437/958 [02:39<03:09,  2.75it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 437/958 [02:40<03:09,  2.75it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 438/958 [02:40<03:09,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 438/958 [02:40<03:09,  2.74it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 439/958 [02:40<03:08,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 439/958 [02:40<03:08,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 440/958 [02:40<03:09,  2.73it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 440/958 [02:41<03:09,  2.73it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 441/958 [02:41<03:09,  2.72it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 441/958 [02:41<03:09,  2.72it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 442/958 [02:41<03:08,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 442/958 [02:41<03:08,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 443/958 [02:41<03:07,  2.75it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 443/958 [02:42<03:07,  2.75it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 444/958 [02:42<03:06,  2.76it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 444/958 [02:42<03:06,  2.76it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 445/958 [02:42<03:06,  2.74it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 445/958 [02:43<03:06,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 446/958 [02:43<03:05,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 446/958 [02:43<03:05,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 447/958 [02:43<03:05,  2.76it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 447/958 [02:43<03:05,  2.76it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 448/958 [02:43<03:05,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 448/958 [02:44<03:05,  2.75it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 449/958 [02:44<03:05,  2.75it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 449/958 [02:44<03:05,  2.75it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 450/958 [02:44<03:05,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 450/958 [02:44<03:05,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 451/958 [02:44<03:05,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 451/958 [02:45<03:05,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 452/958 [02:45<03:04,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 452/958 [02:45<03:04,  2.74it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 453/958 [02:45<03:04,  2.74it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 453/958 [02:45<03:04,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 454/958 [02:45<03:04,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 454/958 [02:46<03:04,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 455/958 [02:46<03:03,  2.75it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 455/958 [02:46<03:03,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 456/958 [02:46<03:02,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 456/958 [02:47<03:02,  2.75it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 457/958 [02:47<03:03,  2.73it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 457/958 [02:47<03:03,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 458/958 [02:47<03:02,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 458/958 [02:47<03:02,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 459/958 [02:47<03:02,  2.74it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 459/958 [02:48<03:02,  2.74it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 460/958 [02:48<03:01,  2.74it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 460/958 [02:48<03:01,  2.74it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 461/958 [02:48<03:02,  2.73it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 461/958 [02:48<03:02,  2.73it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 462/958 [02:48<03:00,  2.74it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 462/958 [02:49<03:00,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 463/958 [02:49<03:01,  2.72it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 463/958 [02:49<03:01,  2.72it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 464/958 [02:49<03:00,  2.73it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 464/958 [02:49<03:00,  2.73it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 465/958 [02:49<03:00,  2.73it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 465/958 [02:50<03:00,  2.73it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 466/958 [02:50<03:00,  2.73it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 466/958 [02:50<03:00,  2.73it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 467/958 [02:50<02:58,  2.75it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 467/958 [02:51<02:58,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 468/958 [02:51<02:57,  2.76it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 468/958 [02:51<02:57,  2.76it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 469/958 [02:51<02:57,  2.75it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 469/958 [02:51<02:57,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 470/958 [02:51<02:57,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 470/958 [02:52<02:57,  2.75it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 471/958 [02:52<02:57,  2.74it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 471/958 [02:52<02:57,  2.74it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 472/958 [02:52<02:57,  2.73it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 472/958 [02:52<02:57,  2.73it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 473/958 [02:52<02:56,  2.75it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 473/958 [02:53<02:56,  2.75it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 474/958 [02:53<02:56,  2.75it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 474/958 [02:53<02:56,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 475/958 [02:53<02:55,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 475/958 [02:53<02:55,  2.75it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 476/958 [02:53<02:54,  2.77it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 476/958 [02:54<02:54,  2.77it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 477/958 [02:54<02:54,  2.76it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 477/958 [02:54<02:54,  2.76it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 478/958 [02:54<02:54,  2.75it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 478/958 [02:55<02:54,  2.75it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  50%|█████     | 479/958 [02:55<02:52,  2.77it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  50%|█████     | 479/958 [02:55<02:52,  2.77it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  50%|█████     | 480/958 [02:55<02:52,  2.78it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  50%|█████     | 480/958 [02:55<02:52,  2.78it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  50%|█████     | 481/958 [02:55<02:51,  2.78it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  50%|█████     | 481/958 [02:56<02:51,  2.78it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  50%|█████     | 482/958 [02:56<02:52,  2.76it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  50%|█████     | 482/958 [02:56<02:52,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  50%|█████     | 483/958 [02:56<02:52,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  50%|█████     | 483/958 [02:56<02:52,  2.76it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  51%|█████     | 484/958 [02:56<02:51,  2.76it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  51%|█████     | 484/958 [02:57<02:51,  2.76it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  51%|█████     | 485/958 [02:57<02:51,  2.76it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  51%|█████     | 485/958 [02:57<02:51,  2.76it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  51%|█████     | 486/958 [02:57<02:51,  2.76it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  51%|█████     | 486/958 [02:57<02:51,  2.76it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  51%|█████     | 487/958 [02:57<02:50,  2.76it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 2:  51%|█████     | 487/958 [02:58<02:50,  2.76it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  51%|█████     | 488/958 [02:58<02:52,  2.73it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  51%|█████     | 488/958 [02:58<02:52,  2.73it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  51%|█████     | 489/958 [02:58<02:51,  2.74it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  51%|█████     | 489/958 [02:59<02:51,  2.74it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  51%|█████     | 490/958 [02:59<02:52,  2.71it/s, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  51%|█████     | 490/958 [02:59<02:52,  2.71it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 491/958 [02:59<02:50,  2.73it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 491/958 [02:59<02:50,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 492/958 [02:59<02:49,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 492/958 [03:00<02:49,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 493/958 [03:00<02:48,  2.75it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 493/958 [03:00<02:48,  2.75it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 494/958 [03:00<02:49,  2.74it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 494/958 [03:00<02:49,  2.74it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 495/958 [03:00<02:48,  2.74it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 495/958 [03:01<02:48,  2.74it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 496/958 [03:01<02:48,  2.74it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 496/958 [03:01<02:48,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 497/958 [03:01<02:49,  2.71it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 497/958 [03:01<02:49,  2.71it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 498/958 [03:02<02:48,  2.73it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 498/958 [03:02<02:48,  2.73it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 499/958 [03:02<02:48,  2.72it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 499/958 [03:02<02:48,  2.72it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 500/958 [03:02<02:47,  2.73it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 500/958 [03:03<02:47,  2.73it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 501/958 [03:03<02:46,  2.74it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 501/958 [03:03<02:46,  2.74it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 502/958 [03:03<02:47,  2.72it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 502/958 [03:03<02:47,  2.72it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 503/958 [03:03<02:46,  2.73it/s, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 503/958 [03:04<02:46,  2.73it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 504/958 [03:04<02:47,  2.71it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 504/958 [03:04<02:47,  2.71it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 505/958 [03:04<02:47,  2.71it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 505/958 [03:04<02:47,  2.71it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 506/958 [03:04<02:46,  2.72it/s, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 506/958 [03:05<02:46,  2.72it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 507/958 [03:05<02:45,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 507/958 [03:05<02:45,  2.73it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 508/958 [03:05<02:43,  2.75it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 508/958 [03:06<02:43,  2.75it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 509/958 [03:06<02:43,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 509/958 [03:06<02:43,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 510/958 [03:06<02:43,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 510/958 [03:06<02:43,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 511/958 [03:06<02:42,  2.75it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 511/958 [03:07<02:42,  2.75it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 512/958 [03:07<02:42,  2.75it/s, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 512/958 [03:07<02:42,  2.75it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 513/958 [03:07<02:41,  2.75it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 513/958 [03:07<02:41,  2.75it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 514/958 [03:07<02:41,  2.75it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 514/958 [03:08<02:41,  2.75it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 515/958 [03:08<02:41,  2.75it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 515/958 [03:08<02:41,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 516/958 [03:08<02:40,  2.75it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 516/958 [03:08<02:40,  2.75it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 517/958 [03:08<02:40,  2.75it/s, training_loss=0.271]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 517/958 [03:09<02:40,  2.75it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 518/958 [03:09<02:39,  2.76it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 518/958 [03:09<02:39,  2.76it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 519/958 [03:09<02:38,  2.77it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 519/958 [03:10<02:38,  2.77it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 520/958 [03:10<02:38,  2.76it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 520/958 [03:10<02:38,  2.76it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 521/958 [03:10<02:37,  2.77it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 521/958 [03:10<02:37,  2.77it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 522/958 [03:10<02:37,  2.77it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 522/958 [03:11<02:37,  2.77it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 523/958 [03:11<02:38,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 523/958 [03:11<02:38,  2.75it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 524/958 [03:11<02:37,  2.75it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 524/958 [03:11<02:37,  2.75it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 525/958 [03:11<02:37,  2.76it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 525/958 [03:12<02:37,  2.76it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 526/958 [03:12<02:37,  2.75it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 526/958 [03:12<02:37,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 527/958 [03:12<02:36,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 527/958 [03:12<02:36,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 528/958 [03:12<02:36,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 528/958 [03:13<02:36,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 529/958 [03:13<02:36,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 529/958 [03:13<02:36,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 530/958 [03:13<02:37,  2.73it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 530/958 [03:14<02:37,  2.73it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 531/958 [03:14<02:35,  2.74it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 531/958 [03:14<02:35,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 532/958 [03:14<02:36,  2.73it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 532/958 [03:14<02:36,  2.73it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 533/958 [03:14<02:36,  2.71it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 533/958 [03:15<02:36,  2.71it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 534/958 [03:15<02:35,  2.73it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 534/958 [03:15<02:35,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 535/958 [03:15<02:34,  2.74it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 535/958 [03:15<02:34,  2.74it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 536/958 [03:15<02:34,  2.74it/s, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 536/958 [03:16<02:34,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 537/958 [03:16<02:34,  2.72it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 537/958 [03:16<02:34,  2.72it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 538/958 [03:16<02:34,  2.72it/s, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 538/958 [03:16<02:34,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 539/958 [03:16<02:33,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 539/958 [03:17<02:33,  2.72it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 540/958 [03:17<02:32,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 540/958 [03:17<02:32,  2.74it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 541/958 [03:17<02:33,  2.72it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 541/958 [03:18<02:33,  2.72it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 542/958 [03:18<02:32,  2.73it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 542/958 [03:18<02:32,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 543/958 [03:18<02:32,  2.73it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 543/958 [03:18<02:32,  2.73it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 544/958 [03:18<02:31,  2.74it/s, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 544/958 [03:19<02:31,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 545/958 [03:19<02:30,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 545/958 [03:19<02:30,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 546/958 [03:19<02:30,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 546/958 [03:19<02:30,  2.74it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 547/958 [03:19<02:30,  2.73it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 547/958 [03:20<02:30,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 548/958 [03:20<02:30,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 548/958 [03:20<02:30,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 549/958 [03:20<02:29,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 549/958 [03:20<02:29,  2.73it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 550/958 [03:20<02:29,  2.74it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 550/958 [03:21<02:29,  2.74it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 551/958 [03:21<02:29,  2.73it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 551/958 [03:21<02:29,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 552/958 [03:21<02:28,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 552/958 [03:22<02:28,  2.74it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 553/958 [03:22<02:27,  2.74it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 553/958 [03:22<02:27,  2.74it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 554/958 [03:22<02:28,  2.73it/s, training_loss=0.267]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 554/958 [03:22<02:28,  2.73it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 555/958 [03:22<02:27,  2.73it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 555/958 [03:23<02:27,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 556/958 [03:23<02:26,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 556/958 [03:23<02:26,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 557/958 [03:23<02:26,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 557/958 [03:23<02:26,  2.73it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 558/958 [03:23<02:26,  2.73it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 558/958 [03:24<02:26,  2.73it/s, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 559/958 [03:24<02:25,  2.74it/s, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 559/958 [03:24<02:25,  2.74it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 560/958 [03:24<02:26,  2.72it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 560/958 [03:25<02:26,  2.72it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 561/958 [03:25<02:24,  2.74it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 561/958 [03:25<02:24,  2.74it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 562/958 [03:25<02:23,  2.76it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 562/958 [03:25<02:23,  2.76it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 563/958 [03:25<02:23,  2.74it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 563/958 [03:26<02:23,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 564/958 [03:26<02:23,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 564/958 [03:26<02:23,  2.75it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 565/958 [03:26<02:23,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 565/958 [03:26<02:23,  2.74it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 566/958 [03:26<02:23,  2.74it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 566/958 [03:27<02:23,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 567/958 [03:27<02:23,  2.72it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 567/958 [03:27<02:23,  2.72it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 568/958 [03:27<02:24,  2.71it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 568/958 [03:27<02:24,  2.71it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 569/958 [03:27<02:23,  2.70it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 569/958 [03:28<02:23,  2.70it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 570/958 [03:28<02:22,  2.73it/s, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 570/958 [03:28<02:22,  2.73it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 571/958 [03:28<02:22,  2.71it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 571/958 [03:29<02:22,  2.71it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 572/958 [03:29<02:22,  2.71it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 572/958 [03:29<02:22,  2.71it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 573/958 [03:29<02:21,  2.72it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 573/958 [03:29<02:21,  2.72it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 574/958 [03:29<02:21,  2.71it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 574/958 [03:30<02:21,  2.71it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  60%|██████    | 575/958 [03:30<02:20,  2.73it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  60%|██████    | 575/958 [03:30<02:20,  2.73it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  60%|██████    | 576/958 [03:30<02:19,  2.74it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  60%|██████    | 576/958 [03:30<02:19,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  60%|██████    | 577/958 [03:30<02:18,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  60%|██████    | 577/958 [03:31<02:18,  2.74it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  60%|██████    | 578/958 [03:31<02:18,  2.74it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  60%|██████    | 578/958 [03:31<02:18,  2.74it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  60%|██████    | 579/958 [03:31<02:18,  2.73it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  60%|██████    | 579/958 [03:31<02:18,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  61%|██████    | 580/958 [03:31<02:18,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  61%|██████    | 580/958 [03:32<02:18,  2.73it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  61%|██████    | 581/958 [03:32<02:17,  2.75it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  61%|██████    | 581/958 [03:32<02:17,  2.75it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  61%|██████    | 582/958 [03:32<02:17,  2.74it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  61%|██████    | 582/958 [03:33<02:17,  2.74it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  61%|██████    | 583/958 [03:33<02:17,  2.73it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  61%|██████    | 583/958 [03:33<02:17,  2.73it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  61%|██████    | 584/958 [03:33<02:16,  2.74it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  61%|██████    | 584/958 [03:33<02:16,  2.74it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  61%|██████    | 585/958 [03:33<02:15,  2.74it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  61%|██████    | 585/958 [03:34<02:15,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  61%|██████    | 586/958 [03:34<02:15,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  61%|██████    | 586/958 [03:34<02:15,  2.74it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 587/958 [03:34<02:14,  2.75it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 587/958 [03:34<02:14,  2.75it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 588/958 [03:34<02:15,  2.73it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 588/958 [03:35<02:15,  2.73it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 589/958 [03:35<02:15,  2.72it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 589/958 [03:35<02:15,  2.72it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 590/958 [03:35<02:15,  2.72it/s, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 590/958 [03:36<02:15,  2.72it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 591/958 [03:36<02:16,  2.70it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 591/958 [03:36<02:16,  2.70it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 592/958 [03:36<02:14,  2.71it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 592/958 [03:36<02:14,  2.71it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 593/958 [03:36<02:13,  2.73it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 593/958 [03:37<02:13,  2.73it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 594/958 [03:37<02:12,  2.74it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 594/958 [03:37<02:12,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 595/958 [03:37<02:13,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 595/958 [03:37<02:13,  2.73it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 596/958 [03:37<02:12,  2.74it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 596/958 [03:38<02:12,  2.74it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 597/958 [03:38<02:10,  2.76it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 597/958 [03:38<02:10,  2.76it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 598/958 [03:38<02:10,  2.75it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 598/958 [03:38<02:10,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 599/958 [03:38<02:10,  2.76it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 599/958 [03:39<02:10,  2.76it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 600/958 [03:39<02:10,  2.75it/s, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 600/958 [03:39<02:10,  2.75it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 601/958 [03:39<02:09,  2.76it/s, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 601/958 [03:40<02:09,  2.76it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 602/958 [03:40<02:09,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 602/958 [03:40<02:09,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 603/958 [03:40<02:09,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 603/958 [03:40<02:09,  2.74it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 604/958 [03:40<02:08,  2.75it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 604/958 [03:41<02:08,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 605/958 [03:41<02:09,  2.72it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 605/958 [03:41<02:09,  2.72it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 606/958 [03:41<02:08,  2.74it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 606/958 [03:41<02:08,  2.74it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 607/958 [03:41<02:07,  2.74it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 607/958 [03:42<02:07,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 608/958 [03:42<02:07,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 608/958 [03:42<02:07,  2.75it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 609/958 [03:42<02:07,  2.73it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 609/958 [03:42<02:07,  2.73it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 610/958 [03:42<02:06,  2.74it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 610/958 [03:43<02:06,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 611/958 [03:43<02:06,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 611/958 [03:43<02:06,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 612/958 [03:43<02:05,  2.76it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 612/958 [03:44<02:05,  2.76it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 613/958 [03:44<02:05,  2.75it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 613/958 [03:44<02:05,  2.75it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 614/958 [03:44<02:06,  2.73it/s, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 614/958 [03:44<02:06,  2.73it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 615/958 [03:44<02:04,  2.75it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 615/958 [03:45<02:04,  2.75it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 616/958 [03:45<02:03,  2.76it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 616/958 [03:45<02:03,  2.76it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 617/958 [03:45<02:03,  2.76it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 617/958 [03:45<02:03,  2.76it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 618/958 [03:45<02:03,  2.76it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 618/958 [03:46<02:03,  2.76it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 619/958 [03:46<02:03,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 619/958 [03:46<02:03,  2.75it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 620/958 [03:46<02:03,  2.73it/s, training_loss=0.311]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 620/958 [03:46<02:03,  2.73it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 621/958 [03:46<02:02,  2.75it/s, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 621/958 [03:47<02:02,  2.75it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 622/958 [03:47<02:03,  2.73it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 622/958 [03:47<02:03,  2.73it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 623/958 [03:47<02:02,  2.73it/s, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 623/958 [03:48<02:02,  2.73it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 624/958 [03:48<02:02,  2.72it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 624/958 [03:48<02:02,  2.72it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 625/958 [03:48<02:03,  2.70it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 625/958 [03:48<02:03,  2.70it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 626/958 [03:48<02:02,  2.72it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 626/958 [03:49<02:02,  2.72it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 627/958 [03:49<02:02,  2.71it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 627/958 [03:49<02:02,  2.71it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 628/958 [03:49<02:02,  2.70it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 628/958 [03:49<02:02,  2.70it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 629/958 [03:49<02:00,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 629/958 [03:50<02:00,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 630/958 [03:50<02:00,  2.71it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 630/958 [03:50<02:00,  2.71it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 631/958 [03:50<02:00,  2.72it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 631/958 [03:50<02:00,  2.72it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 632/958 [03:50<01:59,  2.72it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 632/958 [03:51<01:59,  2.72it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 633/958 [03:51<01:59,  2.72it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 633/958 [03:51<01:59,  2.72it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 634/958 [03:51<01:59,  2.72it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 634/958 [03:52<01:59,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 635/958 [03:52<01:58,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 635/958 [03:52<01:58,  2.72it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 636/958 [03:52<01:58,  2.71it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 636/958 [03:52<01:58,  2.71it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 637/958 [03:52<01:58,  2.71it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 637/958 [03:53<01:58,  2.71it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 638/958 [03:53<01:57,  2.72it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 638/958 [03:53<01:57,  2.72it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 639/958 [03:53<01:56,  2.74it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 639/958 [03:53<01:56,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 640/958 [03:53<01:56,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 640/958 [03:54<01:56,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 641/958 [03:54<01:54,  2.76it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 641/958 [03:54<01:54,  2.76it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 642/958 [03:54<01:54,  2.77it/s, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 642/958 [03:54<01:54,  2.77it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 643/958 [03:55<01:54,  2.76it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 643/958 [03:55<01:54,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 644/958 [03:55<01:54,  2.74it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 644/958 [03:55<01:54,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 645/958 [03:55<01:53,  2.76it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 645/958 [03:56<01:53,  2.76it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 646/958 [03:56<01:53,  2.76it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 646/958 [03:56<01:53,  2.76it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 647/958 [03:56<01:53,  2.74it/s, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 647/958 [03:56<01:53,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 648/958 [03:56<01:52,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 648/958 [03:57<01:52,  2.75it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 649/958 [03:57<01:52,  2.74it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 649/958 [03:57<01:52,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 650/958 [03:57<01:52,  2.75it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 650/958 [03:57<01:52,  2.75it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 651/958 [03:57<01:51,  2.74it/s, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 651/958 [03:58<01:51,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 652/958 [03:58<01:52,  2.73it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 652/958 [03:58<01:52,  2.73it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 653/958 [03:58<01:52,  2.72it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 653/958 [03:59<01:52,  2.72it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 654/958 [03:59<01:51,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 654/958 [03:59<01:51,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 655/958 [03:59<01:50,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 655/958 [03:59<01:50,  2.74it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 656/958 [03:59<01:50,  2.74it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 656/958 [04:00<01:50,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 657/958 [04:00<01:49,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 657/958 [04:00<01:49,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 658/958 [04:00<01:48,  2.77it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 658/958 [04:00<01:48,  2.77it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 659/958 [04:00<01:48,  2.77it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 659/958 [04:01<01:48,  2.77it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 660/958 [04:01<01:47,  2.77it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 660/958 [04:01<01:47,  2.77it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 661/958 [04:01<01:47,  2.76it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 661/958 [04:01<01:47,  2.76it/s, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 662/958 [04:01<01:47,  2.75it/s, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 662/958 [04:02<01:47,  2.75it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 663/958 [04:02<01:46,  2.76it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 663/958 [04:02<01:46,  2.76it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 664/958 [04:02<01:46,  2.75it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 664/958 [04:03<01:46,  2.75it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 665/958 [04:03<01:47,  2.73it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 665/958 [04:03<01:47,  2.73it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 666/958 [04:03<01:46,  2.74it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 666/958 [04:03<01:46,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 667/958 [04:03<01:46,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 667/958 [04:04<01:46,  2.74it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 668/958 [04:04<01:45,  2.75it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 668/958 [04:04<01:45,  2.75it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 669/958 [04:04<01:45,  2.75it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 669/958 [04:04<01:45,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 670/958 [04:04<01:44,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 670/958 [04:05<01:44,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  70%|███████   | 671/958 [04:05<01:44,  2.75it/s, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  70%|███████   | 671/958 [04:05<01:44,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  70%|███████   | 672/958 [04:05<01:43,  2.76it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  70%|███████   | 672/958 [04:05<01:43,  2.76it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|███████   | 673/958 [04:05<01:43,  2.76it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  70%|███████   | 673/958 [04:06<01:43,  2.76it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  70%|███████   | 674/958 [04:06<01:42,  2.76it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  70%|███████   | 674/958 [04:06<01:42,  2.76it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  70%|███████   | 675/958 [04:06<01:42,  2.76it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  70%|███████   | 675/958 [04:07<01:42,  2.76it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  71%|███████   | 676/958 [04:07<01:43,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  71%|███████   | 676/958 [04:07<01:43,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  71%|███████   | 677/958 [04:07<01:42,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  71%|███████   | 677/958 [04:07<01:42,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  71%|███████   | 678/958 [04:07<01:42,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  71%|███████   | 678/958 [04:08<01:42,  2.73it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  71%|███████   | 679/958 [04:08<01:41,  2.74it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  71%|███████   | 679/958 [04:08<01:41,  2.74it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  71%|███████   | 680/958 [04:08<01:42,  2.72it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  71%|███████   | 680/958 [04:08<01:42,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  71%|███████   | 681/958 [04:08<01:41,  2.72it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  71%|███████   | 681/958 [04:09<01:41,  2.72it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  71%|███████   | 682/958 [04:09<01:41,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  71%|███████   | 682/958 [04:09<01:41,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 683/958 [04:09<01:40,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 683/958 [04:09<01:40,  2.73it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 684/958 [04:09<01:40,  2.73it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 684/958 [04:10<01:40,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 685/958 [04:10<01:39,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 685/958 [04:10<01:39,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 686/958 [04:10<01:38,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 686/958 [04:11<01:38,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 687/958 [04:11<01:38,  2.76it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 687/958 [04:11<01:38,  2.76it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 688/958 [04:11<01:37,  2.76it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 688/958 [04:11<01:37,  2.76it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 689/958 [04:11<01:37,  2.75it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 689/958 [04:12<01:37,  2.75it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 690/958 [04:12<01:37,  2.76it/s, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 690/958 [04:12<01:37,  2.76it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 691/958 [04:12<01:36,  2.76it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 691/958 [04:12<01:36,  2.76it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 692/958 [04:12<01:36,  2.76it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 692/958 [04:13<01:36,  2.76it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 693/958 [04:13<01:36,  2.76it/s, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 693/958 [04:13<01:36,  2.76it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 694/958 [04:13<01:35,  2.77it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 694/958 [04:13<01:35,  2.77it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 695/958 [04:13<01:34,  2.77it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 695/958 [04:14<01:34,  2.77it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 696/958 [04:14<01:34,  2.78it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 696/958 [04:14<01:34,  2.78it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 697/958 [04:14<01:35,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 697/958 [04:15<01:35,  2.74it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 698/958 [04:15<01:35,  2.74it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 698/958 [04:15<01:35,  2.74it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 699/958 [04:15<01:34,  2.75it/s, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 699/958 [04:15<01:34,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 700/958 [04:15<01:34,  2.72it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 700/958 [04:16<01:34,  2.72it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 701/958 [04:16<01:34,  2.71it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 701/958 [04:16<01:34,  2.71it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 702/958 [04:16<01:34,  2.72it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 702/958 [04:16<01:34,  2.72it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 703/958 [04:16<01:33,  2.72it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 703/958 [04:17<01:33,  2.72it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 704/958 [04:17<01:33,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 704/958 [04:17<01:33,  2.73it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 705/958 [04:17<01:31,  2.75it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 705/958 [04:17<01:31,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 706/958 [04:17<01:31,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 706/958 [04:18<01:31,  2.75it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 707/958 [04:18<01:31,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 707/958 [04:18<01:31,  2.73it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 708/958 [04:18<01:31,  2.73it/s, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 708/958 [04:19<01:31,  2.73it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 709/958 [04:19<01:31,  2.72it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 709/958 [04:19<01:31,  2.72it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 710/958 [04:19<01:30,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 710/958 [04:19<01:30,  2.74it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 711/958 [04:19<01:29,  2.74it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 711/958 [04:20<01:29,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 712/958 [04:20<01:29,  2.75it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 712/958 [04:20<01:29,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 713/958 [04:20<01:29,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 713/958 [04:20<01:29,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 714/958 [04:20<01:29,  2.74it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 714/958 [04:21<01:29,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 715/958 [04:21<01:28,  2.75it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 715/958 [04:21<01:28,  2.75it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 716/958 [04:21<01:27,  2.76it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 716/958 [04:21<01:27,  2.76it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 717/958 [04:21<01:26,  2.77it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 717/958 [04:22<01:26,  2.77it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 718/958 [04:22<01:26,  2.76it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 718/958 [04:22<01:26,  2.76it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 719/958 [04:22<01:26,  2.76it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 719/958 [04:23<01:26,  2.76it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 720/958 [04:23<01:26,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 720/958 [04:23<01:26,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 721/958 [04:23<01:26,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 721/958 [04:23<01:26,  2.75it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 722/958 [04:23<01:25,  2.76it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 722/958 [04:24<01:25,  2.76it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 723/958 [04:24<01:25,  2.76it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 723/958 [04:24<01:25,  2.76it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 724/958 [04:24<01:24,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 724/958 [04:24<01:24,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 725/958 [04:24<01:25,  2.73it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 725/958 [04:25<01:25,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 726/958 [04:25<01:24,  2.75it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 726/958 [04:25<01:24,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 727/958 [04:25<01:24,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 727/958 [04:25<01:24,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 728/958 [04:25<01:23,  2.75it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 728/958 [04:26<01:23,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 729/958 [04:26<01:23,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 729/958 [04:26<01:23,  2.75it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 730/958 [04:26<01:22,  2.76it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 730/958 [04:27<01:22,  2.76it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 731/958 [04:27<01:22,  2.75it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 731/958 [04:27<01:22,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 732/958 [04:27<01:22,  2.74it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 732/958 [04:27<01:22,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 733/958 [04:27<01:21,  2.75it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 733/958 [04:28<01:21,  2.75it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 734/958 [04:28<01:21,  2.74it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 734/958 [04:28<01:21,  2.74it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 735/958 [04:28<01:21,  2.73it/s, training_loss=0.255]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 735/958 [04:28<01:21,  2.73it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 736/958 [04:28<01:20,  2.75it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 736/958 [04:29<01:20,  2.75it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 737/958 [04:29<01:20,  2.75it/s, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 737/958 [04:29<01:20,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 738/958 [04:29<01:20,  2.74it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 738/958 [04:29<01:20,  2.74it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 739/958 [04:29<01:19,  2.75it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 739/958 [04:30<01:19,  2.75it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 740/958 [04:30<01:18,  2.76it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 740/958 [04:30<01:18,  2.76it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 741/958 [04:30<01:18,  2.76it/s, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 741/958 [04:31<01:18,  2.76it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 742/958 [04:31<01:18,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 742/958 [04:31<01:18,  2.74it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 743/958 [04:31<01:18,  2.75it/s, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 743/958 [04:31<01:18,  2.75it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 744/958 [04:31<01:17,  2.75it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 744/958 [04:32<01:17,  2.75it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 745/958 [04:32<01:16,  2.77it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 745/958 [04:32<01:16,  2.77it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 746/958 [04:32<01:16,  2.78it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 746/958 [04:32<01:16,  2.78it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 747/958 [04:32<01:16,  2.77it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 747/958 [04:33<01:16,  2.77it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 748/958 [04:33<01:16,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 748/958 [04:33<01:16,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 749/958 [04:33<01:15,  2.76it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 749/958 [04:33<01:15,  2.76it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 750/958 [04:33<01:15,  2.77it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 750/958 [04:34<01:15,  2.77it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 751/958 [04:34<01:15,  2.75it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 751/958 [04:34<01:15,  2.75it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 752/958 [04:34<01:15,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 752/958 [04:35<01:15,  2.74it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 753/958 [04:35<01:15,  2.72it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 753/958 [04:35<01:15,  2.72it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 754/958 [04:35<01:14,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 754/958 [04:35<01:14,  2.73it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 755/958 [04:35<01:14,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 755/958 [04:36<01:14,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 756/958 [04:36<01:13,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 756/958 [04:36<01:13,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 757/958 [04:36<01:12,  2.76it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 757/958 [04:36<01:12,  2.76it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 758/958 [04:36<01:12,  2.76it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 758/958 [04:37<01:12,  2.76it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 759/958 [04:37<01:11,  2.77it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 759/958 [04:37<01:11,  2.77it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 760/958 [04:37<01:11,  2.77it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 760/958 [04:37<01:11,  2.77it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 761/958 [04:37<01:11,  2.76it/s, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 761/958 [04:38<01:11,  2.76it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 762/958 [04:38<01:10,  2.76it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 762/958 [04:38<01:10,  2.76it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 763/958 [04:38<01:10,  2.77it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 763/958 [04:39<01:10,  2.77it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 764/958 [04:39<01:10,  2.74it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 764/958 [04:39<01:10,  2.74it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 765/958 [04:39<01:10,  2.73it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 765/958 [04:39<01:10,  2.73it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 766/958 [04:39<01:10,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 766/958 [04:40<01:10,  2.74it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  80%|████████  | 767/958 [04:40<01:09,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  80%|████████  | 767/958 [04:40<01:09,  2.75it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  80%|████████  | 768/958 [04:40<01:09,  2.75it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  80%|████████  | 768/958 [04:40<01:09,  2.75it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  80%|████████  | 769/958 [04:40<01:08,  2.74it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  80%|████████  | 769/958 [04:41<01:08,  2.74it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  80%|████████  | 770/958 [04:41<01:08,  2.75it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  80%|████████  | 770/958 [04:41<01:08,  2.75it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  80%|████████  | 771/958 [04:41<01:08,  2.74it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  80%|████████  | 771/958 [04:41<01:08,  2.74it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  81%|████████  | 772/958 [04:41<01:08,  2.72it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  81%|████████  | 772/958 [04:42<01:08,  2.72it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  81%|████████  | 773/958 [04:42<01:08,  2.71it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  81%|████████  | 773/958 [04:42<01:08,  2.71it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  81%|████████  | 774/958 [04:42<01:07,  2.73it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  81%|████████  | 774/958 [04:43<01:07,  2.73it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  81%|████████  | 775/958 [04:43<01:07,  2.72it/s, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  81%|████████  | 775/958 [04:43<01:07,  2.72it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  81%|████████  | 776/958 [04:43<01:06,  2.72it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  81%|████████  | 776/958 [04:43<01:06,  2.72it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  81%|████████  | 777/958 [04:43<01:06,  2.71it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  81%|████████  | 777/958 [04:44<01:06,  2.71it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  81%|████████  | 778/958 [04:44<01:06,  2.72it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  81%|████████  | 778/958 [04:44<01:06,  2.72it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 779/958 [04:44<01:05,  2.74it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 779/958 [04:44<01:05,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 780/958 [04:44<01:04,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 780/958 [04:45<01:04,  2.75it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 781/958 [04:45<01:04,  2.74it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 781/958 [04:45<01:04,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 782/958 [04:45<01:04,  2.75it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 782/958 [04:45<01:04,  2.75it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 783/958 [04:46<01:03,  2.74it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 783/958 [04:46<01:03,  2.74it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 784/958 [04:46<01:03,  2.75it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 784/958 [04:46<01:03,  2.75it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 785/958 [04:46<01:02,  2.77it/s, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 785/958 [04:47<01:02,  2.77it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 786/958 [04:47<01:02,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 786/958 [04:47<01:02,  2.76it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 787/958 [04:47<01:02,  2.74it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 787/958 [04:47<01:02,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 788/958 [04:47<01:01,  2.75it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 788/958 [04:48<01:01,  2.75it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 789/958 [04:48<01:01,  2.76it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 789/958 [04:48<01:01,  2.76it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 790/958 [04:48<01:01,  2.75it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 790/958 [04:48<01:01,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 791/958 [04:48<01:00,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 791/958 [04:49<01:00,  2.75it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 792/958 [04:49<01:00,  2.76it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 792/958 [04:49<01:00,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 793/958 [04:49<00:59,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 793/958 [04:49<00:59,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 794/958 [04:49<00:59,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 794/958 [04:50<00:59,  2.75it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 795/958 [04:50<00:59,  2.75it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 795/958 [04:50<00:59,  2.75it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 796/958 [04:50<00:58,  2.76it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 796/958 [04:51<00:58,  2.76it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 797/958 [04:51<00:58,  2.76it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 797/958 [04:51<00:58,  2.76it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 798/958 [04:51<00:58,  2.75it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 798/958 [04:51<00:58,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 799/958 [04:51<00:57,  2.76it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 799/958 [04:52<00:57,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 800/958 [04:52<00:57,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 800/958 [04:52<00:57,  2.75it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 801/958 [04:52<00:56,  2.76it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 801/958 [04:52<00:56,  2.76it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 802/958 [04:52<00:56,  2.77it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 802/958 [04:53<00:56,  2.77it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 803/958 [04:53<00:56,  2.75it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 803/958 [04:53<00:56,  2.75it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 804/958 [04:53<00:55,  2.75it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 804/958 [04:53<00:55,  2.75it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 805/958 [04:53<00:55,  2.75it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 805/958 [04:54<00:55,  2.75it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 806/958 [04:54<00:55,  2.75it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 806/958 [04:54<00:55,  2.75it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 807/958 [04:54<00:54,  2.75it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 807/958 [04:55<00:54,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 808/958 [04:55<00:54,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 808/958 [04:55<00:54,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 809/958 [04:55<00:54,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 809/958 [04:55<00:54,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 810/958 [04:55<00:53,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 810/958 [04:56<00:53,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 811/958 [04:56<00:53,  2.77it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 811/958 [04:56<00:53,  2.77it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 812/958 [04:56<00:52,  2.78it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 812/958 [04:56<00:52,  2.78it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 813/958 [04:56<00:52,  2.76it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 813/958 [04:57<00:52,  2.76it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 814/958 [04:57<00:51,  2.77it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 814/958 [04:57<00:51,  2.77it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 815/958 [04:57<00:51,  2.76it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 815/958 [04:57<00:51,  2.76it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 816/958 [04:57<00:51,  2.75it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 816/958 [04:58<00:51,  2.75it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 817/958 [04:58<00:51,  2.76it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 817/958 [04:58<00:51,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 818/958 [04:58<00:50,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 818/958 [04:59<00:50,  2.76it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 819/958 [04:59<00:50,  2.76it/s, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 819/958 [04:59<00:50,  2.76it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 820/958 [04:59<00:50,  2.76it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 820/958 [04:59<00:50,  2.76it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 821/958 [04:59<00:49,  2.75it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 821/958 [05:00<00:49,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 822/958 [05:00<00:49,  2.73it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 822/958 [05:00<00:49,  2.73it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 823/958 [05:00<00:49,  2.73it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 823/958 [05:00<00:49,  2.73it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 824/958 [05:00<00:48,  2.75it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 824/958 [05:01<00:48,  2.75it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 825/958 [05:01<00:48,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 825/958 [05:01<00:48,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 826/958 [05:01<00:48,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 826/958 [05:01<00:48,  2.74it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 827/958 [05:01<00:47,  2.74it/s, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 827/958 [05:02<00:47,  2.74it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 828/958 [05:02<00:47,  2.75it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 828/958 [05:02<00:47,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 829/958 [05:02<00:46,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 829/958 [05:03<00:46,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 830/958 [05:03<00:46,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 830/958 [05:03<00:46,  2.75it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 831/958 [05:03<00:46,  2.75it/s, training_loss=0.287]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 831/958 [05:03<00:46,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 832/958 [05:03<00:45,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 832/958 [05:04<00:45,  2.74it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 833/958 [05:04<00:45,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 833/958 [05:04<00:45,  2.73it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 834/958 [05:04<00:45,  2.73it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 834/958 [05:04<00:45,  2.73it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 835/958 [05:04<00:45,  2.73it/s, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 835/958 [05:05<00:45,  2.73it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 836/958 [05:05<00:44,  2.74it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 836/958 [05:05<00:44,  2.74it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 837/958 [05:05<00:44,  2.74it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 837/958 [05:05<00:44,  2.74it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 838/958 [05:05<00:43,  2.76it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 838/958 [05:06<00:43,  2.76it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 839/958 [05:06<00:43,  2.74it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 839/958 [05:06<00:43,  2.74it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 840/958 [05:06<00:43,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 840/958 [05:07<00:43,  2.73it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 841/958 [05:07<00:42,  2.74it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 841/958 [05:07<00:42,  2.74it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 842/958 [05:07<00:41,  2.76it/s, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 842/958 [05:07<00:41,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 843/958 [05:07<00:41,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 843/958 [05:08<00:41,  2.76it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 844/958 [05:08<00:41,  2.76it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 844/958 [05:08<00:41,  2.76it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 845/958 [05:08<00:40,  2.76it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 845/958 [05:08<00:40,  2.76it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 846/958 [05:08<00:40,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 846/958 [05:09<00:40,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 847/958 [05:09<00:40,  2.72it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 847/958 [05:09<00:40,  2.72it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 848/958 [05:09<00:40,  2.72it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 848/958 [05:09<00:40,  2.72it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 849/958 [05:10<00:40,  2.71it/s, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 849/958 [05:10<00:40,  2.71it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 850/958 [05:10<00:39,  2.72it/s, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 850/958 [05:10<00:39,  2.72it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 851/958 [05:10<00:39,  2.73it/s, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 851/958 [05:11<00:39,  2.73it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 852/958 [05:11<00:38,  2.75it/s, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 852/958 [05:11<00:38,  2.75it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 853/958 [05:11<00:38,  2.75it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 853/958 [05:11<00:38,  2.75it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 854/958 [05:11<00:38,  2.73it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 854/958 [05:12<00:38,  2.73it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 855/958 [05:12<00:37,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 855/958 [05:12<00:37,  2.74it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 856/958 [05:12<00:37,  2.74it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 856/958 [05:12<00:37,  2.74it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 857/958 [05:12<00:36,  2.75it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 857/958 [05:13<00:36,  2.75it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 858/958 [05:13<00:36,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 858/958 [05:13<00:36,  2.74it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 859/958 [05:13<00:35,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 859/958 [05:14<00:35,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 860/958 [05:14<00:35,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 860/958 [05:14<00:35,  2.75it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 861/958 [05:14<00:35,  2.74it/s, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 861/958 [05:14<00:35,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 862/958 [05:14<00:34,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 862/958 [05:15<00:34,  2.75it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 863/958 [05:15<00:34,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 863/958 [05:15<00:34,  2.74it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 864/958 [05:15<00:34,  2.74it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 864/958 [05:15<00:34,  2.74it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 865/958 [05:15<00:33,  2.75it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 865/958 [05:16<00:33,  2.75it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 866/958 [05:16<00:33,  2.73it/s, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 866/958 [05:16<00:33,  2.73it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 867/958 [05:16<00:33,  2.73it/s, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 867/958 [05:16<00:33,  2.73it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 868/958 [05:16<00:32,  2.73it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 868/958 [05:17<00:32,  2.73it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 869/958 [05:17<00:32,  2.73it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 869/958 [05:17<00:32,  2.73it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 870/958 [05:17<00:32,  2.73it/s, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 870/958 [05:18<00:32,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 871/958 [05:18<00:32,  2.72it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 871/958 [05:18<00:32,  2.72it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 872/958 [05:18<00:31,  2.71it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 872/958 [05:18<00:31,  2.71it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 873/958 [05:18<00:31,  2.71it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 873/958 [05:19<00:31,  2.71it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 874/958 [05:19<00:31,  2.69it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 874/958 [05:19<00:31,  2.69it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 875/958 [05:19<00:30,  2.72it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 875/958 [05:19<00:30,  2.72it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 876/958 [05:19<00:29,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 876/958 [05:20<00:29,  2.73it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 877/958 [05:20<00:29,  2.73it/s, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 877/958 [05:20<00:29,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 878/958 [05:20<00:29,  2.74it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 878/958 [05:20<00:29,  2.74it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 879/958 [05:20<00:28,  2.75it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 879/958 [05:21<00:28,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 880/958 [05:21<00:28,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 880/958 [05:21<00:28,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 881/958 [05:21<00:28,  2.72it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 881/958 [05:22<00:28,  2.72it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 882/958 [05:22<00:27,  2.72it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 882/958 [05:22<00:27,  2.72it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 883/958 [05:22<00:27,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 883/958 [05:22<00:27,  2.73it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 884/958 [05:22<00:26,  2.75it/s, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 884/958 [05:23<00:26,  2.75it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 885/958 [05:23<00:26,  2.74it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 885/958 [05:23<00:26,  2.74it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 886/958 [05:23<00:26,  2.73it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 886/958 [05:23<00:26,  2.73it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 887/958 [05:23<00:25,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 887/958 [05:24<00:25,  2.75it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 888/958 [05:24<00:25,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 888/958 [05:24<00:25,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 889/958 [05:24<00:25,  2.74it/s, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 889/958 [05:24<00:25,  2.74it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 890/958 [05:24<00:24,  2.74it/s, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 890/958 [05:25<00:24,  2.74it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 891/958 [05:25<00:24,  2.73it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 891/958 [05:25<00:24,  2.73it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 892/958 [05:25<00:24,  2.72it/s, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 892/958 [05:26<00:24,  2.72it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 893/958 [05:26<00:23,  2.74it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 893/958 [05:26<00:23,  2.74it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 894/958 [05:26<00:23,  2.74it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 894/958 [05:26<00:23,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 895/958 [05:26<00:22,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 895/958 [05:27<00:22,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 896/958 [05:27<00:22,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 896/958 [05:27<00:22,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 897/958 [05:27<00:22,  2.71it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 897/958 [05:27<00:22,  2.71it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 898/958 [05:27<00:21,  2.74it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 898/958 [05:28<00:21,  2.74it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 899/958 [05:28<00:21,  2.72it/s, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 899/958 [05:28<00:21,  2.72it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 900/958 [05:28<00:21,  2.73it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 900/958 [05:29<00:21,  2.73it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 901/958 [05:29<00:20,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 901/958 [05:29<00:20,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 902/958 [05:29<00:20,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 902/958 [05:29<00:20,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 903/958 [05:29<00:20,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 903/958 [05:30<00:20,  2.75it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 904/958 [05:30<00:19,  2.77it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 904/958 [05:30<00:19,  2.77it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 905/958 [05:30<00:19,  2.76it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 905/958 [05:30<00:19,  2.76it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 906/958 [05:30<00:18,  2.76it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 906/958 [05:31<00:18,  2.76it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 907/958 [05:31<00:18,  2.75it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 907/958 [05:31<00:18,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 908/958 [05:31<00:18,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 908/958 [05:31<00:18,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 909/958 [05:31<00:17,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 909/958 [05:32<00:17,  2.75it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 910/958 [05:32<00:17,  2.77it/s, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 910/958 [05:32<00:17,  2.77it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 911/958 [05:32<00:16,  2.78it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 911/958 [05:32<00:16,  2.78it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 912/958 [05:33<00:16,  2.76it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 912/958 [05:33<00:16,  2.76it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 913/958 [05:33<00:16,  2.77it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 913/958 [05:33<00:16,  2.77it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 914/958 [05:33<00:15,  2.77it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 914/958 [05:34<00:15,  2.77it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 915/958 [05:34<00:15,  2.76it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 915/958 [05:34<00:15,  2.76it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 916/958 [05:34<00:15,  2.76it/s, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 916/958 [05:34<00:15,  2.76it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 917/958 [05:34<00:14,  2.77it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 917/958 [05:35<00:14,  2.77it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 918/958 [05:35<00:14,  2.77it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 918/958 [05:35<00:14,  2.77it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 919/958 [05:35<00:14,  2.77it/s, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 919/958 [05:35<00:14,  2.77it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 920/958 [05:35<00:13,  2.75it/s, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 920/958 [05:36<00:13,  2.75it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 921/958 [05:36<00:13,  2.76it/s, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 921/958 [05:36<00:13,  2.76it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 922/958 [05:36<00:13,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 922/958 [05:36<00:13,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 923/958 [05:36<00:12,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 923/958 [05:37<00:12,  2.75it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 924/958 [05:37<00:12,  2.75it/s, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 924/958 [05:37<00:12,  2.75it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 925/958 [05:37<00:12,  2.75it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 925/958 [05:38<00:12,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 926/958 [05:38<00:11,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 926/958 [05:38<00:11,  2.74it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 927/958 [05:38<00:11,  2.74it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 927/958 [05:38<00:11,  2.74it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 928/958 [05:38<00:11,  2.73it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 928/958 [05:39<00:11,  2.73it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 929/958 [05:39<00:10,  2.74it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 929/958 [05:39<00:10,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 930/958 [05:39<00:10,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 930/958 [05:39<00:10,  2.74it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 931/958 [05:39<00:09,  2.75it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 931/958 [05:40<00:09,  2.75it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 932/958 [05:40<00:09,  2.75it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 932/958 [05:40<00:09,  2.75it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 933/958 [05:40<00:09,  2.76it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 933/958 [05:40<00:09,  2.76it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 934/958 [05:40<00:08,  2.76it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 934/958 [05:41<00:08,  2.76it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 935/958 [05:41<00:08,  2.76it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 935/958 [05:41<00:08,  2.76it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 936/958 [05:41<00:07,  2.75it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 936/958 [05:42<00:07,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 937/958 [05:42<00:07,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 937/958 [05:42<00:07,  2.75it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 938/958 [05:42<00:07,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 938/958 [05:42<00:07,  2.73it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 939/958 [05:42<00:06,  2.74it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 939/958 [05:43<00:06,  2.74it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 940/958 [05:43<00:06,  2.74it/s, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 940/958 [05:43<00:06,  2.74it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 941/958 [05:43<00:06,  2.73it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 941/958 [05:43<00:06,  2.73it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 942/958 [05:43<00:05,  2.74it/s, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 942/958 [05:44<00:05,  2.74it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 943/958 [05:44<00:05,  2.77it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 943/958 [05:44<00:05,  2.77it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 944/958 [05:44<00:05,  2.74it/s, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 944/958 [05:44<00:05,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 945/958 [05:45<00:04,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 945/958 [05:45<00:04,  2.75it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 946/958 [05:45<00:04,  2.75it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 946/958 [05:45<00:04,  2.75it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 947/958 [05:45<00:04,  2.74it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 947/958 [05:46<00:04,  2.74it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 948/958 [05:46<00:03,  2.75it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 948/958 [05:46<00:03,  2.75it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 949/958 [05:46<00:03,  2.76it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 949/958 [05:46<00:03,  2.76it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 950/958 [05:46<00:02,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 950/958 [05:47<00:02,  2.75it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 951/958 [05:47<00:02,  2.77it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 951/958 [05:47<00:02,  2.77it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 952/958 [05:47<00:02,  2.77it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 952/958 [05:47<00:02,  2.77it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 953/958 [05:47<00:01,  2.77it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 953/958 [05:48<00:01,  2.77it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 954/958 [05:48<00:01,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 954/958 [05:48<00:01,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 955/958 [05:48<00:01,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 955/958 [05:48<00:01,  2.74it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 956/958 [05:49<00:00,  2.74it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 956/958 [05:49<00:00,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 957/958 [05:49<00:00,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 957/958 [05:49<00:00,  2.73it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 2: 100%|██████████| 958/958 [05:49<00:00,  2.90it/s, training_loss=0.027]\u001b[A\n",
            " 10%|█         | 1/10 [12:23<58:48, 392.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 2\n",
            "Training loss: 0.36191536726076196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0%|          | 0/320 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.131]\u001b[A\n",
            "\n",
            "  0%|          | 1/320 [00:00<00:33,  9.44it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.089]\u001b[A\n",
            "\n",
            "  1%|          | 2/320 [00:00<00:35,  8.86it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.112]\u001b[A\n",
            "\n",
            "  1%|          | 3/320 [00:00<00:36,  8.66it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.176]\u001b[A\n",
            "\n",
            "  1%|▏         | 4/320 [00:00<00:37,  8.54it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.142]\u001b[A\n",
            "\n",
            "  2%|▏         | 5/320 [00:00<00:37,  8.45it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.133]\u001b[A\n",
            "\n",
            "  2%|▏         | 6/320 [00:00<00:36,  8.51it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.147]\u001b[A\n",
            "\n",
            "  2%|▏         | 7/320 [00:00<00:37,  8.45it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.199]\u001b[A\n",
            "\n",
            "  2%|▎         | 8/320 [00:00<00:39,  7.94it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.184]\u001b[A\n",
            "\n",
            "  3%|▎         | 9/320 [00:01<00:38,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.117]\u001b[A\n",
            "\n",
            "  3%|▎         | 10/320 [00:01<00:37,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            "  3%|▎         | 11/320 [00:01<00:38,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.119]\u001b[A\n",
            "\n",
            "  4%|▍         | 12/320 [00:01<00:38,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.112]\u001b[A\n",
            "\n",
            "  4%|▍         | 13/320 [00:01<00:37,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.108]\u001b[A\n",
            "\n",
            "  4%|▍         | 14/320 [00:01<00:37,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.252]\u001b[A\n",
            "\n",
            "  5%|▍         | 15/320 [00:01<00:37,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.253]\u001b[A\n",
            "\n",
            "  5%|▌         | 16/320 [00:01<00:37,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.143]\u001b[A\n",
            "\n",
            "  5%|▌         | 17/320 [00:02<00:36,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.207]\u001b[A\n",
            "\n",
            "  6%|▌         | 18/320 [00:02<00:36,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.117]\u001b[A\n",
            "\n",
            "  6%|▌         | 19/320 [00:02<00:36,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.188]\u001b[A\n",
            "\n",
            "  6%|▋         | 20/320 [00:02<00:36,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.234]\u001b[A\n",
            "\n",
            "  7%|▋         | 21/320 [00:02<00:36,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.222]\u001b[A\n",
            "\n",
            "  7%|▋         | 22/320 [00:02<00:36,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.081]\u001b[A\n",
            "\n",
            "  7%|▋         | 23/320 [00:02<00:36,  8.06it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.200]\u001b[A\n",
            "\n",
            "  8%|▊         | 24/320 [00:02<00:36,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.275]\u001b[A\n",
            "\n",
            "  8%|▊         | 25/320 [00:03<00:36,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.209]\u001b[A\n",
            "\n",
            "  8%|▊         | 26/320 [00:03<00:36,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.131]\u001b[A\n",
            "\n",
            "  8%|▊         | 27/320 [00:03<00:35,  8.35it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.143]\u001b[A\n",
            "\n",
            "  9%|▉         | 28/320 [00:03<00:35,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.196]\u001b[A\n",
            "\n",
            "  9%|▉         | 29/320 [00:03<00:35,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.166]\u001b[A\n",
            "\n",
            "  9%|▉         | 30/320 [00:03<00:35,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.162]\u001b[A\n",
            "\n",
            " 10%|▉         | 31/320 [00:03<00:35,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 10%|█         | 32/320 [00:03<00:34,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.190]\u001b[A\n",
            "\n",
            " 10%|█         | 33/320 [00:04<00:34,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.126]\u001b[A\n",
            "\n",
            " 11%|█         | 34/320 [00:04<00:34,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.198]\u001b[A\n",
            "\n",
            " 11%|█         | 35/320 [00:04<00:34,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.226]\u001b[A\n",
            "\n",
            " 11%|█▏        | 36/320 [00:04<00:35,  8.04it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.287]\u001b[A\n",
            "\n",
            " 12%|█▏        | 37/320 [00:04<00:34,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.117]\u001b[A\n",
            "\n",
            " 12%|█▏        | 38/320 [00:04<00:34,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.134]\u001b[A\n",
            "\n",
            " 12%|█▏        | 39/320 [00:04<00:33,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            " 12%|█▎        | 40/320 [00:04<00:34,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 13%|█▎        | 41/320 [00:04<00:33,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.203]\u001b[A\n",
            "\n",
            " 13%|█▎        | 42/320 [00:05<00:33,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.235]\u001b[A\n",
            "\n",
            " 13%|█▎        | 43/320 [00:05<00:33,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.219]\u001b[A\n",
            "\n",
            " 14%|█▍        | 44/320 [00:05<00:33,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.367]\u001b[A\n",
            "\n",
            " 14%|█▍        | 45/320 [00:05<00:33,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.213]\u001b[A\n",
            "\n",
            " 14%|█▍        | 46/320 [00:05<00:32,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.186]\u001b[A\n",
            "\n",
            " 15%|█▍        | 47/320 [00:05<00:33,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.209]\u001b[A\n",
            "\n",
            " 15%|█▌        | 48/320 [00:05<00:33,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.181]\u001b[A\n",
            "\n",
            " 15%|█▌        | 49/320 [00:05<00:33,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.098]\u001b[A\n",
            "\n",
            " 16%|█▌        | 50/320 [00:06<00:33,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            " 16%|█▌        | 51/320 [00:06<00:32,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.085]\u001b[A\n",
            "\n",
            " 16%|█▋        | 52/320 [00:06<00:32,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.234]\u001b[A\n",
            "\n",
            " 17%|█▋        | 53/320 [00:06<00:32,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.145]\u001b[A\n",
            "\n",
            " 17%|█▋        | 54/320 [00:06<00:32,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.121]\u001b[A\n",
            "\n",
            " 17%|█▋        | 55/320 [00:06<00:32,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.249]\u001b[A\n",
            "\n",
            " 18%|█▊        | 56/320 [00:06<00:32,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.140]\u001b[A\n",
            "\n",
            " 18%|█▊        | 57/320 [00:06<00:32,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.099]\u001b[A\n",
            "\n",
            " 18%|█▊        | 58/320 [00:07<00:32,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.050]\u001b[A\n",
            "\n",
            " 18%|█▊        | 59/320 [00:07<00:32,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.126]\u001b[A\n",
            "\n",
            " 19%|█▉        | 60/320 [00:07<00:31,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.246]\u001b[A\n",
            "\n",
            " 19%|█▉        | 61/320 [00:07<00:31,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.173]\u001b[A\n",
            "\n",
            " 19%|█▉        | 62/320 [00:07<00:31,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.155]\u001b[A\n",
            "\n",
            " 20%|█▉        | 63/320 [00:07<00:31,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.054]\u001b[A\n",
            "\n",
            " 20%|██        | 64/320 [00:07<00:31,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.286]\u001b[A\n",
            "\n",
            " 20%|██        | 65/320 [00:07<00:30,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.165]\u001b[A\n",
            "\n",
            " 21%|██        | 66/320 [00:08<00:30,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.271]\u001b[A\n",
            "\n",
            " 21%|██        | 67/320 [00:08<00:30,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.095]\u001b[A\n",
            "\n",
            " 21%|██▏       | 68/320 [00:08<00:30,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.218]\u001b[A\n",
            "\n",
            " 22%|██▏       | 69/320 [00:08<00:30,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.153]\u001b[A\n",
            "\n",
            " 22%|██▏       | 70/320 [00:08<00:30,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 22%|██▏       | 71/320 [00:08<00:30,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.147]\u001b[A\n",
            "\n",
            " 22%|██▎       | 72/320 [00:08<00:30,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.199]\u001b[A\n",
            "\n",
            " 23%|██▎       | 73/320 [00:08<00:29,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            " 23%|██▎       | 74/320 [00:08<00:29,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 23%|██▎       | 75/320 [00:09<00:29,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.081]\u001b[A\n",
            "\n",
            " 24%|██▍       | 76/320 [00:09<00:29,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.179]\u001b[A\n",
            "\n",
            " 24%|██▍       | 77/320 [00:09<00:29,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 24%|██▍       | 78/320 [00:09<00:29,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.318]\u001b[A\n",
            "\n",
            " 25%|██▍       | 79/320 [00:09<00:29,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.210]\u001b[A\n",
            "\n",
            " 25%|██▌       | 80/320 [00:09<00:29,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.304]\u001b[A\n",
            "\n",
            " 25%|██▌       | 81/320 [00:09<00:29,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.110]\u001b[A\n",
            "\n",
            " 26%|██▌       | 82/320 [00:09<00:28,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.133]\u001b[A\n",
            "\n",
            " 26%|██▌       | 83/320 [00:10<00:28,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.206]\u001b[A\n",
            "\n",
            " 26%|██▋       | 84/320 [00:10<00:28,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.074]\u001b[A\n",
            "\n",
            " 27%|██▋       | 85/320 [00:10<00:29,  7.96it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.148]\u001b[A\n",
            "\n",
            " 27%|██▋       | 86/320 [00:10<00:28,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.181]\u001b[A\n",
            "\n",
            " 27%|██▋       | 87/320 [00:10<00:28,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.106]\u001b[A\n",
            "\n",
            " 28%|██▊       | 88/320 [00:10<00:28,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.183]\u001b[A\n",
            "\n",
            " 28%|██▊       | 89/320 [00:10<00:28,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.190]\u001b[A\n",
            "\n",
            " 28%|██▊       | 90/320 [00:10<00:27,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.071]\u001b[A\n",
            "\n",
            " 28%|██▊       | 91/320 [00:11<00:27,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.183]\u001b[A\n",
            "\n",
            " 29%|██▉       | 92/320 [00:11<00:27,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.223]\u001b[A\n",
            "\n",
            " 29%|██▉       | 93/320 [00:11<00:27,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.142]\u001b[A\n",
            "\n",
            " 29%|██▉       | 94/320 [00:11<00:27,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.243]\u001b[A\n",
            "\n",
            " 30%|██▉       | 95/320 [00:11<00:27,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 30%|███       | 96/320 [00:11<00:27,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.066]\u001b[A\n",
            "\n",
            " 30%|███       | 97/320 [00:11<00:26,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.180]\u001b[A\n",
            "\n",
            " 31%|███       | 98/320 [00:11<00:26,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.155]\u001b[A\n",
            "\n",
            " 31%|███       | 99/320 [00:12<00:26,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.280]\u001b[A\n",
            "\n",
            " 31%|███▏      | 100/320 [00:12<00:26,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.117]\u001b[A\n",
            "\n",
            " 32%|███▏      | 101/320 [00:12<00:26,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.078]\u001b[A\n",
            "\n",
            " 32%|███▏      | 102/320 [00:12<00:26,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 32%|███▏      | 103/320 [00:12<00:26,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.138]\u001b[A\n",
            "\n",
            " 32%|███▎      | 104/320 [00:12<00:26,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.272]\u001b[A\n",
            "\n",
            " 33%|███▎      | 105/320 [00:12<00:26,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.072]\u001b[A\n",
            "\n",
            " 33%|███▎      | 106/320 [00:12<00:25,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.156]\u001b[A\n",
            "\n",
            " 33%|███▎      | 107/320 [00:13<00:25,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.170]\u001b[A\n",
            "\n",
            " 34%|███▍      | 108/320 [00:13<00:25,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.268]\u001b[A\n",
            "\n",
            " 34%|███▍      | 109/320 [00:13<00:25,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.230]\u001b[A\n",
            "\n",
            " 34%|███▍      | 110/320 [00:13<00:25,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.198]\u001b[A\n",
            "\n",
            " 35%|███▍      | 111/320 [00:13<00:25,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 35%|███▌      | 112/320 [00:13<00:25,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 35%|███▌      | 113/320 [00:13<00:25,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.113]\u001b[A\n",
            "\n",
            " 36%|███▌      | 114/320 [00:13<00:24,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.250]\u001b[A\n",
            "\n",
            " 36%|███▌      | 115/320 [00:13<00:25,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.104]\u001b[A\n",
            "\n",
            " 36%|███▋      | 116/320 [00:14<00:24,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            " 37%|███▋      | 117/320 [00:14<00:24,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.379]\u001b[A\n",
            "\n",
            " 37%|███▋      | 118/320 [00:14<00:25,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.130]\u001b[A\n",
            "\n",
            " 37%|███▋      | 119/320 [00:14<00:24,  8.04it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.187]\u001b[A\n",
            "\n",
            " 38%|███▊      | 120/320 [00:14<00:24,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 38%|███▊      | 121/320 [00:14<00:24,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.259]\u001b[A\n",
            "\n",
            " 38%|███▊      | 122/320 [00:14<00:24,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.159]\u001b[A\n",
            "\n",
            " 38%|███▊      | 123/320 [00:14<00:24,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.207]\u001b[A\n",
            "\n",
            " 39%|███▉      | 124/320 [00:15<00:23,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.138]\u001b[A\n",
            "\n",
            " 39%|███▉      | 125/320 [00:15<00:24,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.134]\u001b[A\n",
            "\n",
            " 39%|███▉      | 126/320 [00:15<00:23,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.260]\u001b[A\n",
            "\n",
            " 40%|███▉      | 127/320 [00:15<00:23,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.143]\u001b[A\n",
            "\n",
            " 40%|████      | 128/320 [00:15<00:23,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            " 40%|████      | 129/320 [00:15<00:23,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.029]\u001b[A\n",
            "\n",
            " 41%|████      | 130/320 [00:15<00:23,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.218]\u001b[A\n",
            "\n",
            " 41%|████      | 131/320 [00:15<00:23,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.101]\u001b[A\n",
            "\n",
            " 41%|████▏     | 132/320 [00:16<00:23,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.225]\u001b[A\n",
            "\n",
            " 42%|████▏     | 133/320 [00:16<00:22,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.049]\u001b[A\n",
            "\n",
            " 42%|████▏     | 134/320 [00:16<00:22,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.159]\u001b[A\n",
            "\n",
            " 42%|████▏     | 135/320 [00:16<00:22,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.099]\u001b[A\n",
            "\n",
            " 42%|████▎     | 136/320 [00:16<00:22,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.144]\u001b[A\n",
            "\n",
            " 43%|████▎     | 137/320 [00:16<00:22,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 43%|████▎     | 138/320 [00:16<00:22,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.184]\u001b[A\n",
            "\n",
            " 43%|████▎     | 139/320 [00:16<00:21,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.103]\u001b[A\n",
            "\n",
            " 44%|████▍     | 140/320 [00:17<00:21,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.102]\u001b[A\n",
            "\n",
            " 44%|████▍     | 141/320 [00:17<00:21,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.180]\u001b[A\n",
            "\n",
            " 44%|████▍     | 142/320 [00:17<00:21,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.178]\u001b[A\n",
            "\n",
            " 45%|████▍     | 143/320 [00:17<00:21,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.110]\u001b[A\n",
            "\n",
            " 45%|████▌     | 144/320 [00:17<00:21,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.340]\u001b[A\n",
            "\n",
            " 45%|████▌     | 145/320 [00:17<00:21,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.065]\u001b[A\n",
            "\n",
            " 46%|████▌     | 146/320 [00:17<00:21,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.053]\u001b[A\n",
            "\n",
            " 46%|████▌     | 147/320 [00:17<00:21,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.082]\u001b[A\n",
            "\n",
            " 46%|████▋     | 148/320 [00:18<00:20,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.268]\u001b[A\n",
            "\n",
            " 47%|████▋     | 149/320 [00:18<00:20,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.169]\u001b[A\n",
            "\n",
            " 47%|████▋     | 150/320 [00:18<00:20,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.195]\u001b[A\n",
            "\n",
            " 47%|████▋     | 151/320 [00:18<00:20,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.082]\u001b[A\n",
            "\n",
            " 48%|████▊     | 152/320 [00:18<00:20,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.224]\u001b[A\n",
            "\n",
            " 48%|████▊     | 153/320 [00:18<00:20,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.203]\u001b[A\n",
            "\n",
            " 48%|████▊     | 154/320 [00:18<00:20,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 48%|████▊     | 155/320 [00:18<00:19,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.118]\u001b[A\n",
            "\n",
            " 49%|████▉     | 156/320 [00:19<00:19,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.225]\u001b[A\n",
            "\n",
            " 49%|████▉     | 157/320 [00:19<00:19,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.287]\u001b[A\n",
            "\n",
            " 49%|████▉     | 158/320 [00:19<00:19,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.235]\u001b[A\n",
            "\n",
            " 50%|████▉     | 159/320 [00:19<00:19,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.143]\u001b[A\n",
            "\n",
            " 50%|█████     | 160/320 [00:19<00:19,  8.06it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.181]\u001b[A\n",
            "\n",
            " 50%|█████     | 161/320 [00:19<00:19,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.245]\u001b[A\n",
            "\n",
            " 51%|█████     | 162/320 [00:19<00:19,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.255]\u001b[A\n",
            "\n",
            " 51%|█████     | 163/320 [00:19<00:18,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.238]\u001b[A\n",
            "\n",
            " 51%|█████▏    | 164/320 [00:19<00:18,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.179]\u001b[A\n",
            "\n",
            " 52%|█████▏    | 165/320 [00:20<00:18,  8.32it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.178]\u001b[A\n",
            "\n",
            " 52%|█████▏    | 166/320 [00:20<00:18,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.279]\u001b[A\n",
            "\n",
            " 52%|█████▏    | 167/320 [00:20<00:18,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.321]\u001b[A\n",
            "\n",
            " 52%|█████▎    | 168/320 [00:20<00:18,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.211]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 169/320 [00:20<00:18,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.208]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 170/320 [00:20<00:18,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.127]\u001b[A\n",
            "\n",
            " 53%|█████▎    | 171/320 [00:20<00:17,  8.36it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.315]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 172/320 [00:20<00:17,  8.29it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.133]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 173/320 [00:21<00:17,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.245]\u001b[A\n",
            "\n",
            " 54%|█████▍    | 174/320 [00:21<00:17,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.134]\u001b[A\n",
            "\n",
            " 55%|█████▍    | 175/320 [00:21<00:17,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.181]\u001b[A\n",
            "\n",
            " 55%|█████▌    | 176/320 [00:21<00:17,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.111]\u001b[A\n",
            "\n",
            " 55%|█████▌    | 177/320 [00:21<00:17,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.173]\u001b[A\n",
            "\n",
            " 56%|█████▌    | 178/320 [00:21<00:17,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.198]\u001b[A\n",
            "\n",
            " 56%|█████▌    | 179/320 [00:21<00:17,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.367]\u001b[A\n",
            "\n",
            " 56%|█████▋    | 180/320 [00:21<00:16,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.036]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 181/320 [00:22<00:16,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.306]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 182/320 [00:22<00:16,  8.31it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.226]\u001b[A\n",
            "\n",
            " 57%|█████▋    | 183/320 [00:22<00:16,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.110]\u001b[A\n",
            "\n",
            " 57%|█████▊    | 184/320 [00:22<00:16,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 185/320 [00:22<00:16,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.205]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 186/320 [00:22<00:16,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.242]\u001b[A\n",
            "\n",
            " 58%|█████▊    | 187/320 [00:22<00:16,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.264]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 188/320 [00:22<00:16,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.336]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 189/320 [00:23<00:15,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.156]\u001b[A\n",
            "\n",
            " 59%|█████▉    | 190/320 [00:23<00:15,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.184]\u001b[A\n",
            "\n",
            " 60%|█████▉    | 191/320 [00:23<00:15,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.101]\u001b[A\n",
            "\n",
            " 60%|██████    | 192/320 [00:23<00:15,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.232]\u001b[A\n",
            "\n",
            " 60%|██████    | 193/320 [00:23<00:15,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.164]\u001b[A\n",
            "\n",
            " 61%|██████    | 194/320 [00:23<00:15,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.159]\u001b[A\n",
            "\n",
            " 61%|██████    | 195/320 [00:23<00:14,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.182]\u001b[A\n",
            "\n",
            " 61%|██████▏   | 196/320 [00:23<00:14,  8.33it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.182]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 197/320 [00:23<00:14,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.359]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 198/320 [00:24<00:14,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 62%|██████▏   | 199/320 [00:24<00:14,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.205]\u001b[A\n",
            "\n",
            " 62%|██████▎   | 200/320 [00:24<00:14,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.129]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 201/320 [00:24<00:14,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.245]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 202/320 [00:24<00:14,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.249]\u001b[A\n",
            "\n",
            " 63%|██████▎   | 203/320 [00:24<00:14,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.209]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 204/320 [00:24<00:14,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.052]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 205/320 [00:24<00:14,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.209]\u001b[A\n",
            "\n",
            " 64%|██████▍   | 206/320 [00:25<00:13,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            " 65%|██████▍   | 207/320 [00:25<00:14,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.178]\u001b[A\n",
            "\n",
            " 65%|██████▌   | 208/320 [00:25<00:13,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.229]\u001b[A\n",
            "\n",
            " 65%|██████▌   | 209/320 [00:25<00:13,  8.03it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.087]\u001b[A\n",
            "\n",
            " 66%|██████▌   | 210/320 [00:25<00:13,  8.03it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.184]\u001b[A\n",
            "\n",
            " 66%|██████▌   | 211/320 [00:25<00:13,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.235]\u001b[A\n",
            "\n",
            " 66%|██████▋   | 212/320 [00:25<00:13,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.135]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 213/320 [00:25<00:13,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.116]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 214/320 [00:26<00:12,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.281]\u001b[A\n",
            "\n",
            " 67%|██████▋   | 215/320 [00:26<00:12,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.149]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 216/320 [00:26<00:12,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.098]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 217/320 [00:26<00:12,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.235]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 218/320 [00:26<00:12,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.064]\u001b[A\n",
            "\n",
            " 68%|██████▊   | 219/320 [00:26<00:12,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.154]\u001b[A\n",
            "\n",
            " 69%|██████▉   | 220/320 [00:26<00:12,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.077]\u001b[A\n",
            "\n",
            " 69%|██████▉   | 221/320 [00:26<00:12,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.134]\u001b[A\n",
            "\n",
            " 69%|██████▉   | 222/320 [00:27<00:12,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.184]\u001b[A\n",
            "\n",
            " 70%|██████▉   | 223/320 [00:27<00:11,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 70%|███████   | 224/320 [00:27<00:11,  8.03it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 70%|███████   | 225/320 [00:27<00:11,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.171]\u001b[A\n",
            "\n",
            " 71%|███████   | 226/320 [00:27<00:11,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.214]\u001b[A\n",
            "\n",
            " 71%|███████   | 227/320 [00:27<00:11,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.140]\u001b[A\n",
            "\n",
            " 71%|███████▏  | 228/320 [00:27<00:11,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.273]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 229/320 [00:27<00:11,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 230/320 [00:28<00:10,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.085]\u001b[A\n",
            "\n",
            " 72%|███████▏  | 231/320 [00:28<00:10,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.112]\u001b[A\n",
            "\n",
            " 72%|███████▎  | 232/320 [00:28<00:10,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.185]\u001b[A\n",
            "\n",
            " 73%|███████▎  | 233/320 [00:28<00:10,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.300]\u001b[A\n",
            "\n",
            " 73%|███████▎  | 234/320 [00:28<00:10,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.176]\u001b[A\n",
            "\n",
            " 73%|███████▎  | 235/320 [00:28<00:10,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.314]\u001b[A\n",
            "\n",
            " 74%|███████▍  | 236/320 [00:28<00:10,  8.01it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.190]\u001b[A\n",
            "\n",
            " 74%|███████▍  | 237/320 [00:28<00:10,  8.03it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.208]\u001b[A\n",
            "\n",
            " 74%|███████▍  | 238/320 [00:29<00:10,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.149]\u001b[A\n",
            "\n",
            " 75%|███████▍  | 239/320 [00:29<00:09,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.147]\u001b[A\n",
            "\n",
            " 75%|███████▌  | 240/320 [00:29<00:10,  8.00it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.283]\u001b[A\n",
            "\n",
            " 75%|███████▌  | 241/320 [00:29<00:09,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.098]\u001b[A\n",
            "\n",
            " 76%|███████▌  | 242/320 [00:29<00:09,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.312]\u001b[A\n",
            "\n",
            " 76%|███████▌  | 243/320 [00:29<00:09,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.208]\u001b[A\n",
            "\n",
            " 76%|███████▋  | 244/320 [00:29<00:09,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.228]\u001b[A\n",
            "\n",
            " 77%|███████▋  | 245/320 [00:29<00:09,  8.30it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.016]\u001b[A\n",
            "\n",
            " 77%|███████▋  | 246/320 [00:30<00:08,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.059]\u001b[A\n",
            "\n",
            " 77%|███████▋  | 247/320 [00:30<00:08,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.121]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 248/320 [00:30<00:08,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.080]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 249/320 [00:30<00:08,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 250/320 [00:30<00:08,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.174]\u001b[A\n",
            "\n",
            " 78%|███████▊  | 251/320 [00:30<00:08,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.204]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 252/320 [00:30<00:08,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.079]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 253/320 [00:30<00:08,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.183]\u001b[A\n",
            "\n",
            " 79%|███████▉  | 254/320 [00:30<00:07,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.134]\u001b[A\n",
            "\n",
            " 80%|███████▉  | 255/320 [00:31<00:07,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.170]\u001b[A\n",
            "\n",
            " 80%|████████  | 256/320 [00:31<00:07,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 80%|████████  | 257/320 [00:31<00:07,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.210]\u001b[A\n",
            "\n",
            " 81%|████████  | 258/320 [00:31<00:07,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.288]\u001b[A\n",
            "\n",
            " 81%|████████  | 259/320 [00:31<00:07,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.343]\u001b[A\n",
            "\n",
            " 81%|████████▏ | 260/320 [00:31<00:07,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.153]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 261/320 [00:31<00:07,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.234]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 262/320 [00:31<00:07,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.162]\u001b[A\n",
            "\n",
            " 82%|████████▏ | 263/320 [00:32<00:06,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.306]\u001b[A\n",
            "\n",
            " 82%|████████▎ | 264/320 [00:32<00:06,  8.26it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.065]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 265/320 [00:32<00:06,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.182]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 266/320 [00:32<00:06,  8.35it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.178]\u001b[A\n",
            "\n",
            " 83%|████████▎ | 267/320 [00:32<00:06,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.153]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 268/320 [00:32<00:06,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.130]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 269/320 [00:32<00:06,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.081]\u001b[A\n",
            "\n",
            " 84%|████████▍ | 270/320 [00:32<00:06,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.281]\u001b[A\n",
            "\n",
            " 85%|████████▍ | 271/320 [00:33<00:05,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.098]\u001b[A\n",
            "\n",
            " 85%|████████▌ | 272/320 [00:33<00:05,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.196]\u001b[A\n",
            "\n",
            " 85%|████████▌ | 273/320 [00:33<00:05,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.192]\u001b[A\n",
            "\n",
            " 86%|████████▌ | 274/320 [00:33<00:05,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.113]\u001b[A\n",
            "\n",
            " 86%|████████▌ | 275/320 [00:33<00:05,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.288]\u001b[A\n",
            "\n",
            " 86%|████████▋ | 276/320 [00:33<00:05,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.198]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 277/320 [00:33<00:05,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 278/320 [00:33<00:05,  8.34it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.194]\u001b[A\n",
            "\n",
            " 87%|████████▋ | 279/320 [00:34<00:04,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.108]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 280/320 [00:34<00:04,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.193]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 281/320 [00:34<00:04,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.232]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 282/320 [00:34<00:04,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.208]\u001b[A\n",
            "\n",
            " 88%|████████▊ | 283/320 [00:34<00:04,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.118]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 284/320 [00:34<00:04,  8.25it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.146]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 285/320 [00:34<00:04,  8.15it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.165]\u001b[A\n",
            "\n",
            " 89%|████████▉ | 286/320 [00:34<00:04,  8.24it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.034]\u001b[A\n",
            "\n",
            " 90%|████████▉ | 287/320 [00:35<00:04,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.161]\u001b[A\n",
            "\n",
            " 90%|█████████ | 288/320 [00:35<00:03,  8.06it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.139]\u001b[A\n",
            "\n",
            " 90%|█████████ | 289/320 [00:35<00:03,  8.17it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.294]\u001b[A\n",
            "\n",
            " 91%|█████████ | 290/320 [00:35<00:03,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.200]\u001b[A\n",
            "\n",
            " 91%|█████████ | 291/320 [00:35<00:03,  8.09it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.231]\u001b[A\n",
            "\n",
            " 91%|█████████▏| 292/320 [00:35<00:03,  8.10it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.075]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 293/320 [00:35<00:03,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.080]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 294/320 [00:35<00:03,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.117]\u001b[A\n",
            "\n",
            " 92%|█████████▏| 295/320 [00:35<00:03,  8.28it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.172]\u001b[A\n",
            "\n",
            " 92%|█████████▎| 296/320 [00:36<00:03,  7.96it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.245]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 297/320 [00:36<00:02,  8.08it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.252]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 298/320 [00:36<00:02,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.108]\u001b[A\n",
            "\n",
            " 93%|█████████▎| 299/320 [00:36<00:02,  8.18it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.073]\u001b[A\n",
            "\n",
            " 94%|█████████▍| 300/320 [00:36<00:02,  8.04it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.209]\u001b[A\n",
            "\n",
            " 94%|█████████▍| 301/320 [00:36<00:02,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.258]\u001b[A\n",
            "\n",
            " 94%|█████████▍| 302/320 [00:36<00:02,  8.02it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.312]\u001b[A\n",
            "\n",
            " 95%|█████████▍| 303/320 [00:36<00:02,  8.13it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.206]\u001b[A\n",
            "\n",
            " 95%|█████████▌| 304/320 [00:37<00:01,  8.16it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.252]\u001b[A\n",
            "\n",
            " 95%|█████████▌| 305/320 [00:37<00:01,  8.11it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.243]\u001b[A\n",
            "\n",
            " 96%|█████████▌| 306/320 [00:37<00:01,  8.12it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.191]\u001b[A\n",
            "\n",
            " 96%|█████████▌| 307/320 [00:37<00:01,  8.21it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.204]\u001b[A\n",
            "\n",
            " 96%|█████████▋| 308/320 [00:37<00:01,  8.07it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.211]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 309/320 [00:37<00:01,  8.05it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.085]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 310/320 [00:37<00:01,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.248]\u001b[A\n",
            "\n",
            " 97%|█████████▋| 311/320 [00:37<00:01,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.230]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 312/320 [00:38<00:00,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.061]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 313/320 [00:38<00:00,  8.14it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.195]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 314/320 [00:38<00:00,  8.22it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.266]\u001b[A\n",
            "\n",
            " 98%|█████████▊| 315/320 [00:38<00:00,  8.20it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.146]\u001b[A\n",
            "\n",
            " 99%|█████████▉| 316/320 [00:38<00:00,  8.19it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.152]\u001b[A\n",
            "\n",
            " 99%|█████████▉| 317/320 [00:38<00:00,  8.27it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.216]\u001b[A\n",
            "\n",
            " 99%|█████████▉| 318/320 [00:38<00:00,  8.23it/s]\u001b[A\u001b[A\n",
            "Epoch 2:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.177]\u001b[A\n",
            "\n",
            "100%|█████████▉| 319/320 [00:38<00:00,  8.14it/s]\u001b[A\u001b[A\n",
            "100%|██████████| 320/320 [00:38<00:00,  8.21it/s]\n",
            "\n",
            " 20%|██        | 2/10 [13:02<52:07, 390.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5407840141560882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/958 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/958 [00:00<?, ?it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 3:   0%|          | 1/958 [00:00<05:44,  2.78it/s, training_loss=0.078]\u001b[A\n",
            "Epoch 3:   0%|          | 1/958 [00:00<05:44,  2.78it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   0%|          | 2/958 [00:00<05:52,  2.72it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   0%|          | 2/958 [00:01<05:52,  2.72it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   0%|          | 3/958 [00:01<05:54,  2.69it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   0%|          | 3/958 [00:01<05:54,  2.69it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 3:   0%|          | 4/958 [00:01<05:49,  2.73it/s, training_loss=0.088]\u001b[A\n",
            "Epoch 3:   0%|          | 4/958 [00:01<05:49,  2.73it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 3:   1%|          | 5/958 [00:01<05:47,  2.74it/s, training_loss=0.105]\u001b[A\n",
            "Epoch 3:   1%|          | 5/958 [00:02<05:47,  2.74it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 3:   1%|          | 6/958 [00:02<05:51,  2.71it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 3:   1%|          | 6/958 [00:02<05:51,  2.71it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   1%|          | 7/958 [00:02<05:48,  2.73it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   1%|          | 7/958 [00:02<05:48,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 3:   1%|          | 8/958 [00:02<05:47,  2.73it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 3:   1%|          | 8/958 [00:03<05:47,  2.73it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   1%|          | 9/958 [00:03<05:48,  2.73it/s, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   1%|          | 9/958 [00:03<05:48,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   1%|          | 10/958 [00:03<05:45,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   1%|          | 10/958 [00:04<05:45,  2.74it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 3:   1%|          | 11/958 [00:04<05:45,  2.74it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 3:   1%|          | 11/958 [00:04<05:45,  2.74it/s, training_loss=0.010]\u001b[A\n",
            "Epoch 3:   1%|▏         | 12/958 [00:04<05:47,  2.72it/s, training_loss=0.010]\u001b[A\n",
            "Epoch 3:   1%|▏         | 12/958 [00:04<05:47,  2.72it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:   1%|▏         | 13/958 [00:04<05:48,  2.71it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:   1%|▏         | 13/958 [00:05<05:48,  2.71it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:   1%|▏         | 14/958 [00:05<05:49,  2.70it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:   1%|▏         | 14/958 [00:05<05:49,  2.70it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 3:   2%|▏         | 15/958 [00:05<05:49,  2.70it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 3:   2%|▏         | 15/958 [00:05<05:49,  2.70it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:   2%|▏         | 16/958 [00:05<05:47,  2.71it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:   2%|▏         | 16/958 [00:06<05:47,  2.71it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 3:   2%|▏         | 17/958 [00:06<05:49,  2.69it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 3:   2%|▏         | 17/958 [00:06<05:49,  2.69it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 3:   2%|▏         | 18/958 [00:06<05:46,  2.71it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 3:   2%|▏         | 18/958 [00:06<05:46,  2.71it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:   2%|▏         | 19/958 [00:07<05:47,  2.70it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:   2%|▏         | 19/958 [00:07<05:47,  2.70it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   2%|▏         | 20/958 [00:07<05:45,  2.71it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   2%|▏         | 20/958 [00:07<05:45,  2.71it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 3:   2%|▏         | 21/958 [00:07<05:45,  2.71it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 3:   2%|▏         | 21/958 [00:08<05:45,  2.71it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 3:   2%|▏         | 22/958 [00:08<05:46,  2.70it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 3:   2%|▏         | 22/958 [00:08<05:46,  2.70it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 3:   2%|▏         | 23/958 [00:08<05:46,  2.70it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 3:   2%|▏         | 23/958 [00:08<05:46,  2.70it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:   3%|▎         | 24/958 [00:08<05:43,  2.72it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:   3%|▎         | 24/958 [00:09<05:43,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 3:   3%|▎         | 25/958 [00:09<05:42,  2.72it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 3:   3%|▎         | 25/958 [00:09<05:42,  2.72it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   3%|▎         | 26/958 [00:09<05:42,  2.72it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   3%|▎         | 26/958 [00:09<05:42,  2.72it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   3%|▎         | 27/958 [00:09<05:39,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   3%|▎         | 27/958 [00:10<05:39,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 3:   3%|▎         | 28/958 [00:10<05:40,  2.73it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 3:   3%|▎         | 28/958 [00:10<05:40,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:   3%|▎         | 29/958 [00:10<05:40,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:   3%|▎         | 29/958 [00:11<05:40,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   3%|▎         | 30/958 [00:11<05:39,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   3%|▎         | 30/958 [00:11<05:39,  2.73it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   3%|▎         | 31/958 [00:11<05:37,  2.74it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   3%|▎         | 31/958 [00:11<05:37,  2.74it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 3:   3%|▎         | 32/958 [00:11<05:36,  2.75it/s, training_loss=0.150]\u001b[A\n",
            "Epoch 3:   3%|▎         | 32/958 [00:12<05:36,  2.75it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:   3%|▎         | 33/958 [00:12<05:37,  2.74it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:   3%|▎         | 33/958 [00:12<05:37,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 3:   4%|▎         | 34/958 [00:12<05:36,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 3:   4%|▎         | 34/958 [00:12<05:36,  2.74it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 3:   4%|▎         | 35/958 [00:12<05:37,  2.74it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 3:   4%|▎         | 35/958 [00:13<05:37,  2.74it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:   4%|▍         | 36/958 [00:13<05:37,  2.73it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:   4%|▍         | 36/958 [00:13<05:37,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:   4%|▍         | 37/958 [00:13<05:36,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:   4%|▍         | 37/958 [00:13<05:36,  2.73it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 3:   4%|▍         | 38/958 [00:13<05:35,  2.74it/s, training_loss=0.161]\u001b[A\n",
            "Epoch 3:   4%|▍         | 38/958 [00:14<05:35,  2.74it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 3:   4%|▍         | 39/958 [00:14<05:36,  2.73it/s, training_loss=0.019]\u001b[A\n",
            "Epoch 3:   4%|▍         | 39/958 [00:14<05:36,  2.73it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:   4%|▍         | 40/958 [00:14<05:36,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:   4%|▍         | 40/958 [00:15<05:36,  2.72it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   4%|▍         | 41/958 [00:15<05:35,  2.73it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   4%|▍         | 41/958 [00:15<05:35,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:   4%|▍         | 42/958 [00:15<05:37,  2.72it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:   4%|▍         | 42/958 [00:15<05:37,  2.72it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:   4%|▍         | 43/958 [00:15<05:35,  2.73it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:   4%|▍         | 43/958 [00:16<05:35,  2.73it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:   5%|▍         | 44/958 [00:16<05:37,  2.71it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:   5%|▍         | 44/958 [00:16<05:37,  2.71it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:   5%|▍         | 45/958 [00:16<05:37,  2.70it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:   5%|▍         | 45/958 [00:16<05:37,  2.70it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 3:   5%|▍         | 46/958 [00:16<05:34,  2.72it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 3:   5%|▍         | 46/958 [00:17<05:34,  2.72it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 3:   5%|▍         | 47/958 [00:17<05:33,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 3:   5%|▍         | 47/958 [00:17<05:33,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 3:   5%|▌         | 48/958 [00:17<05:33,  2.73it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 3:   5%|▌         | 48/958 [00:17<05:33,  2.73it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 3:   5%|▌         | 49/958 [00:17<05:32,  2.73it/s, training_loss=0.139]\u001b[A\n",
            "Epoch 3:   5%|▌         | 49/958 [00:18<05:32,  2.73it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 3:   5%|▌         | 50/958 [00:18<05:31,  2.74it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 3:   5%|▌         | 50/958 [00:18<05:31,  2.74it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:   5%|▌         | 51/958 [00:18<05:34,  2.72it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:   5%|▌         | 51/958 [00:19<05:34,  2.72it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   5%|▌         | 52/958 [00:19<05:31,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:   5%|▌         | 52/958 [00:19<05:31,  2.73it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:   6%|▌         | 53/958 [00:19<05:32,  2.72it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:   6%|▌         | 53/958 [00:19<05:32,  2.72it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:   6%|▌         | 54/958 [00:19<05:31,  2.72it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:   6%|▌         | 54/958 [00:20<05:31,  2.72it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 3:   6%|▌         | 55/958 [00:20<05:33,  2.71it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 3:   6%|▌         | 55/958 [00:20<05:33,  2.71it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 3:   6%|▌         | 56/958 [00:20<05:31,  2.72it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 3:   6%|▌         | 56/958 [00:20<05:31,  2.72it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 3:   6%|▌         | 57/958 [00:20<05:31,  2.72it/s, training_loss=0.246]\u001b[A\n",
            "Epoch 3:   6%|▌         | 57/958 [00:21<05:31,  2.72it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 3:   6%|▌         | 58/958 [00:21<05:29,  2.73it/s, training_loss=0.029]\u001b[A\n",
            "Epoch 3:   6%|▌         | 58/958 [00:21<05:29,  2.73it/s, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   6%|▌         | 59/958 [00:21<05:29,  2.73it/s, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   6%|▌         | 59/958 [00:22<05:29,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 3:   6%|▋         | 60/958 [00:22<05:28,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 3:   6%|▋         | 60/958 [00:22<05:28,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:   6%|▋         | 61/958 [00:22<05:28,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:   6%|▋         | 61/958 [00:22<05:28,  2.73it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   6%|▋         | 62/958 [00:22<05:27,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   6%|▋         | 62/958 [00:23<05:27,  2.74it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:   7%|▋         | 63/958 [00:23<05:27,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:   7%|▋         | 63/958 [00:23<05:27,  2.73it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:   7%|▋         | 64/958 [00:23<05:26,  2.74it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:   7%|▋         | 64/958 [00:23<05:26,  2.74it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 3:   7%|▋         | 65/958 [00:23<05:25,  2.74it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 3:   7%|▋         | 65/958 [00:24<05:25,  2.74it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 3:   7%|▋         | 66/958 [00:24<05:27,  2.72it/s, training_loss=0.166]\u001b[A\n",
            "Epoch 3:   7%|▋         | 66/958 [00:24<05:27,  2.72it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 3:   7%|▋         | 67/958 [00:24<05:28,  2.71it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 3:   7%|▋         | 67/958 [00:24<05:28,  2.71it/s, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   7%|▋         | 68/958 [00:24<05:27,  2.71it/s, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   7%|▋         | 68/958 [00:25<05:27,  2.71it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   7%|▋         | 69/958 [00:25<05:25,  2.73it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 3:   7%|▋         | 69/958 [00:25<05:25,  2.73it/s, training_loss=0.016]\u001b[A\n",
            "Epoch 3:   7%|▋         | 70/958 [00:25<05:25,  2.73it/s, training_loss=0.016]\u001b[A\n",
            "Epoch 3:   7%|▋         | 70/958 [00:26<05:25,  2.73it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 3:   7%|▋         | 71/958 [00:26<05:24,  2.74it/s, training_loss=0.141]\u001b[A\n",
            "Epoch 3:   7%|▋         | 71/958 [00:26<05:24,  2.74it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 3:   8%|▊         | 72/958 [00:26<05:24,  2.73it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 3:   8%|▊         | 72/958 [00:26<05:24,  2.73it/s, training_loss=0.020]\u001b[A\n",
            "Epoch 3:   8%|▊         | 73/958 [00:26<05:23,  2.74it/s, training_loss=0.020]\u001b[A\n",
            "Epoch 3:   8%|▊         | 73/958 [00:27<05:23,  2.74it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:   8%|▊         | 74/958 [00:27<05:21,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:   8%|▊         | 74/958 [00:27<05:21,  2.75it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 3:   8%|▊         | 75/958 [00:27<05:21,  2.74it/s, training_loss=0.089]\u001b[A\n",
            "Epoch 3:   8%|▊         | 75/958 [00:27<05:21,  2.74it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:   8%|▊         | 76/958 [00:27<05:21,  2.75it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:   8%|▊         | 76/958 [00:28<05:21,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   8%|▊         | 77/958 [00:28<05:21,  2.74it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 3:   8%|▊         | 77/958 [00:28<05:21,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:   8%|▊         | 78/958 [00:28<05:24,  2.71it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:   8%|▊         | 78/958 [00:28<05:24,  2.71it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 3:   8%|▊         | 79/958 [00:28<05:23,  2.71it/s, training_loss=0.181]\u001b[A\n",
            "Epoch 3:   8%|▊         | 79/958 [00:29<05:23,  2.71it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   8%|▊         | 80/958 [00:29<05:21,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   8%|▊         | 80/958 [00:29<05:21,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 3:   8%|▊         | 81/958 [00:29<05:21,  2.73it/s, training_loss=0.174]\u001b[A\n",
            "Epoch 3:   8%|▊         | 81/958 [00:30<05:21,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   9%|▊         | 82/958 [00:30<05:20,  2.73it/s, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   9%|▊         | 82/958 [00:30<05:20,  2.73it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 3:   9%|▊         | 83/958 [00:30<05:19,  2.74it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 3:   9%|▊         | 83/958 [00:30<05:19,  2.74it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 3:   9%|▉         | 84/958 [00:30<05:19,  2.74it/s, training_loss=0.076]\u001b[A\n",
            "Epoch 3:   9%|▉         | 84/958 [00:31<05:19,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 3:   9%|▉         | 85/958 [00:31<05:19,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 3:   9%|▉         | 85/958 [00:31<05:19,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:   9%|▉         | 86/958 [00:31<05:17,  2.75it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:   9%|▉         | 86/958 [00:31<05:17,  2.75it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   9%|▉         | 87/958 [00:31<05:18,  2.74it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   9%|▉         | 87/958 [00:32<05:18,  2.74it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:   9%|▉         | 88/958 [00:32<05:16,  2.75it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:   9%|▉         | 88/958 [00:32<05:16,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 3:   9%|▉         | 89/958 [00:32<05:14,  2.76it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 3:   9%|▉         | 89/958 [00:32<05:14,  2.76it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 3:   9%|▉         | 90/958 [00:32<05:14,  2.76it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 3:   9%|▉         | 90/958 [00:33<05:14,  2.76it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 3:   9%|▉         | 91/958 [00:33<05:14,  2.75it/s, training_loss=0.122]\u001b[A\n",
            "Epoch 3:   9%|▉         | 91/958 [00:33<05:14,  2.75it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  10%|▉         | 92/958 [00:33<05:12,  2.77it/s, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  10%|▉         | 92/958 [00:34<05:12,  2.77it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  10%|▉         | 93/958 [00:34<05:14,  2.75it/s, training_loss=0.142]\u001b[A\n",
            "Epoch 3:  10%|▉         | 93/958 [00:34<05:14,  2.75it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  10%|▉         | 94/958 [00:34<05:13,  2.75it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  10%|▉         | 94/958 [00:34<05:13,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  10%|▉         | 95/958 [00:34<05:15,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  10%|▉         | 95/958 [00:35<05:15,  2.74it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  10%|█         | 96/958 [00:35<05:15,  2.73it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  10%|█         | 96/958 [00:35<05:15,  2.73it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  10%|█         | 97/958 [00:35<05:14,  2.74it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  10%|█         | 97/958 [00:35<05:14,  2.74it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  10%|█         | 98/958 [00:35<05:15,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  10%|█         | 98/958 [00:36<05:15,  2.73it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  10%|█         | 99/958 [00:36<05:13,  2.74it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  10%|█         | 99/958 [00:36<05:13,  2.74it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  10%|█         | 100/958 [00:36<05:11,  2.76it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  10%|█         | 100/958 [00:36<05:11,  2.76it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  11%|█         | 101/958 [00:36<05:10,  2.76it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  11%|█         | 101/958 [00:37<05:10,  2.76it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  11%|█         | 102/958 [00:37<05:10,  2.76it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  11%|█         | 102/958 [00:37<05:10,  2.76it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  11%|█         | 103/958 [00:37<05:11,  2.75it/s, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  11%|█         | 103/958 [00:38<05:11,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  11%|█         | 104/958 [00:38<05:12,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  11%|█         | 104/958 [00:38<05:12,  2.74it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  11%|█         | 105/958 [00:38<05:10,  2.74it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  11%|█         | 105/958 [00:38<05:10,  2.74it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  11%|█         | 106/958 [00:38<05:11,  2.74it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  11%|█         | 106/958 [00:39<05:11,  2.74it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  11%|█         | 107/958 [00:39<05:11,  2.73it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  11%|█         | 107/958 [00:39<05:11,  2.73it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 108/958 [00:39<05:11,  2.73it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 108/958 [00:39<05:11,  2.73it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 109/958 [00:39<05:11,  2.73it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 109/958 [00:40<05:11,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 110/958 [00:40<05:11,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 110/958 [00:40<05:11,  2.73it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 111/958 [00:40<05:11,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 111/958 [00:41<05:11,  2.72it/s, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 112/958 [00:41<05:11,  2.71it/s, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 112/958 [00:41<05:11,  2.71it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 113/958 [00:41<05:09,  2.73it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 113/958 [00:41<05:09,  2.73it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 114/958 [00:41<05:10,  2.72it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 114/958 [00:42<05:10,  2.72it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 115/958 [00:42<05:09,  2.72it/s, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 115/958 [00:42<05:09,  2.72it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 116/958 [00:42<05:08,  2.73it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 116/958 [00:42<05:08,  2.73it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 117/958 [00:42<05:05,  2.75it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 117/958 [00:43<05:05,  2.75it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 118/958 [00:43<05:07,  2.73it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 118/958 [00:43<05:07,  2.73it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 119/958 [00:43<05:05,  2.75it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 119/958 [00:43<05:05,  2.75it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 120/958 [00:43<05:06,  2.73it/s, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 120/958 [00:44<05:06,  2.73it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 121/958 [00:44<05:05,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 121/958 [00:44<05:05,  2.74it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 122/958 [00:44<05:04,  2.75it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 122/958 [00:45<05:04,  2.75it/s, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 123/958 [00:45<05:04,  2.75it/s, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 123/958 [00:45<05:04,  2.75it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 124/958 [00:45<05:04,  2.74it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 124/958 [00:45<05:04,  2.74it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 125/958 [00:45<05:02,  2.76it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 125/958 [00:46<05:02,  2.76it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 126/958 [00:46<05:03,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 126/958 [00:46<05:03,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 127/958 [00:46<05:01,  2.76it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 127/958 [00:46<05:01,  2.76it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 128/958 [00:46<05:00,  2.76it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 128/958 [00:47<05:00,  2.76it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 129/958 [00:47<05:01,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 129/958 [00:47<05:01,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 130/958 [00:47<05:00,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 130/958 [00:47<05:00,  2.75it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 131/958 [00:47<04:59,  2.77it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 131/958 [00:48<04:59,  2.77it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 132/958 [00:48<05:00,  2.75it/s, training_loss=0.147]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 132/958 [00:48<05:00,  2.75it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 133/958 [00:48<04:58,  2.76it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 133/958 [00:49<04:58,  2.76it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 134/958 [00:49<04:59,  2.76it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 134/958 [00:49<04:59,  2.76it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 135/958 [00:49<04:58,  2.76it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 135/958 [00:49<04:58,  2.76it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 136/958 [00:49<04:58,  2.75it/s, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 136/958 [00:50<04:58,  2.75it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 137/958 [00:50<04:57,  2.76it/s, training_loss=0.212]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 137/958 [00:50<04:57,  2.76it/s, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 138/958 [00:50<04:56,  2.77it/s, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 138/958 [00:50<04:56,  2.77it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 139/958 [00:50<04:54,  2.78it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 139/958 [00:51<04:54,  2.78it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 140/958 [00:51<04:54,  2.78it/s, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 140/958 [00:51<04:54,  2.78it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 141/958 [00:51<04:53,  2.78it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 141/958 [00:51<04:53,  2.78it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 142/958 [00:51<04:53,  2.78it/s, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 142/958 [00:52<04:53,  2.78it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 143/958 [00:52<04:53,  2.78it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 143/958 [00:52<04:53,  2.78it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 144/958 [00:52<04:52,  2.78it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 144/958 [00:52<04:52,  2.78it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 145/958 [00:53<04:53,  2.77it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 145/958 [00:53<04:53,  2.77it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 146/958 [00:53<04:55,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 146/958 [00:53<04:55,  2.75it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 147/958 [00:53<04:56,  2.73it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 147/958 [00:54<04:56,  2.73it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 148/958 [00:54<04:57,  2.73it/s, training_loss=0.195]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 148/958 [00:54<04:57,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 149/958 [00:54<04:58,  2.71it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 149/958 [00:54<04:58,  2.71it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 150/958 [00:54<04:58,  2.70it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 150/958 [00:55<04:58,  2.70it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 151/958 [00:55<04:59,  2.70it/s, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 151/958 [00:55<04:59,  2.70it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 152/958 [00:55<04:56,  2.71it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 152/958 [00:55<04:56,  2.71it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 153/958 [00:55<04:58,  2.70it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 153/958 [00:56<04:58,  2.70it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 154/958 [00:56<04:55,  2.72it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 154/958 [00:56<04:55,  2.72it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 155/958 [00:56<04:53,  2.73it/s, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 155/958 [00:57<04:53,  2.73it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 156/958 [00:57<04:53,  2.73it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 156/958 [00:57<04:53,  2.73it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 157/958 [00:57<04:54,  2.72it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 157/958 [00:57<04:54,  2.72it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 158/958 [00:57<04:52,  2.74it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 158/958 [00:58<04:52,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 159/958 [00:58<04:52,  2.73it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 159/958 [00:58<04:52,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 160/958 [00:58<04:51,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 160/958 [00:58<04:51,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 161/958 [00:58<04:50,  2.74it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 161/958 [00:59<04:50,  2.74it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 162/958 [00:59<04:48,  2.76it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 162/958 [00:59<04:48,  2.76it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 163/958 [00:59<04:47,  2.77it/s, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 163/958 [00:59<04:47,  2.77it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 164/958 [00:59<04:49,  2.74it/s, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 164/958 [01:00<04:49,  2.74it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 165/958 [01:00<04:52,  2.71it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 165/958 [01:00<04:52,  2.71it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 166/958 [01:00<04:49,  2.73it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 166/958 [01:01<04:49,  2.73it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 167/958 [01:01<04:51,  2.72it/s, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 167/958 [01:01<04:51,  2.72it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 168/958 [01:01<04:51,  2.71it/s, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 168/958 [01:01<04:51,  2.71it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 169/958 [01:01<04:51,  2.71it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 169/958 [01:02<04:51,  2.71it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 170/958 [01:02<04:50,  2.71it/s, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 170/958 [01:02<04:50,  2.71it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 171/958 [01:02<04:49,  2.72it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 171/958 [01:02<04:49,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 172/958 [01:02<04:48,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 172/958 [01:03<04:48,  2.72it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 173/958 [01:03<04:48,  2.73it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 173/958 [01:03<04:48,  2.73it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 174/958 [01:03<04:50,  2.70it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 174/958 [01:04<04:50,  2.70it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 175/958 [01:04<04:49,  2.70it/s, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 175/958 [01:04<04:49,  2.70it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 176/958 [01:04<04:47,  2.72it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 176/958 [01:04<04:47,  2.72it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 177/958 [01:04<04:45,  2.74it/s, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 177/958 [01:05<04:45,  2.74it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 178/958 [01:05<04:47,  2.71it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 178/958 [01:05<04:47,  2.71it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 179/958 [01:05<04:48,  2.70it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 179/958 [01:05<04:48,  2.70it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 180/958 [01:05<04:45,  2.73it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 180/958 [01:06<04:45,  2.73it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 181/958 [01:06<04:45,  2.72it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 181/958 [01:06<04:45,  2.72it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 182/958 [01:06<04:46,  2.71it/s, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 182/958 [01:06<04:46,  2.71it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 183/958 [01:06<04:43,  2.73it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 183/958 [01:07<04:43,  2.73it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 184/958 [01:07<04:46,  2.70it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 184/958 [01:07<04:46,  2.70it/s, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 185/958 [01:07<04:45,  2.71it/s, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 185/958 [01:08<04:45,  2.71it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 186/958 [01:08<04:42,  2.73it/s, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 186/958 [01:08<04:42,  2.73it/s, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 187/958 [01:08<04:41,  2.74it/s, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 187/958 [01:08<04:41,  2.74it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 188/958 [01:08<04:39,  2.75it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 188/958 [01:09<04:39,  2.75it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 189/958 [01:09<04:39,  2.76it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 189/958 [01:09<04:39,  2.76it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 190/958 [01:09<04:38,  2.76it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 190/958 [01:09<04:38,  2.76it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 191/958 [01:09<04:36,  2.77it/s, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 191/958 [01:10<04:36,  2.77it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  20%|██        | 192/958 [01:10<04:36,  2.77it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  20%|██        | 192/958 [01:10<04:36,  2.77it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  20%|██        | 193/958 [01:10<04:35,  2.78it/s, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  20%|██        | 193/958 [01:10<04:35,  2.78it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  20%|██        | 194/958 [01:10<04:34,  2.78it/s, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  20%|██        | 194/958 [01:11<04:34,  2.78it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  20%|██        | 195/958 [01:11<04:35,  2.77it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  20%|██        | 195/958 [01:11<04:35,  2.77it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  20%|██        | 196/958 [01:11<04:35,  2.77it/s, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  20%|██        | 196/958 [01:12<04:35,  2.77it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  21%|██        | 197/958 [01:12<04:36,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  21%|██        | 197/958 [01:12<04:36,  2.75it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  21%|██        | 198/958 [01:12<04:36,  2.75it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  21%|██        | 198/958 [01:12<04:36,  2.75it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  21%|██        | 199/958 [01:12<04:35,  2.76it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  21%|██        | 199/958 [01:13<04:35,  2.76it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  21%|██        | 200/958 [01:13<04:35,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  21%|██        | 200/958 [01:13<04:35,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  21%|██        | 201/958 [01:13<04:36,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  21%|██        | 201/958 [01:13<04:36,  2.74it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  21%|██        | 202/958 [01:13<04:34,  2.75it/s, training_loss=0.194]\u001b[A\n",
            "Epoch 3:  21%|██        | 202/958 [01:14<04:34,  2.75it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  21%|██        | 203/958 [01:14<04:34,  2.75it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  21%|██        | 203/958 [01:14<04:34,  2.75it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 204/958 [01:14<04:35,  2.73it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 204/958 [01:14<04:35,  2.73it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 205/958 [01:14<04:34,  2.75it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 205/958 [01:15<04:34,  2.75it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 206/958 [01:15<04:31,  2.77it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 206/958 [01:15<04:31,  2.77it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 207/958 [01:15<04:32,  2.76it/s, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 207/958 [01:16<04:32,  2.76it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 208/958 [01:16<04:30,  2.77it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 208/958 [01:16<04:30,  2.77it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 209/958 [01:16<04:30,  2.77it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 209/958 [01:16<04:30,  2.77it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 210/958 [01:16<04:32,  2.75it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 210/958 [01:17<04:32,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 211/958 [01:17<04:30,  2.76it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 211/958 [01:17<04:30,  2.76it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 212/958 [01:17<04:30,  2.75it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 212/958 [01:17<04:30,  2.75it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 213/958 [01:17<04:31,  2.75it/s, training_loss=0.021]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 213/958 [01:18<04:31,  2.75it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 214/958 [01:18<04:31,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 214/958 [01:18<04:31,  2.74it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 215/958 [01:18<04:31,  2.74it/s, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 215/958 [01:18<04:31,  2.74it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 216/958 [01:18<04:30,  2.74it/s, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 216/958 [01:19<04:30,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 217/958 [01:19<04:30,  2.74it/s, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 217/958 [01:19<04:30,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 218/958 [01:19<04:30,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 218/958 [01:20<04:30,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 219/958 [01:20<04:29,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 219/958 [01:20<04:29,  2.74it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 220/958 [01:20<04:28,  2.75it/s, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 220/958 [01:20<04:28,  2.75it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 221/958 [01:20<04:27,  2.76it/s, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 221/958 [01:21<04:27,  2.76it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 222/958 [01:21<04:27,  2.75it/s, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 222/958 [01:21<04:27,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 223/958 [01:21<04:27,  2.75it/s, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 223/958 [01:21<04:27,  2.75it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 224/958 [01:21<04:26,  2.75it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 224/958 [01:22<04:26,  2.75it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 225/958 [01:22<04:25,  2.76it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 225/958 [01:22<04:25,  2.76it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 226/958 [01:22<04:25,  2.76it/s, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 226/958 [01:22<04:25,  2.76it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 227/958 [01:22<04:27,  2.74it/s, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 227/958 [01:23<04:27,  2.74it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 228/958 [01:23<04:25,  2.75it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 228/958 [01:23<04:25,  2.75it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 229/958 [01:23<04:25,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 229/958 [01:24<04:25,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 230/958 [01:24<04:28,  2.71it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 230/958 [01:24<04:28,  2.71it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 231/958 [01:24<04:25,  2.73it/s, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 231/958 [01:24<04:25,  2.73it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 232/958 [01:24<04:23,  2.75it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 232/958 [01:25<04:23,  2.75it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 233/958 [01:25<04:24,  2.74it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 233/958 [01:25<04:24,  2.74it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 234/958 [01:25<04:23,  2.75it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 234/958 [01:25<04:23,  2.75it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 235/958 [01:25<04:23,  2.74it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 235/958 [01:26<04:23,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 236/958 [01:26<04:22,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 236/958 [01:26<04:22,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 237/958 [01:26<04:21,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 237/958 [01:26<04:21,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 238/958 [01:26<04:21,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 238/958 [01:27<04:21,  2.75it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 239/958 [01:27<04:21,  2.75it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 239/958 [01:27<04:21,  2.75it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 240/958 [01:27<04:22,  2.73it/s, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 240/958 [01:28<04:22,  2.73it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 241/958 [01:28<04:22,  2.73it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 241/958 [01:28<04:22,  2.73it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 242/958 [01:28<04:21,  2.73it/s, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 242/958 [01:28<04:21,  2.73it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 243/958 [01:28<04:20,  2.74it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 243/958 [01:29<04:20,  2.74it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 244/958 [01:29<04:20,  2.74it/s, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 244/958 [01:29<04:20,  2.74it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 245/958 [01:29<04:19,  2.75it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 245/958 [01:29<04:19,  2.75it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 246/958 [01:29<04:20,  2.73it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 246/958 [01:30<04:20,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 247/958 [01:30<04:19,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 247/958 [01:30<04:19,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 248/958 [01:30<04:18,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 248/958 [01:30<04:18,  2.75it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 249/958 [01:30<04:17,  2.76it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 249/958 [01:31<04:17,  2.76it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 250/958 [01:31<04:16,  2.76it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 250/958 [01:31<04:16,  2.76it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 251/958 [01:31<04:15,  2.77it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 251/958 [01:32<04:15,  2.77it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 252/958 [01:32<04:15,  2.76it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 252/958 [01:32<04:15,  2.76it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 253/958 [01:32<04:16,  2.75it/s, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 253/958 [01:32<04:16,  2.75it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 254/958 [01:32<04:16,  2.74it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 254/958 [01:33<04:16,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 255/958 [01:33<04:19,  2.71it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 255/958 [01:33<04:19,  2.71it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 256/958 [01:33<04:17,  2.73it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 256/958 [01:33<04:17,  2.73it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 257/958 [01:33<04:15,  2.74it/s, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 257/958 [01:34<04:15,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 258/958 [01:34<04:15,  2.74it/s, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 258/958 [01:34<04:15,  2.74it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 259/958 [01:34<04:16,  2.73it/s, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 259/958 [01:34<04:16,  2.73it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 260/958 [01:34<04:14,  2.75it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 260/958 [01:35<04:14,  2.75it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 261/958 [01:35<04:14,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 261/958 [01:35<04:14,  2.74it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 262/958 [01:35<04:13,  2.75it/s, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 262/958 [01:36<04:13,  2.75it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 263/958 [01:36<04:13,  2.74it/s, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 263/958 [01:36<04:13,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 264/958 [01:36<04:13,  2.74it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 264/958 [01:36<04:13,  2.74it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 265/958 [01:36<04:11,  2.75it/s, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 265/958 [01:37<04:11,  2.75it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 266/958 [01:37<04:11,  2.76it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 266/958 [01:37<04:11,  2.76it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 267/958 [01:37<04:10,  2.76it/s, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 267/958 [01:37<04:10,  2.76it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 268/958 [01:37<04:12,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 268/958 [01:38<04:12,  2.73it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 269/958 [01:38<04:11,  2.74it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 269/958 [01:38<04:11,  2.74it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 270/958 [01:38<04:09,  2.76it/s, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 270/958 [01:38<04:09,  2.76it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 271/958 [01:38<04:09,  2.76it/s, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 271/958 [01:39<04:09,  2.76it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 272/958 [01:39<04:09,  2.75it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 272/958 [01:39<04:09,  2.75it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 273/958 [01:39<04:10,  2.74it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 273/958 [01:40<04:10,  2.74it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 274/958 [01:40<04:11,  2.72it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 274/958 [01:40<04:11,  2.72it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 275/958 [01:40<04:12,  2.71it/s, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 275/958 [01:40<04:12,  2.71it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 276/958 [01:40<04:10,  2.72it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 276/958 [01:41<04:10,  2.72it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 277/958 [01:41<04:09,  2.73it/s, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 277/958 [01:41<04:09,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 278/958 [01:41<04:09,  2.73it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 278/958 [01:41<04:09,  2.73it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 279/958 [01:41<04:09,  2.72it/s, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 279/958 [01:42<04:09,  2.72it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 280/958 [01:42<04:07,  2.74it/s, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 280/958 [01:42<04:07,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 281/958 [01:42<04:06,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 281/958 [01:43<04:06,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 282/958 [01:43<04:07,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 282/958 [01:43<04:07,  2.73it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 283/958 [01:43<04:06,  2.73it/s, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 283/958 [01:43<04:06,  2.73it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 284/958 [01:43<04:05,  2.74it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 284/958 [01:44<04:05,  2.74it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 285/958 [01:44<04:06,  2.73it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 285/958 [01:44<04:06,  2.73it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 286/958 [01:44<04:05,  2.73it/s, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 286/958 [01:44<04:05,  2.73it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 287/958 [01:44<04:06,  2.73it/s, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 287/958 [01:45<04:06,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  30%|███       | 288/958 [01:45<04:05,  2.72it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  30%|███       | 288/958 [01:45<04:05,  2.72it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  30%|███       | 289/958 [01:45<04:05,  2.72it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  30%|███       | 289/958 [01:45<04:05,  2.72it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  30%|███       | 290/958 [01:45<04:06,  2.71it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  30%|███       | 290/958 [01:46<04:06,  2.71it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  30%|███       | 291/958 [01:46<04:05,  2.71it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  30%|███       | 291/958 [01:46<04:05,  2.71it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  30%|███       | 292/958 [01:46<04:03,  2.73it/s, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  30%|███       | 292/958 [01:47<04:03,  2.73it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  31%|███       | 293/958 [01:47<04:03,  2.74it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  31%|███       | 293/958 [01:47<04:03,  2.74it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  31%|███       | 294/958 [01:47<04:01,  2.75it/s, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  31%|███       | 294/958 [01:47<04:01,  2.75it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  31%|███       | 295/958 [01:47<03:59,  2.76it/s, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  31%|███       | 295/958 [01:48<03:59,  2.76it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  31%|███       | 296/958 [01:48<04:00,  2.76it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  31%|███       | 296/958 [01:48<04:00,  2.76it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  31%|███       | 297/958 [01:48<04:00,  2.75it/s, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  31%|███       | 297/958 [01:48<04:00,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  31%|███       | 298/958 [01:48<03:59,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  31%|███       | 298/958 [01:49<03:59,  2.75it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  31%|███       | 299/958 [01:49<03:59,  2.75it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  31%|███       | 299/958 [01:49<03:59,  2.75it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 300/958 [01:49<03:58,  2.75it/s, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 300/958 [01:49<03:58,  2.75it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 301/958 [01:49<03:57,  2.76it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 301/958 [01:50<03:57,  2.76it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 302/958 [01:50<03:58,  2.75it/s, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 302/958 [01:50<03:58,  2.75it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 303/958 [01:50<03:59,  2.74it/s, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 303/958 [01:51<03:59,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 304/958 [01:51<03:58,  2.74it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 304/958 [01:51<03:58,  2.74it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 305/958 [01:51<03:58,  2.73it/s, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 305/958 [01:51<03:58,  2.73it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 306/958 [01:51<03:57,  2.74it/s, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 306/958 [01:52<03:57,  2.74it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 307/958 [01:52<03:57,  2.74it/s, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 307/958 [01:52<03:57,  2.74it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 308/958 [01:52<03:58,  2.73it/s, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 308/958 [01:52<03:58,  2.73it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 309/958 [01:52<03:57,  2.74it/s, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 309/958 [01:53<03:57,  2.74it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 310/958 [01:53<03:55,  2.75it/s, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 310/958 [01:53<03:55,  2.75it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 311/958 [01:53<03:56,  2.74it/s, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 311/958 [01:53<03:56,  2.74it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 312/958 [01:53<03:55,  2.74it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 312/958 [01:54<03:55,  2.74it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 313/958 [01:54<03:57,  2.72it/s, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 313/958 [01:54<03:57,  2.72it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 314/958 [01:54<03:56,  2.73it/s, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 314/958 [01:55<03:56,  2.73it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 315/958 [01:55<03:53,  2.75it/s, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 315/958 [01:55<03:53,  2.75it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 316/958 [01:55<03:54,  2.74it/s, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 316/958 [01:55<03:54,  2.74it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 317/958 [01:55<03:52,  2.75it/s, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 317/958 [01:56<03:52,  2.75it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 318/958 [01:56<03:52,  2.76it/s, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 318/958 [01:56<03:52,  2.76it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 319/958 [01:56<03:54,  2.73it/s, training_loss=0.119]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 319/958 [01:56<03:54,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 320/958 [01:56<03:53,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 320/958 [01:57<03:53,  2.73it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 321/958 [01:57<03:53,  2.72it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 321/958 [01:57<03:53,  2.72it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 322/958 [01:57<03:53,  2.73it/s, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 322/958 [01:57<03:53,  2.73it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 323/958 [01:57<03:52,  2.73it/s, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 323/958 [01:58<03:52,  2.73it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 324/958 [01:58<03:51,  2.73it/s, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 324/958 [01:58<03:51,  2.73it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 325/958 [01:58<03:51,  2.73it/s, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 325/958 [01:59<03:51,  2.73it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 326/958 [01:59<03:50,  2.74it/s, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 326/958 [01:59<03:50,  2.74it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 327/958 [01:59<03:50,  2.74it/s, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 327/958 [01:59<03:50,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 328/958 [01:59<03:49,  2.74it/s, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 328/958 [02:00<03:49,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 329/958 [02:00<03:49,  2.74it/s, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 329/958 [02:00<03:49,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 330/958 [02:00<03:49,  2.74it/s, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 330/958 [02:00<03:49,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 331/958 [02:00<03:48,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 331/958 [02:01<03:48,  2.74it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 332/958 [02:01<03:47,  2.75it/s, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 332/958 [02:01<03:47,  2.75it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 333/958 [02:01<03:47,  2.74it/s, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 333/958 [02:01<03:47,  2.74it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 334/958 [02:01<03:47,  2.75it/s, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 334/958 [02:02<03:47,  2.75it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 335/958 [02:02<03:45,  2.76it/s, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 335/958 [02:02<03:45,  2.76it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 336/958 [02:02<03:44,  2.77it/s, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 336/958 [02:03<03:44,  2.77it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 337/958 [02:03<03:44,  2.77it/s, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 337/958 [02:03<03:44,  2.77it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 338/958 [02:03<03:44,  2.77it/s, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 338/958 [02:03<03:44,  2.77it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 339/958 [02:03<03:44,  2.76it/s, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 339/958 [02:04<03:44,  2.76it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 340/958 [02:04<03:43,  2.77it/s, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 340/958 [02:04<03:43,  2.77it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 341/958 [02:04<03:43,  2.77it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 341/958 [02:04<03:43,  2.77it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 342/958 [02:04<03:44,  2.74it/s, training_loss=0.093]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 342/958 [02:05<03:44,  2.74it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 343/958 [02:05<03:44,  2.74it/s, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 343/958 [02:05<03:44,  2.74it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 344/958 [02:05<03:45,  2.72it/s, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 344/958 [02:05<03:45,  2.72it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 345/958 [02:05<03:43,  2.74it/s, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 345/958 [02:06<03:43,  2.74it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 346/958 [02:06<03:42,  2.75it/s, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 346/958 [02:06<03:42,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 347/958 [02:06<03:42,  2.75it/s, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 347/958 [02:07<03:42,  2.75it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 348/958 [02:07<03:41,  2.75it/s, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 348/958 [02:07<03:41,  2.75it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 349/958 [02:07<03:41,  2.74it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 349/958 [02:07<03:41,  2.74it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 350/958 [02:07<03:42,  2.73it/s, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 350/958 [02:08<03:42,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 351/958 [02:08<03:42,  2.73it/s, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 351/958 [02:08<03:42,  2.73it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 352/958 [02:08<03:40,  2.74it/s, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 352/958 [02:08<03:40,  2.74it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 353/958 [02:08<03:39,  2.76it/s, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 353/958 [02:09<03:39,  2.76it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 354/958 [02:09<03:40,  2.75it/s, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 354/958 [02:09<03:40,  2.75it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 355/958 [02:09<03:39,  2.75it/s, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 355/958 [02:09<03:39,  2.75it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 356/958 [02:10<03:40,  2.73it/s, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 356/958 [02:10<03:40,  2.73it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 357/958 [02:10<03:40,  2.72it/s, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 357/958 [02:10<03:40,  2.72it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 358/958 [02:10<03:40,  2.72it/s, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 358/958 [02:11<03:40,  2.72it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 359/958 [02:11<03:38,  2.74it/s, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 359/958 [02:11<03:38,  2.74it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 360/958 [02:11<03:39,  2.73it/s, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 360/958 [02:11<03:39,  2.73it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 361/958 [02:11<03:38,  2.73it/s, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 361/958 [02:12<03:38,  2.73it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 362/958 [02:12<03:39,  2.72it/s, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 362/958 [02:12<03:39,  2.72it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 363/958 [02:12<03:37,  2.73it/s, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 363/958 [02:12<03:37,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 364/958 [02:12<03:37,  2.73it/s, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 364/958 [02:13<03:37,  2.73it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 365/958 [02:13<03:37,  2.73it/s, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 365/958 [02:13<03:37,  2.73it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 366/958 [02:13<03:37,  2.72it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 366/958 [02:14<03:37,  2.72it/s, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 367/958 [02:14<03:37,  2.71it/s, training_loss=0.051]\u001b[A\n",
            " 20%|██        | 2/10 [15:16<1:01:05, 458.23s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-61a5c27cfdff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss_train_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lossTrain)\n",
        "plt.plot(lossVal)\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cMUgul832j8M",
        "outputId": "f068da85-3947-4483-dd01-e5f315da1baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_val)\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "metadata": {
        "id": "gl-gAEI1jJxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b1efa7-9169-4655-86f5-73949411bfbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.228]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.235]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.275]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.314]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.246]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.296]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.188]\n",
            "Epoch 6:   0%|          | 0/320 [00:00<?, ?it/s, validation_loss=0.421]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.317]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.090]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.200]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.228]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.167]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.270]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.213]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.212]\n",
            "Epoch 6:   0%|          | 0/320 [00:01<?, ?it/s, validation_loss=0.234]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.139]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.449]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.296]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.268]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.167]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.511]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.150]\n",
            "Epoch 6:   0%|          | 0/320 [00:02<?, ?it/s, validation_loss=0.194]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.348]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.224]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.195]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.218]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.294]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.091]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.114]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.191]\n",
            "Epoch 6:   0%|          | 0/320 [00:03<?, ?it/s, validation_loss=0.286]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.166]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.173]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.235]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.305]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.136]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.227]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.150]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.125]\n",
            "Epoch 6:   0%|          | 0/320 [00:04<?, ?it/s, validation_loss=0.074]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.283]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.324]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.090]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.265]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.216]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.296]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.196]\n",
            "Epoch 6:   0%|          | 0/320 [00:05<?, ?it/s, validation_loss=0.136]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.170]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.023]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.346]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.293]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.329]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.247]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.306]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.083]\n",
            "Epoch 6:   0%|          | 0/320 [00:06<?, ?it/s, validation_loss=0.345]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.117]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.184]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.206]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.174]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.399]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.161]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.268]\n",
            "Epoch 6:   0%|          | 0/320 [00:07<?, ?it/s, validation_loss=0.200]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.084]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.206]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.143]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.383]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.392]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.103]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.189]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.242]\n",
            "Epoch 6:   0%|          | 0/320 [00:08<?, ?it/s, validation_loss=0.358]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.142]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.136]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.134]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.271]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.247]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.140]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.193]\n",
            "Epoch 6:   0%|          | 0/320 [00:09<?, ?it/s, validation_loss=0.140]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.096]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.211]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.331]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.189]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.168]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.307]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.252]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.298]\n",
            "Epoch 6:   0%|          | 0/320 [00:10<?, ?it/s, validation_loss=0.359]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.345]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.302]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.221]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.044]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.304]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.237]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.280]\n",
            "Epoch 6:   0%|          | 0/320 [00:11<?, ?it/s, validation_loss=0.141]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.192]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.262]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.178]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.229]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.175]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.504]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.127]\n",
            "Epoch 6:   0%|          | 0/320 [00:12<?, ?it/s, validation_loss=0.124]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.412]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.061]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.377]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.218]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.117]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.297]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.234]\n",
            "Epoch 6:   0%|          | 0/320 [00:13<?, ?it/s, validation_loss=0.285]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.193]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.226]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.262]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.315]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.162]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.303]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.316]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.231]\n",
            "Epoch 6:   0%|          | 0/320 [00:14<?, ?it/s, validation_loss=0.155]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.282]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.196]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.155]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.195]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.247]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.147]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.256]\n",
            "Epoch 6:   0%|          | 0/320 [00:15<?, ?it/s, validation_loss=0.178]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.272]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.266]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.139]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.193]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.118]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.269]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.106]\n",
            "Epoch 6:   0%|          | 0/320 [00:16<?, ?it/s, validation_loss=0.349]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.106]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.270]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.198]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.331]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.320]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.216]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.170]\n",
            "Epoch 6:   0%|          | 0/320 [00:17<?, ?it/s, validation_loss=0.136]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.372]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.321]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.311]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.169]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.267]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.131]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.114]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.329]\n",
            "Epoch 6:   0%|          | 0/320 [00:18<?, ?it/s, validation_loss=0.217]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.161]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.195]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.346]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.143]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.319]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.209]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.207]\n",
            "Epoch 6:   0%|          | 0/320 [00:19<?, ?it/s, validation_loss=0.171]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.200]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.220]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.245]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.274]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.316]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.192]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.328]\n",
            "Epoch 6:   0%|          | 0/320 [00:20<?, ?it/s, validation_loss=0.210]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.254]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.183]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.376]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.231]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.209]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.416]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.104]\n",
            "Epoch 6:   0%|          | 0/320 [00:21<?, ?it/s, validation_loss=0.307]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.189]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.231]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.224]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.061]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.219]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.481]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.251]\n",
            "Epoch 6:   0%|          | 0/320 [00:22<?, ?it/s, validation_loss=0.332]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.250]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.313]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.055]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.305]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.316]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.301]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.248]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.235]\n",
            "Epoch 6:   0%|          | 0/320 [00:23<?, ?it/s, validation_loss=0.233]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.221]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.468]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.347]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.322]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.313]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.161]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.108]\n",
            "Epoch 6:   0%|          | 0/320 [00:24<?, ?it/s, validation_loss=0.252]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.211]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.506]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.287]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.246]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.156]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.255]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.147]\n",
            "Epoch 6:   0%|          | 0/320 [00:25<?, ?it/s, validation_loss=0.201]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.252]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.113]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.403]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.209]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.225]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.178]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.198]\n",
            "Epoch 6:   0%|          | 0/320 [00:26<?, ?it/s, validation_loss=0.224]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.144]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.254]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.205]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.157]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.188]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.127]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.254]\n",
            "Epoch 6:   0%|          | 0/320 [00:27<?, ?it/s, validation_loss=0.304]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.449]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.270]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.173]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.221]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.099]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.175]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.128]\n",
            "Epoch 6:   0%|          | 0/320 [00:28<?, ?it/s, validation_loss=0.258]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.281]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.026]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.135]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.251]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.075]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.338]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.277]\n",
            "Epoch 6:   0%|          | 0/320 [00:29<?, ?it/s, validation_loss=0.244]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.013]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.188]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.378]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.112]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.292]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.348]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.269]\n",
            "Epoch 6:   0%|          | 0/320 [00:30<?, ?it/s, validation_loss=0.161]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.202]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.223]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.283]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.260]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.155]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.194]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.246]\n",
            "Epoch 6:   0%|          | 0/320 [00:31<?, ?it/s, validation_loss=0.256]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.335]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.145]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.301]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.207]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.142]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.229]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.177]\n",
            "Epoch 6:   0%|          | 0/320 [00:32<?, ?it/s, validation_loss=0.096]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.161]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.266]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.130]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.325]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.140]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.198]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.291]\n",
            "Epoch 6:   0%|          | 0/320 [00:33<?, ?it/s, validation_loss=0.263]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.324]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.251]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.230]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.284]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.229]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.305]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.228]\n",
            "Epoch 6:   0%|          | 0/320 [00:34<?, ?it/s, validation_loss=0.202]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.258]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.172]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.243]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.287]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.294]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.184]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.187]\n",
            "Epoch 6:   0%|          | 0/320 [00:35<?, ?it/s, validation_loss=0.465]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.354]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.225]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.167]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.184]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.047]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.276]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.153]\n",
            "Epoch 6:   0%|          | 0/320 [00:36<?, ?it/s, validation_loss=0.204]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.291]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.318]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.162]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.341]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.322]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.267]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.195]\n",
            "Epoch 6:   0%|          | 0/320 [00:37<?, ?it/s, validation_loss=0.248]\n",
            "Epoch 6:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.219]\n",
            "Epoch 6:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.309]\n",
            "Epoch 6:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.205]\n",
            "Epoch 6:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.300]\n",
            "Epoch 6:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.116]\n",
            "Epoch 6:   0%|          | 0/320 [00:38<?, ?it/s, validation_loss=0.154]\n",
            "100%|██████████| 320/320 [00:38<00:00,  8.28it/s]\n",
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: 0\n",
            "Accuracy:1302/1902 - 0.6845425867507886 \n",
            "\n",
            "Class: 1\n",
            "Accuracy:3953/4487 - 0.8809895252952975 \n",
            "\n",
            "Class: 2\n",
            "Accuracy:3162/3827 - 0.8262346485497779 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/My Drive/NLP/Project'\n",
        "!pwd\n",
        "shutil.copy(\"BERT_ft_epoch1.model\",base_path)\n",
        "shutil.copy(\"BERT_ft_epoch4.model\",base_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "S9wne9Jkt8PD",
        "outputId": "5d04dd54-e406-47f3-b9fa-81f89ce23c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a4f9ffa11e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/NLP/Project'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BERT_ft_epoch1.model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BERT_ft_epoch4.model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BERT_ft_epoch1.model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqP4Bvu7bpHf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "\n",
        "# model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=3)\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Ldgi7DAxLh",
        "outputId": "a8615fff-6e5c-4c5d-c905-2078912bdb31"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 1 ... 1 0 2]\n",
            "[[  101  1998  1998 ...     0     0     0]\n",
            " [  101  6040  2831 ...     0     0     0]\n",
            " [  101 21887 23350 ...     0     0     0]\n",
            " ...\n",
            " [  101  2017  2113 ...     0     0     0]\n",
            " [  101  2003  2009 ...     0     0     0]\n",
            " [  101  2092  2047 ...   102     0     0]]\n"
          ]
        }
      ],
      "source": [
        "# data['OriginalTweet'].fillna(value='', inplace=True)\n",
        "# sentences=data['OriginalTweet']\n",
        "# labels=data['Sentiment']\n",
        "\n",
        "# input_ids=[]\n",
        "# attention_masks=[]\n",
        "\n",
        "# for sent in sentences:\n",
        "#     bert_inp=tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
        "#     input_ids.append(bert_inp['input_ids'])\n",
        "#     attention_masks.append(bert_inp['attention_mask'])\n",
        "\n",
        "# input_ids=np.asarray(input_ids)\n",
        "# attention_masks=np.array(attention_masks)\n",
        "# labels=np.array(labels)\n",
        "# print(labels)\n",
        "# print(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD8dHiTYBfGr"
      },
      "outputs": [],
      "source": [
        "# train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.25,shuffle=True)\n",
        "\n",
        "# print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))\n",
        "y = tf.keras.utils.to_categorical(data[\"Sentiment\"].values, num_classes=3)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(data['OriginalTweet'], y, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbUJfL3RHZ0D"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def avg_recall(y_true, y_pred):\n",
        "    \"\"\"This function calculates the balanced recall metric\n",
        "    recall = TP / (TP + FN)\n",
        "    \"\"\"\n",
        "    recall_by_class = 0\n",
        "    # iterate over each predicted class to get class-specific metric\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        y_pred_class = y_pred[:, i]\n",
        "        y_true_class = y_true[:, i]\n",
        "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        recall_by_class = recall_by_class + recall\n",
        "    return recall_by_class / y_pred.shape[1]\n",
        "\n",
        "def avg_precision(y_true, y_pred):\n",
        "    \"\"\"This function calculates the balanced precision metric\n",
        "    precision = TP / (TP + FP)\n",
        "    \"\"\"\n",
        "    precision_by_class = 0\n",
        "    # iterate over each predicted class to get class-specific metric\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        y_pred_class = y_pred[:, i]\n",
        "        y_true_class = y_true[:, i]\n",
        "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        precision_by_class = precision_by_class + precision\n",
        "    # return average balanced metric for each class\n",
        "    return precision_by_class / y_pred.shape[1]\n",
        "\n",
        "def avg_f1_score(y_true, y_pred):\n",
        "    \"\"\"This function calculates the F1 score metric\"\"\"\n",
        "    precision = avg_precision(y_true, y_pred)\n",
        "    recall = avg_recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ0VIN3_BtgW"
      },
      "outputs": [],
      "source": [
        "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "x = bert_preprocess(i)\n",
        "x = bert_encoder(x)\n",
        "x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x['pooled_output'])\n",
        "# x = tf.keras.layers.Dense(16, activation='sigmoid', name=\"FC\")(x)\n",
        "x = tf.keras.layers.Dense(3, activation='softmax', name=\"output\")(x)\n",
        "\n",
        "model = tf.keras.Model(i, x)\n",
        "\n",
        "# print('\\nBert Model',model.summary())\n",
        "\n",
        "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]#,avg_recall, avg_precision,avg_f1_score\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
        "\n",
        "# model.compile(loss=loss,optimizer=optimizer,metrics=[metrics],run_eagerly=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "B4uy5AQwItkB",
        "outputId": "ac06e343-8b08-46c4-c92c-6228b7e1e4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "483/483 [==============================] - 834s 2s/step - loss: 1.0311 - accuracy: 0.4780 - avg_recall: 0.2397 - avg_precision: 0.4168 - avg_f1_score: 0.2974 - val_loss: 0.9624 - val_accuracy: 0.5332 - val_avg_recall: 0.2165 - val_avg_precision: 0.4789 - val_avg_f1_score: 0.2951\n",
            "Epoch 2/20\n",
            "483/483 [==============================] - 824s 2s/step - loss: 0.9905 - accuracy: 0.5075 - avg_recall: 0.2678 - avg_precision: 0.4719 - avg_f1_score: 0.3348 - val_loss: 0.9497 - val_accuracy: 0.5404 - val_avg_recall: 0.2810 - val_avg_precision: 0.4641 - val_avg_f1_score: 0.3463\n",
            "Epoch 3/20\n",
            "483/483 [==============================] - 824s 2s/step - loss: 0.9770 - accuracy: 0.5188 - avg_recall: 0.2869 - avg_precision: 0.5090 - avg_f1_score: 0.3599 - val_loss: 0.9478 - val_accuracy: 0.5491 - val_avg_recall: 0.2516 - val_avg_precision: 0.5572 - val_avg_f1_score: 0.3431\n",
            "Epoch 4/20\n",
            "483/483 [==============================] - 826s 2s/step - loss: 0.9684 - accuracy: 0.5246 - avg_recall: 0.2946 - avg_precision: 0.5105 - avg_f1_score: 0.3666 - val_loss: 0.9504 - val_accuracy: 0.5389 - val_avg_recall: 0.3225 - val_avg_precision: 0.4392 - val_avg_f1_score: 0.3684\n",
            "Epoch 5/20\n",
            "483/483 [==============================] - 825s 2s/step - loss: 0.9623 - accuracy: 0.5263 - avg_recall: 0.3024 - avg_precision: 0.5331 - avg_f1_score: 0.3795 - val_loss: 0.9323 - val_accuracy: 0.5492 - val_avg_recall: 0.2857 - val_avg_precision: 0.5201 - val_avg_f1_score: 0.3637\n",
            "Epoch 6/20\n",
            "483/483 [==============================] - 824s 2s/step - loss: 0.9612 - accuracy: 0.5313 - avg_recall: 0.3047 - avg_precision: 0.5332 - avg_f1_score: 0.3815 - val_loss: 0.9289 - val_accuracy: 0.5542 - val_avg_recall: 0.2957 - val_avg_precision: 0.5022 - val_avg_f1_score: 0.3675\n",
            "Epoch 7/20\n",
            "483/483 [==============================] - 822s 2s/step - loss: 0.9611 - accuracy: 0.5292 - avg_recall: 0.3063 - avg_precision: 0.5318 - avg_f1_score: 0.3822 - val_loss: 0.9669 - val_accuracy: 0.5197 - val_avg_recall: 0.3331 - val_avg_precision: 0.4735 - val_avg_f1_score: 0.3868\n",
            "Epoch 8/20\n",
            "219/483 [============>.................] - ETA: 5:38 - loss: 0.9521 - accuracy: 0.5385 - avg_recall: 0.3073 - avg_precision: 0.5393 - avg_f1_score: 0.3859"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3b4aeea69735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                       callbacks = [earlystop_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_epochs = 20\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "      avg_recall,\n",
        "      avg_precision,\n",
        "      avg_f1_score\n",
        "]\n",
        "\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
        "                                                      patience = 3,\n",
        "                                                      mode='min',\n",
        "                                                      restore_best_weights = True)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,epsilon=1e-08),\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics = METRICS)\n",
        "\n",
        "model_fit = model.fit(x_train, \n",
        "                      y_train, \n",
        "                      epochs = n_epochs,\n",
        "                      batch_size=64,\n",
        "                      validation_data = (x_val, y_val),\n",
        "                      callbacks = [earlystop_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1FLkO_GJHRs"
      },
      "outputs": [],
      "source": [
        "x = list(range(1, n_epochs+1))\n",
        "metric_list = list(model_fit.history.keys())\n",
        "num_metrics = int(len(metric_list)/2)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=num_metrics, figsize=(30, 5))\n",
        "\n",
        "for i in range(0, num_metrics):\n",
        "  ax[i].plot(x, model_fit.history[metric_list[i]], marker=\"o\", label=metric_list[i].replace(\"_\", \" \"))\n",
        "  ax[i].plot(x, model_fit.history[metric_list[i+num_metrics]], marker=\"o\", label=metric_list[i+num_metrics].replace(\"_\", \" \"))\n",
        "  ax[i].set_xlabel(\"epochs\",fontsize=14)\n",
        "  ax[i].set_title(metric_list[i].replace(\"_\", \" \"),fontsize=20)\n",
        "  ax[i].legend(loc=\"lower left\")\n",
        "\n",
        "model.save_weights(\"bertFinalv1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "EVk0agh1CAzW",
        "outputId": "d47ac839-df82-4666-aa57-682da8b6262e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0d7a667820b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                       \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                       restore_best_weights = True)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearlystop_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m         \u001b[0;31m# Collect metrics to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mreturn_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The two structures don't have the same sequence type. Input structure has type <class 'tuple'>, while shallow structure has type <class 'transformers.modeling_tf_outputs.TFSequenceClassifierOutput'>."
          ]
        }
      ],
      "source": [
        "# train_inp = np.array([np.array(val) for val in train_inp])\n",
        "# train_label = np.array([np.array(val) for val in train_label])\n",
        "# train_mask = np.array([np.array(val) for val in train_mask])\n",
        "\n",
        "# val_inp = np.array([np.array(val) for val in val_inp])\n",
        "# val_label = np.array([np.array(val) for val in val_label])\n",
        "# val_mask = np.array([np.array(val) for val in val_mask])\n",
        "\n",
        "# base_output = model.bert([ids, mask, token_type_ids])\n",
        "# model.trainable = True\n",
        "\n",
        "# earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
        "#                                                       patience = 1,\n",
        "#                                                       restore_best_weights = True)\n",
        "# history=model.fit([train_inp,train_mask],train_label,batch_size=16,epochs=4,verbose = 1,validation_data=([val_inp,val_mask],val_label),callbacks=earlystop_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Duars5Ou66jS",
        "outputId": "1d297fc9-5468-437f-b7c9-834ac4ed7f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[0][0]',            \n",
            "                                768),                             'keras_layer[0][1]',            \n",
            "                                 'encoder_outputs':               'keras_layer[0][2]']            \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768)}                                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n",
            "(30867,)\n",
            "(30867,)\n",
            "Epoch 1/3\n",
            "553/965 [================>.............] - ETA: 4:13 - loss: 0.0000e+00 - accuracy: 1.0000 - avg_recall: 0.9994 - avg_precision: 0.8113 - avg_f1_score: 0.8939"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7d26501b5375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m  \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m  metrics=METRICS)\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# X_train.fillna(value='', inplace=True)\n",
        "# X_train = np.array([np.array(val) for val in X_train])\n",
        "# y_train = np.array([np.array(val) for val in y_train])\n",
        "\n",
        "# X_test.fillna(value='', inplace=True)\n",
        "# X_test = np.array([np.array(val) for val in X_test])\n",
        "# y_test = np.array([np.array(val) for val in y_test])\n",
        "\n",
        "# text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "# preprocessed_text = bert_preprocess(text_input)\n",
        "# outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# l = tf.keras.layers.Dropout(0.5, name=\"dropout\")(outputs['pooled_output'])\n",
        "# l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "# model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
        "# model.summary()\n",
        "\n",
        "# METRICS = [\n",
        "#       tf.keras.metrics.CategoricalAccuracy('accuracy'),\n",
        "#       avg_recall,\n",
        "#       avg_precision,\n",
        "#       avg_f1_score\n",
        "#       # tf.keras.metrics.Precision(class_id=1,name='precision_1'),\n",
        "#       # tf.keras.metrics.Recall(class_id=1,name='recall_1'),\n",
        "#       # tf.keras.metrics.Precision(class_id=2,name='precision_2'),\n",
        "#       # tf.keras.metrics.Recall(class_id=2,name='recall_2')\n",
        "# ]\n",
        "# print(X_train.shape)\n",
        "# print(y_train.shape)\n",
        "# earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
        "#                                                       patience = 1,\n",
        "#                                                       restore_best_weights = True)\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "#  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "#  metrics=METRICS)\n",
        "# history=model.fit(X_train,y_train, epochs=3, verbose = 1,validation_data = (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NjCSlAFQ3Pvx",
        "outputId": "2c9b475d-ead1-4d5d-c36b-bded2edbe989"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "qyrvO--23UTd",
        "outputId": "db71ab86-59b0-4d76-fdb8-ec452bd6b4e7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(model.history.history['avg_f1_score']).plot()\n",
        "plt.plot(model.history.history['val_avg_f1_score'])\n",
        "plt.title('Model F1-score')\n",
        "plt.ylabel('F1-score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0p4GblVABLq",
        "outputId": "82206121-1800-4066-df55-e4ced80339ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. ... 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# X_test.fillna(value='', inplace=True)\n",
        "# X_test = np.array([np.array(val) for val in X_test])\n",
        "# y_test = np.array([np.array(val) for val in y_test])\n",
        "# y_predicted = model.predict(X_test)\n",
        "# y_predicted = y_predicted.flatten()\n",
        "# y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
        "# print(y_predicted)\n",
        "# model.evaluate(X_test, y_test)\n",
        "\n",
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.flatten()\n",
        "# y_predicted = np.where(y_predicted > 0.5, 0, 1, 2)\n",
        "print(y_predicted)\n",
        "model.save_weights(\"bert.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "N6yh_NdN2_Pq",
        "outputId": "0673b2d8-a0f3-467d-fc51-60fa035c8850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/NLP/Project/bert.h5'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/My Drive/NLP/Project'\n",
        "shutil.copy(\"bertFinalv1.h5\",base_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmFCablp46iY"
      },
      "outputs": [],
      "source": [
        "dataTest = pd.read_csv(r\"Corona_NLP_test.csv\",encoding='latin-1')\n",
        "dataTest[\"Sentiment\"] = dataTest[\"Sentiment\"].replace('Extremely Negative', 'Negative', regex=True)\n",
        "\n",
        "dataTest[\"Sentiment\"] = dataTest[\"Sentiment\"].replace('Extremely Positive', 'Positive', regex=True)\n",
        "\n",
        "#transform Sentiment to number\n",
        "#negative=0\n",
        "#postive=1\n",
        "#neutral=2\n",
        "dataTest[\"Sentiment\"]=dataTest[\"Sentiment\"].replace('Negative', 2, regex=True)\n",
        "dataTest[\"Sentiment\"]=dataTest[\"Sentiment\"].replace('Positive', 1, regex=True)\n",
        "dataTest[\"Sentiment\"]=dataTest[\"Sentiment\"].replace('Neutral', 0, regex=True)\n",
        "\n",
        "dataTest[\"OriginalTweet\"] = dataTest[\"OriginalTweet\"].apply(lambda x: lookup_dict(x,emoticons))\n",
        "\n",
        "dataTest['OriginalTweet']=dataTest['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict1))\n",
        "dataTest['OriginalTweet']=dataTest['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict2))\n",
        "dataTest['OriginalTweet']  = dataTest['OriginalTweet'].str.lower()\n",
        "dataTest['OriginalTweet']=dataTest['OriginalTweet'].apply(lambda x:lookup_dict(x,contraction_dict2))\n",
        "dataTest['OriginalTweet'] = dataTest['OriginalTweet'].apply(lambda x: ''.join(''.join(s)[:2] for _, s in itertools.groupby(x)))\n",
        "\n",
        "\n",
        "#to lower case\n",
        "dataTest['OriginalTweet']  = dataTest['OriginalTweet'].str.lower()\n",
        "#remove numbers\n",
        "dataTest[\"OriginalTweet\"] = dataTest[\"OriginalTweet\"].replace('[0-9]', '', regex=True)\n",
        "\n",
        "#remove mentions\n",
        "dataTest[\"OriginalTweet\"] = dataTest[\"OriginalTweet\"].replace('@([a-zA-Z0-9_]{1,50})', '', regex=True)\n",
        "\n",
        "#remove hashtags\n",
        "dataTest[\"OriginalTweet\"] = dataTest[\"OriginalTweet\"].replace('#', '', regex=True)\n",
        "\n",
        "#remove urls\n",
        "dataTest[\"OriginalTweet\"] = dataTest[\"OriginalTweet\"].replace('http\\S+', '', regex=True)\n",
        "dataTest[\"OriginalTweet\"]=dataTest[\"OriginalTweet\"].replace(\"_\", \"\", regex=True)\n",
        "dataTest[\"OriginalTweet\"]=dataTest[\"OriginalTweet\"].replace(\"   \", \" \", regex=True)\n",
        "dataTest[\"OriginalTweet\"]=dataTest[\"OriginalTweet\"].replace(\"  \", \" \", regex=True)\n",
        "dataTest['OriginalTweet']  = dataTest['OriginalTweet'].str.strip()\n",
        "\n",
        "dataTest['OriginalTweet'].fillna(value='', inplace=True)\n",
        "X = np.array([np.array(val) for val in dataTest['OriginalTweet']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi28xqZU5zKv",
        "outputId": "33e6e719-7f2f-4374-dd69-316e6b75c69a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. ... 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import  metrics\n",
        "y_predicted = model.predict(X)\n",
        "y_predicted = y_predicted.flatten()\n",
        "# print(metrics.classification_report(y_predicted,dataTest[\"Sentiment\"]))\n",
        "# y_predicted = np.where(y_predicted > 0.5, 0, 1, 2)\n",
        "print(y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc8frIqX7YBc"
      },
      "outputs": [],
      "source": [
        "for i in y_predicted:\n",
        "  if i == 2: \n",
        "    print(i)\n",
        "  elif i==0:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C0Fm9sYdWfR",
        "outputId": "c2aa9b60-2125-4c7d-e059-bc5714d4ace4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mΗ έξοδος ροής περικόπηκε στις τελευταίες 5000 γραμμές.\u001b[0m\n",
            "5656\n",
            "5657\n",
            "5658\n",
            "5659\n",
            "5660\n",
            "5661\n",
            "5662\n",
            "5663\n",
            "5664\n",
            "5665\n",
            "5666\n",
            "5667\n",
            "5668\n",
            "5669\n",
            "5670\n",
            "5671\n",
            "5672\n",
            "5673\n",
            "5674\n",
            "5675\n",
            "5676\n",
            "5677\n",
            "5678\n",
            "5679\n",
            "5680\n",
            "5681\n",
            "5682\n",
            "5683\n",
            "5684\n",
            "5685\n",
            "5686\n",
            "5687\n",
            "5688\n",
            "5689\n",
            "5690\n",
            "5691\n",
            "5692\n",
            "5693\n",
            "5694\n",
            "5695\n",
            "5696\n",
            "5697\n",
            "5698\n",
            "5699\n",
            "5700\n",
            "5701\n",
            "5702\n",
            "5703\n",
            "5704\n",
            "5705\n",
            "5706\n",
            "5707\n",
            "5708\n",
            "5709\n",
            "5710\n",
            "5711\n",
            "5712\n",
            "5713\n",
            "5714\n",
            "5715\n",
            "5716\n",
            "5717\n",
            "5718\n",
            "5719\n",
            "5720\n",
            "5721\n",
            "5722\n",
            "5723\n",
            "5724\n",
            "5725\n",
            "5726\n",
            "5727\n",
            "5728\n",
            "5729\n",
            "5730\n",
            "5731\n",
            "5732\n",
            "5733\n",
            "5734\n",
            "5735\n",
            "5736\n",
            "5737\n",
            "5738\n",
            "5739\n",
            "5740\n",
            "5741\n",
            "5742\n",
            "5743\n",
            "5744\n",
            "5745\n",
            "5746\n",
            "5747\n",
            "5748\n",
            "5749\n",
            "5750\n",
            "5751\n",
            "5752\n",
            "5753\n",
            "5754\n",
            "5755\n",
            "5756\n",
            "5757\n",
            "5758\n",
            "5759\n",
            "5760\n",
            "5761\n",
            "5762\n",
            "5763\n",
            "5764\n",
            "5765\n",
            "5766\n",
            "5767\n",
            "5768\n",
            "5769\n",
            "5770\n",
            "5771\n",
            "5772\n",
            "5773\n",
            "5774\n",
            "5775\n",
            "5776\n",
            "5777\n",
            "5778\n",
            "5779\n",
            "5780\n",
            "5781\n",
            "5782\n",
            "5783\n",
            "5784\n",
            "5785\n",
            "5786\n",
            "5787\n",
            "5788\n",
            "5789\n",
            "5790\n",
            "5791\n",
            "5792\n",
            "5793\n",
            "5794\n",
            "5795\n",
            "5796\n",
            "5797\n",
            "5798\n",
            "5799\n",
            "5800\n",
            "5801\n",
            "5802\n",
            "5803\n",
            "5804\n",
            "5805\n",
            "5806\n",
            "5807\n",
            "5808\n",
            "5809\n",
            "5810\n",
            "5811\n",
            "5812\n",
            "5813\n",
            "5814\n",
            "5815\n",
            "5816\n",
            "5817\n",
            "5818\n",
            "5819\n",
            "5820\n",
            "5821\n",
            "5822\n",
            "5823\n",
            "5824\n",
            "5825\n",
            "5826\n",
            "5827\n",
            "5828\n",
            "5829\n",
            "5830\n",
            "5831\n",
            "5832\n",
            "5833\n",
            "5834\n",
            "5835\n",
            "5836\n",
            "5837\n",
            "5838\n",
            "5839\n",
            "5840\n",
            "5841\n",
            "5842\n",
            "5843\n",
            "5844\n",
            "5845\n",
            "5846\n",
            "5847\n",
            "5848\n",
            "5849\n",
            "5850\n",
            "5851\n",
            "5852\n",
            "5853\n",
            "5854\n",
            "5855\n",
            "5856\n",
            "5857\n",
            "5858\n",
            "5859\n",
            "5860\n",
            "5861\n",
            "5862\n",
            "5863\n",
            "5864\n",
            "5865\n",
            "5866\n",
            "5867\n",
            "5868\n",
            "5869\n",
            "5870\n",
            "5871\n",
            "5872\n",
            "5873\n",
            "5874\n",
            "5875\n",
            "5876\n",
            "5877\n",
            "5878\n",
            "5879\n",
            "5880\n",
            "5881\n",
            "5882\n",
            "5883\n",
            "5884\n",
            "5885\n",
            "5886\n",
            "5887\n",
            "5888\n",
            "5889\n",
            "5890\n",
            "5891\n",
            "5892\n",
            "5893\n",
            "5894\n",
            "5895\n",
            "5896\n",
            "5897\n",
            "5898\n",
            "5899\n",
            "5900\n",
            "5901\n",
            "5902\n",
            "5903\n",
            "5904\n",
            "5905\n",
            "5906\n",
            "5907\n",
            "5908\n",
            "5909\n",
            "5910\n",
            "5911\n",
            "5912\n",
            "5913\n",
            "5914\n",
            "5915\n",
            "5916\n",
            "5917\n",
            "5918\n",
            "5919\n",
            "5920\n",
            "5921\n",
            "5922\n",
            "5923\n",
            "5924\n",
            "5925\n",
            "5926\n",
            "5927\n",
            "5928\n",
            "5929\n",
            "5930\n",
            "5931\n",
            "5932\n",
            "5933\n",
            "5934\n",
            "5935\n",
            "5936\n",
            "5937\n",
            "5938\n",
            "5939\n",
            "5940\n",
            "5941\n",
            "5942\n",
            "5943\n",
            "5944\n",
            "5945\n",
            "5946\n",
            "5947\n",
            "5948\n",
            "5949\n",
            "5950\n",
            "5951\n",
            "5952\n",
            "5953\n",
            "5954\n",
            "5955\n",
            "5956\n",
            "5957\n",
            "5958\n",
            "5959\n",
            "5960\n",
            "5961\n",
            "5962\n",
            "5963\n",
            "5964\n",
            "5965\n",
            "5966\n",
            "5967\n",
            "5968\n",
            "5969\n",
            "5970\n",
            "5971\n",
            "5972\n",
            "5973\n",
            "5974\n",
            "5975\n",
            "5976\n",
            "5977\n",
            "5978\n",
            "5979\n",
            "5980\n",
            "5981\n",
            "5982\n",
            "5983\n",
            "5984\n",
            "5985\n",
            "5986\n",
            "5987\n",
            "5988\n",
            "5989\n",
            "5990\n",
            "5991\n",
            "5992\n",
            "5993\n",
            "5994\n",
            "5995\n",
            "5996\n",
            "5997\n",
            "5998\n",
            "5999\n",
            "6000\n",
            "6001\n",
            "6002\n",
            "6003\n",
            "6004\n",
            "6005\n",
            "6006\n",
            "6007\n",
            "6008\n",
            "6009\n",
            "6010\n",
            "6011\n",
            "6012\n",
            "6013\n",
            "6014\n",
            "6015\n",
            "6016\n",
            "6017\n",
            "6018\n",
            "6019\n",
            "6020\n",
            "6021\n",
            "6022\n",
            "6023\n",
            "6024\n",
            "6025\n",
            "6026\n",
            "6027\n",
            "6028\n",
            "6029\n",
            "6030\n",
            "6031\n",
            "6032\n",
            "6033\n",
            "6034\n",
            "6035\n",
            "6036\n",
            "6037\n",
            "6038\n",
            "6039\n",
            "6040\n",
            "6041\n",
            "6042\n",
            "6043\n",
            "6044\n",
            "6045\n",
            "6046\n",
            "6047\n",
            "6048\n",
            "6049\n",
            "6050\n",
            "6051\n",
            "6052\n",
            "6053\n",
            "6054\n",
            "6055\n",
            "6056\n",
            "6057\n",
            "6058\n",
            "6059\n",
            "6060\n",
            "6061\n",
            "6062\n",
            "6063\n",
            "6064\n",
            "6065\n",
            "6066\n",
            "6067\n",
            "6068\n",
            "6069\n",
            "6070\n",
            "6071\n",
            "6072\n",
            "6073\n",
            "6074\n",
            "6075\n",
            "6076\n",
            "6077\n",
            "6078\n",
            "6079\n",
            "6080\n",
            "6081\n",
            "6082\n",
            "6083\n",
            "6084\n",
            "6085\n",
            "6086\n",
            "6087\n",
            "6088\n",
            "6089\n",
            "6090\n",
            "6091\n",
            "6092\n",
            "6093\n",
            "6094\n",
            "6095\n",
            "6096\n",
            "6097\n",
            "6098\n",
            "6099\n",
            "6100\n",
            "6101\n",
            "6102\n",
            "6103\n",
            "6104\n",
            "6105\n",
            "6106\n",
            "6107\n",
            "6108\n",
            "6109\n",
            "6110\n",
            "6111\n",
            "6112\n",
            "6113\n",
            "6114\n",
            "6115\n",
            "6116\n",
            "6117\n",
            "6118\n",
            "6119\n",
            "6120\n",
            "6121\n",
            "6122\n",
            "6123\n",
            "6124\n",
            "6125\n",
            "6126\n",
            "6127\n",
            "6128\n",
            "6129\n",
            "6130\n",
            "6131\n",
            "6132\n",
            "6133\n",
            "6134\n",
            "6135\n",
            "6136\n",
            "6137\n",
            "6138\n",
            "6139\n",
            "6140\n",
            "6141\n",
            "6142\n",
            "6143\n",
            "6144\n",
            "6145\n",
            "6146\n",
            "6147\n",
            "6148\n",
            "6149\n",
            "6150\n",
            "6151\n",
            "6152\n",
            "6153\n",
            "6154\n",
            "6155\n",
            "6156\n",
            "6157\n",
            "6158\n",
            "6159\n",
            "6160\n",
            "6161\n",
            "6162\n",
            "6163\n",
            "6164\n",
            "6165\n",
            "6166\n",
            "6167\n",
            "6168\n",
            "6169\n",
            "6170\n",
            "6171\n",
            "6172\n",
            "6173\n",
            "6174\n",
            "6175\n",
            "6176\n",
            "6177\n",
            "6178\n",
            "6179\n",
            "6180\n",
            "6181\n",
            "6182\n",
            "6183\n",
            "6184\n",
            "6185\n",
            "6186\n",
            "6187\n",
            "6188\n",
            "6189\n",
            "6190\n",
            "6191\n",
            "6192\n",
            "6193\n",
            "6194\n",
            "6195\n",
            "6196\n",
            "6197\n",
            "6198\n",
            "6199\n",
            "6200\n",
            "6201\n",
            "6202\n",
            "6203\n",
            "6204\n",
            "6205\n",
            "6206\n",
            "6207\n",
            "6208\n",
            "6209\n",
            "6210\n",
            "6211\n",
            "6212\n",
            "6213\n",
            "6214\n",
            "6215\n",
            "6216\n",
            "6217\n",
            "6218\n",
            "6219\n",
            "6220\n",
            "6221\n",
            "6222\n",
            "6223\n",
            "6224\n",
            "6225\n",
            "6226\n",
            "6227\n",
            "6228\n",
            "6229\n",
            "6230\n",
            "6231\n",
            "6232\n",
            "6233\n",
            "6234\n",
            "6235\n",
            "6236\n",
            "6237\n",
            "6238\n",
            "6239\n",
            "6240\n",
            "6241\n",
            "6242\n",
            "6243\n",
            "6244\n",
            "6245\n",
            "6246\n",
            "6247\n",
            "6248\n",
            "6249\n",
            "6250\n",
            "6251\n",
            "6252\n",
            "6253\n",
            "6254\n",
            "6255\n",
            "6256\n",
            "6257\n",
            "6258\n",
            "6259\n",
            "6260\n",
            "6261\n",
            "6262\n",
            "6263\n",
            "6264\n",
            "6265\n",
            "6266\n",
            "6267\n",
            "6268\n",
            "6269\n",
            "6270\n",
            "6271\n",
            "6272\n",
            "6273\n",
            "6274\n",
            "6275\n",
            "6276\n",
            "6277\n",
            "6278\n",
            "6279\n",
            "6280\n",
            "6281\n",
            "6282\n",
            "6283\n",
            "6284\n",
            "6285\n",
            "6286\n",
            "6287\n",
            "6288\n",
            "6289\n",
            "6290\n",
            "6291\n",
            "6292\n",
            "6293\n",
            "6294\n",
            "6295\n",
            "6296\n",
            "6297\n",
            "6298\n",
            "6299\n",
            "6300\n",
            "6301\n",
            "6302\n",
            "6303\n",
            "6304\n",
            "6305\n",
            "6306\n",
            "6307\n",
            "6308\n",
            "6309\n",
            "6310\n",
            "6311\n",
            "6312\n",
            "6313\n",
            "6314\n",
            "6315\n",
            "6316\n",
            "6317\n",
            "6318\n",
            "6319\n",
            "6320\n",
            "6321\n",
            "6322\n",
            "6323\n",
            "6324\n",
            "6325\n",
            "6326\n",
            "6327\n",
            "6328\n",
            "6329\n",
            "6330\n",
            "6331\n",
            "6332\n",
            "6333\n",
            "6334\n",
            "6335\n",
            "6336\n",
            "6337\n",
            "6338\n",
            "6339\n",
            "6340\n",
            "6341\n",
            "6342\n",
            "6343\n",
            "6344\n",
            "6345\n",
            "6346\n",
            "6347\n",
            "6348\n",
            "6349\n",
            "6350\n",
            "6351\n",
            "6352\n",
            "6353\n",
            "6354\n",
            "6355\n",
            "6356\n",
            "6357\n",
            "6358\n",
            "6359\n",
            "6360\n",
            "6361\n",
            "6362\n",
            "6363\n",
            "6364\n",
            "6365\n",
            "6366\n",
            "6367\n",
            "6368\n",
            "6369\n",
            "6370\n",
            "6371\n",
            "6372\n",
            "6373\n",
            "6374\n",
            "6375\n",
            "6376\n",
            "6377\n",
            "6378\n",
            "6379\n",
            "6380\n",
            "6381\n",
            "6382\n",
            "6383\n",
            "6384\n",
            "6385\n",
            "6386\n",
            "6387\n",
            "6388\n",
            "6389\n",
            "6390\n",
            "6391\n",
            "6392\n",
            "6393\n",
            "6394\n",
            "6395\n",
            "6396\n",
            "6397\n",
            "6398\n",
            "6399\n",
            "6400\n",
            "6401\n",
            "6402\n",
            "6403\n",
            "6404\n",
            "6405\n",
            "6406\n",
            "6407\n",
            "6408\n",
            "6409\n",
            "6410\n",
            "6411\n",
            "6412\n",
            "6413\n",
            "6414\n",
            "6415\n",
            "6416\n",
            "6417\n",
            "6418\n",
            "6419\n",
            "6420\n",
            "6421\n",
            "6422\n",
            "6423\n",
            "6424\n",
            "6425\n",
            "6426\n",
            "6427\n",
            "6428\n",
            "6429\n",
            "6430\n",
            "6431\n",
            "6432\n",
            "6433\n",
            "6434\n",
            "6435\n",
            "6436\n",
            "6437\n",
            "6438\n",
            "6439\n",
            "6440\n",
            "6441\n",
            "6442\n",
            "6443\n",
            "6444\n",
            "6445\n",
            "6446\n",
            "6447\n",
            "6448\n",
            "6449\n",
            "6450\n",
            "6451\n",
            "6452\n",
            "6453\n",
            "6454\n",
            "6455\n",
            "6456\n",
            "6457\n",
            "6458\n",
            "6459\n",
            "6460\n",
            "6461\n",
            "6462\n",
            "6463\n",
            "6464\n",
            "6465\n",
            "6466\n",
            "6467\n",
            "6468\n",
            "6469\n",
            "6470\n",
            "6471\n",
            "6472\n",
            "6473\n",
            "6474\n",
            "6475\n",
            "6476\n",
            "6477\n",
            "6478\n",
            "6479\n",
            "6480\n",
            "6481\n",
            "6482\n",
            "6483\n",
            "6484\n",
            "6485\n",
            "6486\n",
            "6487\n",
            "6488\n",
            "6489\n",
            "6490\n",
            "6491\n",
            "6492\n",
            "6493\n",
            "6494\n",
            "6495\n",
            "6496\n",
            "6497\n",
            "6498\n",
            "6499\n",
            "6500\n",
            "6501\n",
            "6502\n",
            "6503\n",
            "6504\n",
            "6505\n",
            "6506\n",
            "6507\n",
            "6508\n",
            "6509\n",
            "6510\n",
            "6511\n",
            "6512\n",
            "6513\n",
            "6514\n",
            "6515\n",
            "6516\n",
            "6517\n",
            "6518\n",
            "6519\n",
            "6520\n",
            "6521\n",
            "6522\n",
            "6523\n",
            "6524\n",
            "6525\n",
            "6526\n",
            "6527\n",
            "6528\n",
            "6529\n",
            "6530\n",
            "6531\n",
            "6532\n",
            "6533\n",
            "6534\n",
            "6535\n",
            "6536\n",
            "6537\n",
            "6538\n",
            "6539\n",
            "6540\n",
            "6541\n",
            "6542\n",
            "6543\n",
            "6544\n",
            "6545\n",
            "6546\n",
            "6547\n",
            "6548\n",
            "6549\n",
            "6550\n",
            "6551\n",
            "6552\n",
            "6553\n",
            "6554\n",
            "6555\n",
            "6556\n",
            "6557\n",
            "6558\n",
            "6559\n",
            "6560\n",
            "6561\n",
            "6562\n",
            "6563\n",
            "6564\n",
            "6565\n",
            "6566\n",
            "6567\n",
            "6568\n",
            "6569\n",
            "6570\n",
            "6571\n",
            "6572\n",
            "6573\n",
            "6574\n",
            "6575\n",
            "6576\n",
            "6577\n",
            "6578\n",
            "6579\n",
            "6580\n",
            "6581\n",
            "6582\n",
            "6583\n",
            "6584\n",
            "6585\n",
            "6586\n",
            "6587\n",
            "6588\n",
            "6589\n",
            "6590\n",
            "6591\n",
            "6592\n",
            "6593\n",
            "6594\n",
            "6595\n",
            "6596\n",
            "6597\n",
            "6598\n",
            "6599\n",
            "6600\n",
            "6601\n",
            "6602\n",
            "6603\n",
            "6604\n",
            "6605\n",
            "6606\n",
            "6607\n",
            "6608\n",
            "6609\n",
            "6610\n",
            "6611\n",
            "6612\n",
            "6613\n",
            "6614\n",
            "6615\n",
            "6616\n",
            "6617\n",
            "6618\n",
            "6619\n",
            "6620\n",
            "6621\n",
            "6622\n",
            "6623\n",
            "6624\n",
            "6625\n",
            "6626\n",
            "6627\n",
            "6628\n",
            "6629\n",
            "6630\n",
            "6631\n",
            "6632\n",
            "6633\n",
            "6634\n",
            "6635\n",
            "6636\n",
            "6637\n",
            "6638\n",
            "6639\n",
            "6640\n",
            "6641\n",
            "6642\n",
            "6643\n",
            "6644\n",
            "6645\n",
            "6646\n",
            "6647\n",
            "6648\n",
            "6649\n",
            "6650\n",
            "6651\n",
            "6652\n",
            "6653\n",
            "6654\n",
            "6655\n",
            "6656\n",
            "6657\n",
            "6658\n",
            "6659\n",
            "6660\n",
            "6661\n",
            "6662\n",
            "6663\n",
            "6664\n",
            "6665\n",
            "6666\n",
            "6667\n",
            "6668\n",
            "6669\n",
            "6670\n",
            "6671\n",
            "6672\n",
            "6673\n",
            "6674\n",
            "6675\n",
            "6676\n",
            "6677\n",
            "6678\n",
            "6679\n",
            "6680\n",
            "6681\n",
            "6682\n",
            "6683\n",
            "6684\n",
            "6685\n",
            "6686\n",
            "6687\n",
            "6688\n",
            "6689\n",
            "6690\n",
            "6691\n",
            "6692\n",
            "6693\n",
            "6694\n",
            "6695\n",
            "6696\n",
            "6697\n",
            "6698\n",
            "6699\n",
            "6700\n",
            "6701\n",
            "6702\n",
            "6703\n",
            "6704\n",
            "6705\n",
            "6706\n",
            "6707\n",
            "6708\n",
            "6709\n",
            "6710\n",
            "6711\n",
            "6712\n",
            "6713\n",
            "6714\n",
            "6715\n",
            "6716\n",
            "6717\n",
            "6718\n",
            "6719\n",
            "6720\n",
            "6721\n",
            "6722\n",
            "6723\n",
            "6724\n",
            "6725\n",
            "6726\n",
            "6727\n",
            "6728\n",
            "6729\n",
            "6730\n",
            "6731\n",
            "6732\n",
            "6733\n",
            "6734\n",
            "6735\n",
            "6736\n",
            "6737\n",
            "6738\n",
            "6739\n",
            "6740\n",
            "6741\n",
            "6742\n",
            "6743\n",
            "6744\n",
            "6745\n",
            "6746\n",
            "6747\n",
            "6748\n",
            "6749\n",
            "6750\n",
            "6751\n",
            "6752\n",
            "6753\n",
            "6754\n",
            "6755\n",
            "6756\n",
            "6757\n",
            "6758\n",
            "6759\n",
            "6760\n",
            "6761\n",
            "6762\n",
            "6763\n",
            "6764\n",
            "6765\n",
            "6766\n",
            "6767\n",
            "6768\n",
            "6769\n",
            "6770\n",
            "6771\n",
            "6772\n",
            "6773\n",
            "6774\n",
            "6775\n",
            "6776\n",
            "6777\n",
            "6778\n",
            "6779\n",
            "6780\n",
            "6781\n",
            "6782\n",
            "6783\n",
            "6784\n",
            "6785\n",
            "6786\n",
            "6787\n",
            "6788\n",
            "6789\n",
            "6790\n",
            "6791\n",
            "6792\n",
            "6793\n",
            "6794\n",
            "6795\n",
            "6796\n",
            "6797\n",
            "6798\n",
            "6799\n",
            "6800\n",
            "6801\n",
            "6802\n",
            "6803\n",
            "6804\n",
            "6805\n",
            "6806\n",
            "6807\n",
            "6808\n",
            "6809\n",
            "6810\n",
            "6811\n",
            "6812\n",
            "6813\n",
            "6814\n",
            "6815\n",
            "6816\n",
            "6817\n",
            "6818\n",
            "6819\n",
            "6820\n",
            "6821\n",
            "6822\n",
            "6823\n",
            "6824\n",
            "6825\n",
            "6826\n",
            "6827\n",
            "6828\n",
            "6829\n",
            "6830\n",
            "6831\n",
            "6832\n",
            "6833\n",
            "6834\n",
            "6835\n",
            "6836\n",
            "6837\n",
            "6838\n",
            "6839\n",
            "6840\n",
            "6841\n",
            "6842\n",
            "6843\n",
            "6844\n",
            "6845\n",
            "6846\n",
            "6847\n",
            "6848\n",
            "6849\n",
            "6850\n",
            "6851\n",
            "6852\n",
            "6853\n",
            "6854\n",
            "6855\n",
            "6856\n",
            "6857\n",
            "6858\n",
            "6859\n",
            "6860\n",
            "6861\n",
            "6862\n",
            "6863\n",
            "6864\n",
            "6865\n",
            "6866\n",
            "6867\n",
            "6868\n",
            "6869\n",
            "6870\n",
            "6871\n",
            "6872\n",
            "6873\n",
            "6874\n",
            "6875\n",
            "6876\n",
            "6877\n",
            "6878\n",
            "6879\n",
            "6880\n",
            "6881\n",
            "6882\n",
            "6883\n",
            "6884\n",
            "6885\n",
            "6886\n",
            "6887\n",
            "6888\n",
            "6889\n",
            "6890\n",
            "6891\n",
            "6892\n",
            "6893\n",
            "6894\n",
            "6895\n",
            "6896\n",
            "6897\n",
            "6898\n",
            "6899\n",
            "6900\n",
            "6901\n",
            "6902\n",
            "6903\n",
            "6904\n",
            "6905\n",
            "6906\n",
            "6907\n",
            "6908\n",
            "6909\n",
            "6910\n",
            "6911\n",
            "6912\n",
            "6913\n",
            "6914\n",
            "6915\n",
            "6916\n",
            "6917\n",
            "6918\n",
            "6919\n",
            "6920\n",
            "6921\n",
            "6922\n",
            "6923\n",
            "6924\n",
            "6925\n",
            "6926\n",
            "6927\n",
            "6928\n",
            "6929\n",
            "6930\n",
            "6931\n",
            "6932\n",
            "6933\n",
            "6934\n",
            "6935\n",
            "6936\n",
            "6937\n",
            "6938\n",
            "6939\n",
            "6940\n",
            "6941\n",
            "6942\n",
            "6943\n",
            "6944\n",
            "6945\n",
            "6946\n",
            "6947\n",
            "6948\n",
            "6949\n",
            "6950\n",
            "6951\n",
            "6952\n",
            "6953\n",
            "6954\n",
            "6955\n",
            "6956\n",
            "6957\n",
            "6958\n",
            "6959\n",
            "6960\n",
            "6961\n",
            "6962\n",
            "6963\n",
            "6964\n",
            "6965\n",
            "6966\n",
            "6967\n",
            "6968\n",
            "6969\n",
            "6970\n",
            "6971\n",
            "6972\n",
            "6973\n",
            "6974\n",
            "6975\n",
            "6976\n",
            "6977\n",
            "6978\n",
            "6979\n",
            "6980\n",
            "6981\n",
            "6982\n",
            "6983\n",
            "6984\n",
            "6985\n",
            "6986\n",
            "6987\n",
            "6988\n",
            "6989\n",
            "6990\n",
            "6991\n",
            "6992\n",
            "6993\n",
            "6994\n",
            "6995\n",
            "6996\n",
            "6997\n",
            "6998\n",
            "6999\n",
            "7000\n",
            "7001\n",
            "7002\n",
            "7003\n",
            "7004\n",
            "7005\n",
            "7006\n",
            "7007\n",
            "7008\n",
            "7009\n",
            "7010\n",
            "7011\n",
            "7012\n",
            "7013\n",
            "7014\n",
            "7015\n",
            "7016\n",
            "7017\n",
            "7018\n",
            "7019\n",
            "7020\n",
            "7021\n",
            "7022\n",
            "7023\n",
            "7024\n",
            "7025\n",
            "7026\n",
            "7027\n",
            "7028\n",
            "7029\n",
            "7030\n",
            "7031\n",
            "7032\n",
            "7033\n",
            "7034\n",
            "7035\n",
            "7036\n",
            "7037\n",
            "7038\n",
            "7039\n",
            "7040\n",
            "7041\n",
            "7042\n",
            "7043\n",
            "7044\n",
            "7045\n",
            "7046\n",
            "7047\n",
            "7048\n",
            "7049\n",
            "7050\n",
            "7051\n",
            "7052\n",
            "7053\n",
            "7054\n",
            "7055\n",
            "7056\n",
            "7057\n",
            "7058\n",
            "7059\n",
            "7060\n",
            "7061\n",
            "7062\n",
            "7063\n",
            "7064\n",
            "7065\n",
            "7066\n",
            "7067\n",
            "7068\n",
            "7069\n",
            "7070\n",
            "7071\n",
            "7072\n",
            "7073\n",
            "7074\n",
            "7075\n",
            "7076\n",
            "7077\n",
            "7078\n",
            "7079\n",
            "7080\n",
            "7081\n",
            "7082\n",
            "7083\n",
            "7084\n",
            "7085\n",
            "7086\n",
            "7087\n",
            "7088\n",
            "7089\n",
            "7090\n",
            "7091\n",
            "7092\n",
            "7093\n",
            "7094\n",
            "7095\n",
            "7096\n",
            "7097\n",
            "7098\n",
            "7099\n",
            "7100\n",
            "7101\n",
            "7102\n",
            "7103\n",
            "7104\n",
            "7105\n",
            "7106\n",
            "7107\n",
            "7108\n",
            "7109\n",
            "7110\n",
            "7111\n",
            "7112\n",
            "7113\n",
            "7114\n",
            "7115\n",
            "7116\n",
            "7117\n",
            "7118\n",
            "7119\n",
            "7120\n",
            "7121\n",
            "7122\n",
            "7123\n",
            "7124\n",
            "7125\n",
            "7126\n",
            "7127\n",
            "7128\n",
            "7129\n",
            "7130\n",
            "7131\n",
            "7132\n",
            "7133\n",
            "7134\n",
            "7135\n",
            "7136\n",
            "7137\n",
            "7138\n",
            "7139\n",
            "7140\n",
            "7141\n",
            "7142\n",
            "7143\n",
            "7144\n",
            "7145\n",
            "7146\n",
            "7147\n",
            "7148\n",
            "7149\n",
            "7150\n",
            "7151\n",
            "7152\n",
            "7153\n",
            "7154\n",
            "7155\n",
            "7156\n",
            "7157\n",
            "7158\n",
            "7159\n",
            "7160\n",
            "7161\n",
            "7162\n",
            "7163\n",
            "7164\n",
            "7165\n",
            "7166\n",
            "7167\n",
            "7168\n",
            "7169\n",
            "7170\n",
            "7171\n",
            "7172\n",
            "7173\n",
            "7174\n",
            "7175\n",
            "7176\n",
            "7177\n",
            "7178\n",
            "7179\n",
            "7180\n",
            "7181\n",
            "7182\n",
            "7183\n",
            "7184\n",
            "7185\n",
            "7186\n",
            "7187\n",
            "7188\n",
            "7189\n",
            "7190\n",
            "7191\n",
            "7192\n",
            "7193\n",
            "7194\n",
            "7195\n",
            "7196\n",
            "7197\n",
            "7198\n",
            "7199\n",
            "7200\n",
            "7201\n",
            "7202\n",
            "7203\n",
            "7204\n",
            "7205\n",
            "7206\n",
            "7207\n",
            "7208\n",
            "7209\n",
            "7210\n",
            "7211\n",
            "7212\n",
            "7213\n",
            "7214\n",
            "7215\n",
            "7216\n",
            "7217\n",
            "7218\n",
            "7219\n",
            "7220\n",
            "7221\n",
            "7222\n",
            "7223\n",
            "7224\n",
            "7225\n",
            "7226\n",
            "7227\n",
            "7228\n",
            "7229\n",
            "7230\n",
            "7231\n",
            "7232\n",
            "7233\n",
            "7234\n",
            "7235\n",
            "7236\n",
            "7237\n",
            "7238\n",
            "7239\n",
            "7240\n",
            "7241\n",
            "7242\n",
            "7243\n",
            "7244\n",
            "7245\n",
            "7246\n",
            "7247\n",
            "7248\n",
            "7249\n",
            "7250\n",
            "7251\n",
            "7252\n",
            "7253\n",
            "7254\n",
            "7255\n",
            "7256\n",
            "7257\n",
            "7258\n",
            "7259\n",
            "7260\n",
            "7261\n",
            "7262\n",
            "7263\n",
            "7264\n",
            "7265\n",
            "7266\n",
            "7267\n",
            "7268\n",
            "7269\n",
            "7270\n",
            "7271\n",
            "7272\n",
            "7273\n",
            "7274\n",
            "7275\n",
            "7276\n",
            "7277\n",
            "7278\n",
            "7279\n",
            "7280\n",
            "7281\n",
            "7282\n",
            "7283\n",
            "7284\n",
            "7285\n",
            "7286\n",
            "7287\n",
            "7288\n",
            "7289\n",
            "7290\n",
            "7291\n",
            "7292\n",
            "7293\n",
            "7294\n",
            "7295\n",
            "7296\n",
            "7297\n",
            "7298\n",
            "7299\n",
            "7300\n",
            "7301\n",
            "7302\n",
            "7303\n",
            "7304\n",
            "7305\n",
            "7306\n",
            "7307\n",
            "7308\n",
            "7309\n",
            "7310\n",
            "7311\n",
            "7312\n",
            "7313\n",
            "7314\n",
            "7315\n",
            "7316\n",
            "7317\n",
            "7318\n",
            "7319\n",
            "7320\n",
            "7321\n",
            "7322\n",
            "7323\n",
            "7324\n",
            "7325\n",
            "7326\n",
            "7327\n",
            "7328\n",
            "7329\n",
            "7330\n",
            "7331\n",
            "7332\n",
            "7333\n",
            "7334\n",
            "7335\n",
            "7336\n",
            "7337\n",
            "7338\n",
            "7339\n",
            "7340\n",
            "7341\n",
            "7342\n",
            "7343\n",
            "7344\n",
            "7345\n",
            "7346\n",
            "7347\n",
            "7348\n",
            "7349\n",
            "7350\n",
            "7351\n",
            "7352\n",
            "7353\n",
            "7354\n",
            "7355\n",
            "7356\n",
            "7357\n",
            "7358\n",
            "7359\n",
            "7360\n",
            "7361\n",
            "7362\n",
            "7363\n",
            "7364\n",
            "7365\n",
            "7366\n",
            "7367\n",
            "7368\n",
            "7369\n",
            "7370\n",
            "7371\n",
            "7372\n",
            "7373\n",
            "7374\n",
            "7375\n",
            "7376\n",
            "7377\n",
            "7378\n",
            "7379\n",
            "7380\n",
            "7381\n",
            "7382\n",
            "7383\n",
            "7384\n",
            "7385\n",
            "7386\n",
            "7387\n",
            "7388\n",
            "7389\n",
            "7390\n",
            "7391\n",
            "7392\n",
            "7393\n",
            "7394\n",
            "7395\n",
            "7396\n",
            "7397\n",
            "7398\n",
            "7399\n",
            "7400\n",
            "7401\n",
            "7402\n",
            "7403\n",
            "7404\n",
            "7405\n",
            "7406\n",
            "7407\n",
            "7408\n",
            "7409\n",
            "7410\n",
            "7411\n",
            "7412\n",
            "7413\n",
            "7414\n",
            "7415\n",
            "7416\n",
            "7417\n",
            "7418\n",
            "7419\n",
            "7420\n",
            "7421\n",
            "7422\n",
            "7423\n",
            "7424\n",
            "7425\n",
            "7426\n",
            "7427\n",
            "7428\n",
            "7429\n",
            "7430\n",
            "7431\n",
            "7432\n",
            "7433\n",
            "7434\n",
            "7435\n",
            "7436\n",
            "7437\n",
            "7438\n",
            "7439\n",
            "7440\n",
            "7441\n",
            "7442\n",
            "7443\n",
            "7444\n",
            "7445\n",
            "7446\n",
            "7447\n",
            "7448\n",
            "7449\n",
            "7450\n",
            "7451\n",
            "7452\n",
            "7453\n",
            "7454\n",
            "7455\n",
            "7456\n",
            "7457\n",
            "7458\n",
            "7459\n",
            "7460\n",
            "7461\n",
            "7462\n",
            "7463\n",
            "7464\n",
            "7465\n",
            "7466\n",
            "7467\n",
            "7468\n",
            "7469\n",
            "7470\n",
            "7471\n",
            "7472\n",
            "7473\n",
            "7474\n",
            "7475\n",
            "7476\n",
            "7477\n",
            "7478\n",
            "7479\n",
            "7480\n",
            "7481\n",
            "7482\n",
            "7483\n",
            "7484\n",
            "7485\n",
            "7486\n",
            "7487\n",
            "7488\n",
            "7489\n",
            "7490\n",
            "7491\n",
            "7492\n",
            "7493\n",
            "7494\n",
            "7495\n",
            "7496\n",
            "7497\n",
            "7498\n",
            "7499\n",
            "7500\n",
            "7501\n",
            "7502\n",
            "7503\n",
            "7504\n",
            "7505\n",
            "7506\n",
            "7507\n",
            "7508\n",
            "7509\n",
            "7510\n",
            "7511\n",
            "7512\n",
            "7513\n",
            "7514\n",
            "7515\n",
            "7516\n",
            "7517\n",
            "7518\n",
            "7519\n",
            "7520\n",
            "7521\n",
            "7522\n",
            "7523\n",
            "7524\n",
            "7525\n",
            "7526\n",
            "7527\n",
            "7528\n",
            "7529\n",
            "7530\n",
            "7531\n",
            "7532\n",
            "7533\n",
            "7534\n",
            "7535\n",
            "7536\n",
            "7537\n",
            "7538\n",
            "7539\n",
            "7540\n",
            "7541\n",
            "7542\n",
            "7543\n",
            "7544\n",
            "7545\n",
            "7546\n",
            "7547\n",
            "7548\n",
            "7549\n",
            "7550\n",
            "7551\n",
            "7552\n",
            "7553\n",
            "7554\n",
            "7555\n",
            "7556\n",
            "7557\n",
            "7558\n",
            "7559\n",
            "7560\n",
            "7561\n",
            "7562\n",
            "7563\n",
            "7564\n",
            "7565\n",
            "7566\n",
            "7567\n",
            "7568\n",
            "7569\n",
            "7570\n",
            "7571\n",
            "7572\n",
            "7573\n",
            "7574\n",
            "7575\n",
            "7576\n",
            "7577\n",
            "7578\n",
            "7579\n",
            "7580\n",
            "7581\n",
            "7582\n",
            "7583\n",
            "7584\n",
            "7585\n",
            "7586\n",
            "7587\n",
            "7588\n",
            "7589\n",
            "7590\n",
            "7591\n",
            "7592\n",
            "7593\n",
            "7594\n",
            "7595\n",
            "7596\n",
            "7597\n",
            "7598\n",
            "7599\n",
            "7600\n",
            "7601\n",
            "7602\n",
            "7603\n",
            "7604\n",
            "7605\n",
            "7606\n",
            "7607\n",
            "7608\n",
            "7609\n",
            "7610\n",
            "7611\n",
            "7612\n",
            "7613\n",
            "7614\n",
            "7615\n",
            "7616\n",
            "7617\n",
            "7618\n",
            "7619\n",
            "7620\n",
            "7621\n",
            "7622\n",
            "7623\n",
            "7624\n",
            "7625\n",
            "7626\n",
            "7627\n",
            "7628\n",
            "7629\n",
            "7630\n",
            "7631\n",
            "7632\n",
            "7633\n",
            "7634\n",
            "7635\n",
            "7636\n",
            "7637\n",
            "7638\n",
            "7639\n",
            "7640\n",
            "7641\n",
            "7642\n",
            "7643\n",
            "7644\n",
            "7645\n",
            "7646\n",
            "7647\n",
            "7648\n",
            "7649\n",
            "7650\n",
            "7651\n",
            "7652\n",
            "7653\n",
            "7654\n",
            "7655\n",
            "7656\n",
            "7657\n",
            "7658\n",
            "7659\n",
            "7660\n",
            "7661\n",
            "7662\n",
            "7663\n",
            "7664\n",
            "7665\n",
            "7666\n",
            "7667\n",
            "7668\n",
            "7669\n",
            "7670\n",
            "7671\n",
            "7672\n",
            "7673\n",
            "7674\n",
            "7675\n",
            "7676\n",
            "7677\n",
            "7678\n",
            "7679\n",
            "7680\n",
            "7681\n",
            "7682\n",
            "7683\n",
            "7684\n",
            "7685\n",
            "7686\n",
            "7687\n",
            "7688\n",
            "7689\n",
            "7690\n",
            "7691\n",
            "7692\n",
            "7693\n",
            "7694\n",
            "7695\n",
            "7696\n",
            "7697\n",
            "7698\n",
            "7699\n",
            "7700\n",
            "7701\n",
            "7702\n",
            "7703\n",
            "7704\n",
            "7705\n",
            "7706\n",
            "7707\n",
            "7708\n",
            "7709\n",
            "7710\n",
            "7711\n",
            "7712\n",
            "7713\n",
            "7714\n",
            "7715\n",
            "7716\n",
            "7717\n",
            "7718\n",
            "7719\n",
            "7720\n",
            "7721\n",
            "7722\n",
            "7723\n",
            "7724\n",
            "7725\n",
            "7726\n",
            "7727\n",
            "7728\n",
            "7729\n",
            "7730\n",
            "7731\n",
            "7732\n",
            "7733\n",
            "7734\n",
            "7735\n",
            "7736\n",
            "7737\n",
            "7738\n",
            "7739\n",
            "7740\n",
            "7741\n",
            "7742\n",
            "7743\n",
            "7744\n",
            "7745\n",
            "7746\n",
            "7747\n",
            "7748\n",
            "7749\n",
            "7750\n",
            "7751\n",
            "7752\n",
            "7753\n",
            "7754\n",
            "7755\n",
            "7756\n",
            "7757\n",
            "7758\n",
            "7759\n",
            "7760\n",
            "7761\n",
            "7762\n",
            "7763\n",
            "7764\n",
            "7765\n",
            "7766\n",
            "7767\n",
            "7768\n",
            "7769\n",
            "7770\n",
            "7771\n",
            "7772\n",
            "7773\n",
            "7774\n",
            "7775\n",
            "7776\n",
            "7777\n",
            "7778\n",
            "7779\n",
            "7780\n",
            "7781\n",
            "7782\n",
            "7783\n",
            "7784\n",
            "7785\n",
            "7786\n",
            "7787\n",
            "7788\n",
            "7789\n",
            "7790\n",
            "7791\n",
            "7792\n",
            "7793\n",
            "7794\n",
            "7795\n",
            "7796\n",
            "7797\n",
            "7798\n",
            "7799\n",
            "7800\n",
            "7801\n",
            "7802\n",
            "7803\n",
            "7804\n",
            "7805\n",
            "7806\n",
            "7807\n",
            "7808\n",
            "7809\n",
            "7810\n",
            "7811\n",
            "7812\n",
            "7813\n",
            "7814\n",
            "7815\n",
            "7816\n",
            "7817\n",
            "7818\n",
            "7819\n",
            "7820\n",
            "7821\n",
            "7822\n",
            "7823\n",
            "7824\n",
            "7825\n",
            "7826\n",
            "7827\n",
            "7828\n",
            "7829\n",
            "7830\n",
            "7831\n",
            "7832\n",
            "7833\n",
            "7834\n",
            "7835\n",
            "7836\n",
            "7837\n",
            "7838\n",
            "7839\n",
            "7840\n",
            "7841\n",
            "7842\n",
            "7843\n",
            "7844\n",
            "7845\n",
            "7846\n",
            "7847\n",
            "7848\n",
            "7849\n",
            "7850\n",
            "7851\n",
            "7852\n",
            "7853\n",
            "7854\n",
            "7855\n",
            "7856\n",
            "7857\n",
            "7858\n",
            "7859\n",
            "7860\n",
            "7861\n",
            "7862\n",
            "7863\n",
            "7864\n",
            "7865\n",
            "7866\n",
            "7867\n",
            "7868\n",
            "7869\n",
            "7870\n",
            "7871\n",
            "7872\n",
            "7873\n",
            "7874\n",
            "7875\n",
            "7876\n",
            "7877\n",
            "7878\n",
            "7879\n",
            "7880\n",
            "7881\n",
            "7882\n",
            "7883\n",
            "7884\n",
            "7885\n",
            "7886\n",
            "7887\n",
            "7888\n",
            "7889\n",
            "7890\n",
            "7891\n",
            "7892\n",
            "7893\n",
            "7894\n",
            "7895\n",
            "7896\n",
            "7897\n",
            "7898\n",
            "7899\n",
            "7900\n",
            "7901\n",
            "7902\n",
            "7903\n",
            "7904\n",
            "7905\n",
            "7906\n",
            "7907\n",
            "7908\n",
            "7909\n",
            "7910\n",
            "7911\n",
            "7912\n",
            "7913\n",
            "7914\n",
            "7915\n",
            "7916\n",
            "7917\n",
            "7918\n",
            "7919\n",
            "7920\n",
            "7921\n",
            "7922\n",
            "7923\n",
            "7924\n",
            "7925\n",
            "7926\n",
            "7927\n",
            "7928\n",
            "7929\n",
            "7930\n",
            "7931\n",
            "7932\n",
            "7933\n",
            "7934\n",
            "7935\n",
            "7936\n",
            "7937\n",
            "7938\n",
            "7939\n",
            "7940\n",
            "7941\n",
            "7942\n",
            "7943\n",
            "7944\n",
            "7945\n",
            "7946\n",
            "7947\n",
            "7948\n",
            "7949\n",
            "7950\n",
            "7951\n",
            "7952\n",
            "7953\n",
            "7954\n",
            "7955\n",
            "7956\n",
            "7957\n",
            "7958\n",
            "7959\n",
            "7960\n",
            "7961\n",
            "7962\n",
            "7963\n",
            "7964\n",
            "7965\n",
            "7966\n",
            "7967\n",
            "7968\n",
            "7969\n",
            "7970\n",
            "7971\n",
            "7972\n",
            "7973\n",
            "7974\n",
            "7975\n",
            "7976\n",
            "7977\n",
            "7978\n",
            "7979\n",
            "7980\n",
            "7981\n",
            "7982\n",
            "7983\n",
            "7984\n",
            "7985\n",
            "7986\n",
            "7987\n",
            "7988\n",
            "7989\n",
            "7990\n",
            "7991\n",
            "7992\n",
            "7993\n",
            "7994\n",
            "7995\n",
            "7996\n",
            "7997\n",
            "7998\n",
            "7999\n",
            "8000\n",
            "8001\n",
            "8002\n",
            "8003\n",
            "8004\n",
            "8005\n",
            "8006\n",
            "8007\n",
            "8008\n",
            "8009\n",
            "8010\n",
            "8011\n",
            "8012\n",
            "8013\n",
            "8014\n",
            "8015\n",
            "8016\n",
            "8017\n",
            "8018\n",
            "8019\n",
            "8020\n",
            "8021\n",
            "8022\n",
            "8023\n",
            "8024\n",
            "8025\n",
            "8026\n",
            "8027\n",
            "8028\n",
            "8029\n",
            "8030\n",
            "8031\n",
            "8032\n",
            "8033\n",
            "8034\n",
            "8035\n",
            "8036\n",
            "8037\n",
            "8038\n",
            "8039\n",
            "8040\n",
            "8041\n",
            "8042\n",
            "8043\n",
            "8044\n",
            "8045\n",
            "8046\n",
            "8047\n",
            "8048\n",
            "8049\n",
            "8050\n",
            "8051\n",
            "8052\n",
            "8053\n",
            "8054\n",
            "8055\n",
            "8056\n",
            "8057\n",
            "8058\n",
            "8059\n",
            "8060\n",
            "8061\n",
            "8062\n",
            "8063\n",
            "8064\n",
            "8065\n",
            "8066\n",
            "8067\n",
            "8068\n",
            "8069\n",
            "8070\n",
            "8071\n",
            "8072\n",
            "8073\n",
            "8074\n",
            "8075\n",
            "8076\n",
            "8077\n",
            "8078\n",
            "8079\n",
            "8080\n",
            "8081\n",
            "8082\n",
            "8083\n",
            "8084\n",
            "8085\n",
            "8086\n",
            "8087\n",
            "8088\n",
            "8089\n",
            "8090\n",
            "8091\n",
            "8092\n",
            "8093\n",
            "8094\n",
            "8095\n",
            "8096\n",
            "8097\n",
            "8098\n",
            "8099\n",
            "8100\n",
            "8101\n",
            "8102\n",
            "8103\n",
            "8104\n",
            "8105\n",
            "8106\n",
            "8107\n",
            "8108\n",
            "8109\n",
            "8110\n",
            "8111\n",
            "8112\n",
            "8113\n",
            "8114\n",
            "8115\n",
            "8116\n",
            "8117\n",
            "8118\n",
            "8119\n",
            "8120\n",
            "8121\n",
            "8122\n",
            "8123\n",
            "8124\n",
            "8125\n",
            "8126\n",
            "8127\n",
            "8128\n",
            "8129\n",
            "8130\n",
            "8131\n",
            "8132\n",
            "8133\n",
            "8134\n",
            "8135\n",
            "8136\n",
            "8137\n",
            "8138\n",
            "8139\n",
            "8140\n",
            "8141\n",
            "8142\n",
            "8143\n",
            "8144\n",
            "8145\n",
            "8146\n",
            "8147\n",
            "8148\n",
            "8149\n",
            "8150\n",
            "8151\n",
            "8152\n",
            "8153\n",
            "8154\n",
            "8155\n",
            "8156\n",
            "8157\n",
            "8158\n",
            "8159\n",
            "8160\n",
            "8161\n",
            "8162\n",
            "8163\n",
            "8164\n",
            "8165\n",
            "8166\n",
            "8167\n",
            "8168\n",
            "8169\n",
            "8170\n",
            "8171\n",
            "8172\n",
            "8173\n",
            "8174\n",
            "8175\n",
            "8176\n",
            "8177\n",
            "8178\n",
            "8179\n",
            "8180\n",
            "8181\n",
            "8182\n",
            "8183\n",
            "8184\n",
            "8185\n",
            "8186\n",
            "8187\n",
            "8188\n",
            "8189\n",
            "8190\n",
            "8191\n",
            "8192\n",
            "8193\n",
            "8194\n",
            "8195\n",
            "8196\n",
            "8197\n",
            "8198\n",
            "8199\n",
            "8200\n",
            "8201\n",
            "8202\n",
            "8203\n",
            "8204\n",
            "8205\n",
            "8206\n",
            "8207\n",
            "8208\n",
            "8209\n",
            "8210\n",
            "8211\n",
            "8212\n",
            "8213\n",
            "8214\n",
            "8215\n",
            "8216\n",
            "8217\n",
            "8218\n",
            "8219\n",
            "8220\n",
            "8221\n",
            "8222\n",
            "8223\n",
            "8224\n",
            "8225\n",
            "8226\n",
            "8227\n",
            "8228\n",
            "8229\n",
            "8230\n",
            "8231\n",
            "8232\n",
            "8233\n",
            "8234\n",
            "8235\n",
            "8236\n",
            "8237\n",
            "8238\n",
            "8239\n",
            "8240\n",
            "8241\n",
            "8242\n",
            "8243\n",
            "8244\n",
            "8245\n",
            "8246\n",
            "8247\n",
            "8248\n",
            "8249\n",
            "8250\n",
            "8251\n",
            "8252\n",
            "8253\n",
            "8254\n",
            "8255\n",
            "8256\n",
            "8257\n",
            "8258\n",
            "8259\n",
            "8260\n",
            "8261\n",
            "8262\n",
            "8263\n",
            "8264\n",
            "8265\n",
            "8266\n",
            "8267\n",
            "8268\n",
            "8269\n",
            "8270\n",
            "8271\n",
            "8272\n",
            "8273\n",
            "8274\n",
            "8275\n",
            "8276\n",
            "8277\n",
            "8278\n",
            "8279\n",
            "8280\n",
            "8281\n",
            "8282\n",
            "8283\n",
            "8284\n",
            "8285\n",
            "8286\n",
            "8287\n",
            "8288\n",
            "8289\n",
            "8290\n",
            "8291\n",
            "8292\n",
            "8293\n",
            "8294\n",
            "8295\n",
            "8296\n",
            "8297\n",
            "8298\n",
            "8299\n",
            "8300\n",
            "8301\n",
            "8302\n",
            "8303\n",
            "8304\n",
            "8305\n",
            "8306\n",
            "8307\n",
            "8308\n",
            "8309\n",
            "8310\n",
            "8311\n",
            "8312\n",
            "8313\n",
            "8314\n",
            "8315\n",
            "8316\n",
            "8317\n",
            "8318\n",
            "8319\n",
            "8320\n",
            "8321\n",
            "8322\n",
            "8323\n",
            "8324\n",
            "8325\n",
            "8326\n",
            "8327\n",
            "8328\n",
            "8329\n",
            "8330\n",
            "8331\n",
            "8332\n",
            "8333\n",
            "8334\n",
            "8335\n",
            "8336\n",
            "8337\n",
            "8338\n",
            "8339\n",
            "8340\n",
            "8341\n",
            "8342\n",
            "8343\n",
            "8344\n",
            "8345\n",
            "8346\n",
            "8347\n",
            "8348\n",
            "8349\n",
            "8350\n",
            "8351\n",
            "8352\n",
            "8353\n",
            "8354\n",
            "8355\n",
            "8356\n",
            "8357\n",
            "8358\n",
            "8359\n",
            "8360\n",
            "8361\n",
            "8362\n",
            "8363\n",
            "8364\n",
            "8365\n",
            "8366\n",
            "8367\n",
            "8368\n",
            "8369\n",
            "8370\n",
            "8371\n",
            "8372\n",
            "8373\n",
            "8374\n",
            "8375\n",
            "8376\n",
            "8377\n",
            "8378\n",
            "8379\n",
            "8380\n",
            "8381\n",
            "8382\n",
            "8383\n",
            "8384\n",
            "8385\n",
            "8386\n",
            "8387\n",
            "8388\n",
            "8389\n",
            "8390\n",
            "8391\n",
            "8392\n",
            "8393\n",
            "8394\n",
            "8395\n",
            "8396\n",
            "8397\n",
            "8398\n",
            "8399\n",
            "8400\n",
            "8401\n",
            "8402\n",
            "8403\n",
            "8404\n",
            "8405\n",
            "8406\n",
            "8407\n",
            "8408\n",
            "8409\n",
            "8410\n",
            "8411\n",
            "8412\n",
            "8413\n",
            "8414\n",
            "8415\n",
            "8416\n",
            "8417\n",
            "8418\n",
            "8419\n",
            "8420\n",
            "8421\n",
            "8422\n",
            "8423\n",
            "8424\n",
            "8425\n",
            "8426\n",
            "8427\n",
            "8428\n",
            "8429\n",
            "8430\n",
            "8431\n",
            "8432\n",
            "8433\n",
            "8434\n",
            "8435\n",
            "8436\n",
            "8437\n",
            "8438\n",
            "8439\n",
            "8440\n",
            "8441\n",
            "8442\n",
            "8443\n",
            "8444\n",
            "8445\n",
            "8446\n",
            "8447\n",
            "8448\n",
            "8449\n",
            "8450\n",
            "8451\n",
            "8452\n",
            "8453\n",
            "8454\n",
            "8455\n",
            "8456\n",
            "8457\n",
            "8458\n",
            "8459\n",
            "8460\n",
            "8461\n",
            "8462\n",
            "8463\n",
            "8464\n",
            "8465\n",
            "8466\n",
            "8467\n",
            "8468\n",
            "8469\n",
            "8470\n",
            "8471\n",
            "8472\n",
            "8473\n",
            "8474\n",
            "8475\n",
            "8476\n",
            "8477\n",
            "8478\n",
            "8479\n",
            "8480\n",
            "8481\n",
            "8482\n",
            "8483\n",
            "8484\n",
            "8485\n",
            "8486\n",
            "8487\n",
            "8488\n",
            "8489\n",
            "8490\n",
            "8491\n",
            "8492\n",
            "8493\n",
            "8494\n",
            "8495\n",
            "8496\n",
            "8497\n",
            "8498\n",
            "8499\n",
            "8500\n",
            "8501\n",
            "8502\n",
            "8503\n",
            "8504\n",
            "8505\n",
            "8506\n",
            "8507\n",
            "8508\n",
            "8509\n",
            "8510\n",
            "8511\n",
            "8512\n",
            "8513\n",
            "8514\n",
            "8515\n",
            "8516\n",
            "8517\n",
            "8518\n",
            "8519\n",
            "8520\n",
            "8521\n",
            "8522\n",
            "8523\n",
            "8524\n",
            "8525\n",
            "8526\n",
            "8527\n",
            "8528\n",
            "8529\n",
            "8530\n",
            "8531\n",
            "8532\n",
            "8533\n",
            "8534\n",
            "8535\n",
            "8536\n",
            "8537\n",
            "8538\n",
            "8539\n",
            "8540\n",
            "8541\n",
            "8542\n",
            "8543\n",
            "8544\n",
            "8545\n",
            "8546\n",
            "8547\n",
            "8548\n",
            "8549\n",
            "8550\n",
            "8551\n",
            "8552\n",
            "8553\n",
            "8554\n",
            "8555\n",
            "8556\n",
            "8557\n",
            "8558\n",
            "8559\n",
            "8560\n",
            "8561\n",
            "8562\n",
            "8563\n",
            "8564\n",
            "8565\n",
            "8566\n",
            "8567\n",
            "8568\n",
            "8569\n",
            "8570\n",
            "8571\n",
            "8572\n",
            "8573\n",
            "8574\n",
            "8575\n",
            "8576\n",
            "8577\n",
            "8578\n",
            "8579\n",
            "8580\n",
            "8581\n",
            "8582\n",
            "8583\n",
            "8584\n",
            "8585\n",
            "8586\n",
            "8587\n",
            "8588\n",
            "8589\n",
            "8590\n",
            "8591\n",
            "8592\n",
            "8593\n",
            "8594\n",
            "8595\n",
            "8596\n",
            "8597\n",
            "8598\n",
            "8599\n",
            "8600\n",
            "8601\n",
            "8602\n",
            "8603\n",
            "8604\n",
            "8605\n",
            "8606\n",
            "8607\n",
            "8608\n",
            "8609\n",
            "8610\n",
            "8611\n",
            "8612\n",
            "8613\n",
            "8614\n",
            "8615\n",
            "8616\n",
            "8617\n",
            "8618\n",
            "8619\n",
            "8620\n",
            "8621\n",
            "8622\n",
            "8623\n",
            "8624\n",
            "8625\n",
            "8626\n",
            "8627\n",
            "8628\n",
            "8629\n",
            "8630\n",
            "8631\n",
            "8632\n",
            "8633\n",
            "8634\n",
            "8635\n",
            "8636\n",
            "8637\n",
            "8638\n",
            "8639\n",
            "8640\n",
            "8641\n",
            "8642\n",
            "8643\n",
            "8644\n",
            "8645\n",
            "8646\n",
            "8647\n",
            "8648\n",
            "8649\n",
            "8650\n",
            "8651\n",
            "8652\n",
            "8653\n",
            "8654\n",
            "8655\n",
            "8656\n",
            "8657\n",
            "8658\n",
            "8659\n",
            "8660\n",
            "8661\n",
            "8662\n",
            "8663\n",
            "8664\n",
            "8665\n",
            "8666\n",
            "8667\n",
            "8668\n",
            "8669\n",
            "8670\n",
            "8671\n",
            "8672\n",
            "8673\n",
            "8674\n",
            "8675\n",
            "8676\n",
            "8677\n",
            "8678\n",
            "8679\n",
            "8680\n",
            "8681\n",
            "8682\n",
            "8683\n",
            "8684\n",
            "8685\n",
            "8686\n",
            "8687\n",
            "8688\n",
            "8689\n",
            "8690\n",
            "8691\n",
            "8692\n",
            "8693\n",
            "8694\n",
            "8695\n",
            "8696\n",
            "8697\n",
            "8698\n",
            "8699\n",
            "8700\n",
            "8701\n",
            "8702\n",
            "8703\n",
            "8704\n",
            "8705\n",
            "8706\n",
            "8707\n",
            "8708\n",
            "8709\n",
            "8710\n",
            "8711\n",
            "8712\n",
            "8713\n",
            "8714\n",
            "8715\n",
            "8716\n",
            "8717\n",
            "8718\n",
            "8719\n",
            "8720\n",
            "8721\n",
            "8722\n",
            "8723\n",
            "8724\n",
            "8725\n",
            "8726\n",
            "8727\n",
            "8728\n",
            "8729\n",
            "8730\n",
            "8731\n",
            "8732\n",
            "8733\n",
            "8734\n",
            "8735\n",
            "8736\n",
            "8737\n",
            "8738\n",
            "8739\n",
            "8740\n",
            "8741\n",
            "8742\n",
            "8743\n",
            "8744\n",
            "8745\n",
            "8746\n",
            "8747\n",
            "8748\n",
            "8749\n",
            "8750\n",
            "8751\n",
            "8752\n",
            "8753\n",
            "8754\n",
            "8755\n",
            "8756\n",
            "8757\n",
            "8758\n",
            "8759\n",
            "8760\n",
            "8761\n",
            "8762\n",
            "8763\n",
            "8764\n",
            "8765\n",
            "8766\n",
            "8767\n",
            "8768\n",
            "8769\n",
            "8770\n",
            "8771\n",
            "8772\n",
            "8773\n",
            "8774\n",
            "8775\n",
            "8776\n",
            "8777\n",
            "8778\n",
            "8779\n",
            "8780\n",
            "8781\n",
            "8782\n",
            "8783\n",
            "8784\n",
            "8785\n",
            "8786\n",
            "8787\n",
            "8788\n",
            "8789\n",
            "8790\n",
            "8791\n",
            "8792\n",
            "8793\n",
            "8794\n",
            "8795\n",
            "8796\n",
            "8797\n",
            "8798\n",
            "8799\n",
            "8800\n",
            "8801\n",
            "8802\n",
            "8803\n",
            "8804\n",
            "8805\n",
            "8806\n",
            "8807\n",
            "8808\n",
            "8809\n",
            "8810\n",
            "8811\n",
            "8812\n",
            "8813\n",
            "8814\n",
            "8815\n",
            "8816\n",
            "8817\n",
            "8818\n",
            "8819\n",
            "8820\n",
            "8821\n",
            "8822\n",
            "8823\n",
            "8824\n",
            "8825\n",
            "8826\n",
            "8827\n",
            "8828\n",
            "8829\n",
            "8830\n",
            "8831\n",
            "8832\n",
            "8833\n",
            "8834\n",
            "8835\n",
            "8836\n",
            "8837\n",
            "8838\n",
            "8839\n",
            "8840\n",
            "8841\n",
            "8842\n",
            "8843\n",
            "8844\n",
            "8845\n",
            "8846\n",
            "8847\n",
            "8848\n",
            "8849\n",
            "8850\n",
            "8851\n",
            "8852\n",
            "8853\n",
            "8854\n",
            "8855\n",
            "8856\n",
            "8857\n",
            "8858\n",
            "8859\n",
            "8860\n",
            "8861\n",
            "8862\n",
            "8863\n",
            "8864\n",
            "8865\n",
            "8866\n",
            "8867\n",
            "8868\n",
            "8869\n",
            "8870\n",
            "8871\n",
            "8872\n",
            "8873\n",
            "8874\n",
            "8875\n",
            "8876\n",
            "8877\n",
            "8878\n",
            "8879\n",
            "8880\n",
            "8881\n",
            "8882\n",
            "8883\n",
            "8884\n",
            "8885\n",
            "8886\n",
            "8887\n",
            "8888\n",
            "8889\n",
            "8890\n",
            "8891\n",
            "8892\n",
            "8893\n",
            "8894\n",
            "8895\n",
            "8896\n",
            "8897\n",
            "8898\n",
            "8899\n",
            "8900\n",
            "8901\n",
            "8902\n",
            "8903\n",
            "8904\n",
            "8905\n",
            "8906\n",
            "8907\n",
            "8908\n",
            "8909\n",
            "8910\n",
            "8911\n",
            "8912\n",
            "8913\n",
            "8914\n",
            "8915\n",
            "8916\n",
            "8917\n",
            "8918\n",
            "8919\n",
            "8920\n",
            "8921\n",
            "8922\n",
            "8923\n",
            "8924\n",
            "8925\n",
            "8926\n",
            "8927\n",
            "8928\n",
            "8929\n",
            "8930\n",
            "8931\n",
            "8932\n",
            "8933\n",
            "8934\n",
            "8935\n",
            "8936\n",
            "8937\n",
            "8938\n",
            "8939\n",
            "8940\n",
            "8941\n",
            "8942\n",
            "8943\n",
            "8944\n",
            "8945\n",
            "8946\n",
            "8947\n",
            "8948\n",
            "8949\n",
            "8950\n",
            "8951\n",
            "8952\n",
            "8953\n",
            "8954\n",
            "8955\n",
            "8956\n",
            "8957\n",
            "8958\n",
            "8959\n",
            "8960\n",
            "8961\n",
            "8962\n",
            "8963\n",
            "8964\n",
            "8965\n",
            "8966\n",
            "8967\n",
            "8968\n",
            "8969\n",
            "8970\n",
            "8971\n",
            "8972\n",
            "8973\n",
            "8974\n",
            "8975\n",
            "8976\n",
            "8977\n",
            "8978\n",
            "8979\n",
            "8980\n",
            "8981\n",
            "8982\n",
            "8983\n",
            "8984\n",
            "8985\n",
            "8986\n",
            "8987\n",
            "8988\n",
            "8989\n",
            "8990\n",
            "8991\n",
            "8992\n",
            "8993\n",
            "8994\n",
            "8995\n",
            "8996\n",
            "8997\n",
            "8998\n",
            "8999\n",
            "9000\n",
            "9001\n",
            "9002\n",
            "9003\n",
            "9004\n",
            "9005\n",
            "9006\n",
            "9007\n",
            "9008\n",
            "9009\n",
            "9010\n",
            "9011\n",
            "9012\n",
            "9013\n",
            "9014\n",
            "9015\n",
            "9016\n",
            "9017\n",
            "9018\n",
            "9019\n",
            "9020\n",
            "9021\n",
            "9022\n",
            "9023\n",
            "9024\n",
            "9025\n",
            "9026\n",
            "9027\n",
            "9028\n",
            "9029\n",
            "9030\n",
            "9031\n",
            "9032\n",
            "9033\n",
            "9034\n",
            "9035\n",
            "9036\n",
            "9037\n",
            "9038\n",
            "9039\n",
            "9040\n",
            "9041\n",
            "9042\n",
            "9043\n",
            "9044\n",
            "9045\n",
            "9046\n",
            "9047\n",
            "9048\n",
            "9049\n",
            "9050\n",
            "9051\n",
            "9052\n",
            "9053\n",
            "9054\n",
            "9055\n",
            "9056\n",
            "9057\n",
            "9058\n",
            "9059\n",
            "9060\n",
            "9061\n",
            "9062\n",
            "9063\n",
            "9064\n",
            "9065\n",
            "9066\n",
            "9067\n",
            "9068\n",
            "9069\n",
            "9070\n",
            "9071\n",
            "9072\n",
            "9073\n",
            "9074\n",
            "9075\n",
            "9076\n",
            "9077\n",
            "9078\n",
            "9079\n",
            "9080\n",
            "9081\n",
            "9082\n",
            "9083\n",
            "9084\n",
            "9085\n",
            "9086\n",
            "9087\n",
            "9088\n",
            "9089\n",
            "9090\n",
            "9091\n",
            "9092\n",
            "9093\n",
            "9094\n",
            "9095\n",
            "9096\n",
            "9097\n",
            "9098\n",
            "9099\n",
            "9100\n",
            "9101\n",
            "9102\n",
            "9103\n",
            "9104\n",
            "9105\n",
            "9106\n",
            "9107\n",
            "9108\n",
            "9109\n",
            "9110\n",
            "9111\n",
            "9112\n",
            "9113\n",
            "9114\n",
            "9115\n",
            "9116\n",
            "9117\n",
            "9118\n",
            "9119\n",
            "9120\n",
            "9121\n",
            "9122\n",
            "9123\n",
            "9124\n",
            "9125\n",
            "9126\n",
            "9127\n",
            "9128\n",
            "9129\n",
            "9130\n",
            "9131\n",
            "9132\n",
            "9133\n",
            "9134\n",
            "9135\n",
            "9136\n",
            "9137\n",
            "9138\n",
            "9139\n",
            "9140\n",
            "9141\n",
            "9142\n",
            "9143\n",
            "9144\n",
            "9145\n",
            "9146\n",
            "9147\n",
            "9148\n",
            "9149\n",
            "9150\n",
            "9151\n",
            "9152\n",
            "9153\n",
            "9154\n",
            "9155\n",
            "9156\n",
            "9157\n",
            "9158\n",
            "9159\n",
            "9160\n",
            "9161\n",
            "9162\n",
            "9163\n",
            "9164\n",
            "9165\n",
            "9166\n",
            "9167\n",
            "9168\n",
            "9169\n",
            "9170\n",
            "9171\n",
            "9172\n",
            "9173\n",
            "9174\n",
            "9175\n",
            "9176\n",
            "9177\n",
            "9178\n",
            "9179\n",
            "9180\n",
            "9181\n",
            "9182\n",
            "9183\n",
            "9184\n",
            "9185\n",
            "9186\n",
            "9187\n",
            "9188\n",
            "9189\n",
            "9190\n",
            "9191\n",
            "9192\n",
            "9193\n",
            "9194\n",
            "9195\n",
            "9196\n",
            "9197\n",
            "9198\n",
            "9199\n",
            "9200\n",
            "9201\n",
            "9202\n",
            "9203\n",
            "9204\n",
            "9205\n",
            "9206\n",
            "9207\n",
            "9208\n",
            "9209\n",
            "9210\n",
            "9211\n",
            "9212\n",
            "9213\n",
            "9214\n",
            "9215\n",
            "9216\n",
            "9217\n",
            "9218\n",
            "9219\n",
            "9220\n",
            "9221\n",
            "9222\n",
            "9223\n",
            "9224\n",
            "9225\n",
            "9226\n",
            "9227\n",
            "9228\n",
            "9229\n",
            "9230\n",
            "9231\n",
            "9232\n",
            "9233\n",
            "9234\n",
            "9235\n",
            "9236\n",
            "9237\n",
            "9238\n",
            "9239\n",
            "9240\n",
            "9241\n",
            "9242\n",
            "9243\n",
            "9244\n",
            "9245\n",
            "9246\n",
            "9247\n",
            "9248\n",
            "9249\n",
            "9250\n",
            "9251\n",
            "9252\n",
            "9253\n",
            "9254\n",
            "9255\n",
            "9256\n",
            "9257\n",
            "9258\n",
            "9259\n",
            "9260\n",
            "9261\n",
            "9262\n",
            "9263\n",
            "9264\n",
            "9265\n",
            "9266\n",
            "9267\n",
            "9268\n",
            "9269\n",
            "9270\n",
            "9271\n",
            "9272\n",
            "9273\n",
            "9274\n",
            "9275\n",
            "9276\n",
            "9277\n",
            "9278\n",
            "9279\n",
            "9280\n",
            "9281\n",
            "9282\n",
            "9283\n",
            "9284\n",
            "9285\n",
            "9286\n",
            "9287\n",
            "9288\n",
            "9289\n",
            "9290\n",
            "9291\n",
            "9292\n",
            "9293\n",
            "9294\n",
            "9295\n",
            "9296\n",
            "9297\n",
            "9298\n",
            "9299\n",
            "9300\n",
            "9301\n",
            "9302\n",
            "9303\n",
            "9304\n",
            "9305\n",
            "9306\n",
            "9307\n",
            "9308\n",
            "9309\n",
            "9310\n",
            "9311\n",
            "9312\n",
            "9313\n",
            "9314\n",
            "9315\n",
            "9316\n",
            "9317\n",
            "9318\n",
            "9319\n",
            "9320\n",
            "9321\n",
            "9322\n",
            "9323\n",
            "9324\n",
            "9325\n",
            "9326\n",
            "9327\n",
            "9328\n",
            "9329\n",
            "9330\n",
            "9331\n",
            "9332\n",
            "9333\n",
            "9334\n",
            "9335\n",
            "9336\n",
            "9337\n",
            "9338\n",
            "9339\n",
            "9340\n",
            "9341\n",
            "9342\n",
            "9343\n",
            "9344\n",
            "9345\n",
            "9346\n",
            "9347\n",
            "9348\n",
            "9349\n",
            "9350\n",
            "9351\n",
            "9352\n",
            "9353\n",
            "9354\n",
            "9355\n",
            "9356\n",
            "9357\n",
            "9358\n",
            "9359\n",
            "9360\n",
            "9361\n",
            "9362\n",
            "9363\n",
            "9364\n",
            "9365\n",
            "9366\n",
            "9367\n",
            "9368\n",
            "9369\n",
            "9370\n",
            "9371\n",
            "9372\n",
            "9373\n",
            "9374\n",
            "9375\n",
            "9376\n",
            "9377\n",
            "9378\n",
            "9379\n",
            "9380\n",
            "9381\n",
            "9382\n",
            "9383\n",
            "9384\n",
            "9385\n",
            "9386\n",
            "9387\n",
            "9388\n",
            "9389\n",
            "9390\n",
            "9391\n",
            "9392\n",
            "9393\n",
            "9394\n",
            "9395\n",
            "9396\n",
            "9397\n",
            "9398\n",
            "9399\n",
            "9400\n",
            "9401\n",
            "9402\n",
            "9403\n",
            "9404\n",
            "9405\n",
            "9406\n",
            "9407\n",
            "9408\n",
            "9409\n",
            "9410\n",
            "9411\n",
            "9412\n",
            "9413\n",
            "9414\n",
            "9415\n",
            "9416\n",
            "9417\n",
            "9418\n",
            "9419\n",
            "9420\n",
            "9421\n",
            "9422\n",
            "9423\n",
            "9424\n",
            "9425\n",
            "9426\n",
            "9427\n",
            "9428\n",
            "9429\n",
            "9430\n",
            "9431\n",
            "9432\n",
            "9433\n",
            "9434\n",
            "9435\n",
            "9436\n",
            "9437\n",
            "9438\n",
            "9439\n",
            "9440\n",
            "9441\n",
            "9442\n",
            "9443\n",
            "9444\n",
            "9445\n",
            "9446\n",
            "9447\n",
            "9448\n",
            "9449\n",
            "9450\n",
            "9451\n",
            "9452\n",
            "9453\n",
            "9454\n",
            "9455\n",
            "9456\n",
            "9457\n",
            "9458\n",
            "9459\n",
            "9460\n",
            "9461\n",
            "9462\n",
            "9463\n",
            "9464\n",
            "9465\n",
            "9466\n",
            "9467\n",
            "9468\n",
            "9469\n",
            "9470\n",
            "9471\n",
            "9472\n",
            "9473\n",
            "9474\n",
            "9475\n",
            "9476\n",
            "9477\n",
            "9478\n",
            "9479\n",
            "9480\n",
            "9481\n",
            "9482\n",
            "9483\n",
            "9484\n",
            "9485\n",
            "9486\n",
            "9487\n",
            "9488\n",
            "9489\n",
            "9490\n",
            "9491\n",
            "9492\n",
            "9493\n",
            "9494\n",
            "9495\n",
            "9496\n",
            "9497\n",
            "9498\n",
            "9499\n",
            "9500\n",
            "9501\n",
            "9502\n",
            "9503\n",
            "9504\n",
            "9505\n",
            "9506\n",
            "9507\n",
            "9508\n",
            "9509\n",
            "9510\n",
            "9511\n",
            "9512\n",
            "9513\n",
            "9514\n",
            "9515\n",
            "9516\n",
            "9517\n",
            "9518\n",
            "9519\n",
            "9520\n",
            "9521\n",
            "9522\n",
            "9523\n",
            "9524\n",
            "9525\n",
            "9526\n",
            "9527\n",
            "9528\n",
            "9529\n",
            "9530\n",
            "9531\n",
            "9532\n",
            "9533\n",
            "9534\n",
            "9535\n",
            "9536\n",
            "9537\n",
            "9538\n",
            "9539\n",
            "9540\n",
            "9541\n",
            "9542\n",
            "9543\n",
            "9544\n",
            "9545\n",
            "9546\n",
            "9547\n",
            "9548\n",
            "9549\n",
            "9550\n",
            "9551\n",
            "9552\n",
            "9553\n",
            "9554\n",
            "9555\n",
            "9556\n",
            "9557\n",
            "9558\n",
            "9559\n",
            "9560\n",
            "9561\n",
            "9562\n",
            "9563\n",
            "9564\n",
            "9565\n",
            "9566\n",
            "9567\n",
            "9568\n",
            "9569\n",
            "9570\n",
            "9571\n",
            "9572\n",
            "9573\n",
            "9574\n",
            "9575\n",
            "9576\n",
            "9577\n",
            "9578\n",
            "9579\n",
            "9580\n",
            "9581\n",
            "9582\n",
            "9583\n",
            "9584\n",
            "9585\n",
            "9586\n",
            "9587\n",
            "9588\n",
            "9589\n",
            "9590\n",
            "9591\n",
            "9592\n",
            "9593\n",
            "9594\n",
            "9595\n",
            "9596\n",
            "9597\n",
            "9598\n",
            "9599\n",
            "9600\n",
            "9601\n",
            "9602\n",
            "9603\n",
            "9604\n",
            "9605\n",
            "9606\n",
            "9607\n",
            "9608\n",
            "9609\n",
            "9610\n",
            "9611\n",
            "9612\n",
            "9613\n",
            "9614\n",
            "9615\n",
            "9616\n",
            "9617\n",
            "9618\n",
            "9619\n",
            "9620\n",
            "9621\n",
            "9622\n",
            "9623\n",
            "9624\n",
            "9625\n",
            "9626\n",
            "9627\n",
            "9628\n",
            "9629\n",
            "9630\n",
            "9631\n",
            "9632\n",
            "9633\n",
            "9634\n",
            "9635\n",
            "9636\n",
            "9637\n",
            "9638\n",
            "9639\n",
            "9640\n",
            "9641\n",
            "9642\n",
            "9643\n",
            "9644\n",
            "9645\n",
            "9646\n",
            "9647\n",
            "9648\n",
            "9649\n",
            "9650\n",
            "9651\n",
            "9652\n",
            "9653\n",
            "9654\n",
            "9655\n",
            "9656\n",
            "9657\n",
            "9658\n",
            "9659\n",
            "9660\n",
            "9661\n",
            "9662\n",
            "9663\n",
            "9664\n",
            "9665\n",
            "9666\n",
            "9667\n",
            "9668\n",
            "9669\n",
            "9670\n",
            "9671\n",
            "9672\n",
            "9673\n",
            "9674\n",
            "9675\n",
            "9676\n",
            "9677\n",
            "9678\n",
            "9679\n",
            "9680\n",
            "9681\n",
            "9682\n",
            "9683\n",
            "9684\n",
            "9685\n",
            "9686\n",
            "9687\n",
            "9688\n",
            "9689\n",
            "9690\n",
            "9691\n",
            "9692\n",
            "9693\n",
            "9694\n",
            "9695\n",
            "9696\n",
            "9697\n",
            "9698\n",
            "9699\n",
            "9700\n",
            "9701\n",
            "9702\n",
            "9703\n",
            "9704\n",
            "9705\n",
            "9706\n",
            "9707\n",
            "9708\n",
            "9709\n",
            "9710\n",
            "9711\n",
            "9712\n",
            "9713\n",
            "9714\n",
            "9715\n",
            "9716\n",
            "9717\n",
            "9718\n",
            "9719\n",
            "9720\n",
            "9721\n",
            "9722\n",
            "9723\n",
            "9724\n",
            "9725\n",
            "9726\n",
            "9727\n",
            "9728\n",
            "9729\n",
            "9730\n",
            "9731\n",
            "9732\n",
            "9733\n",
            "9734\n",
            "9735\n",
            "9736\n",
            "9737\n",
            "9738\n",
            "9739\n",
            "9740\n",
            "9741\n",
            "9742\n",
            "9743\n",
            "9744\n",
            "9745\n",
            "9746\n",
            "9747\n",
            "9748\n",
            "9749\n",
            "9750\n",
            "9751\n",
            "9752\n",
            "9753\n",
            "9754\n",
            "9755\n",
            "9756\n",
            "9757\n",
            "9758\n",
            "9759\n",
            "9760\n",
            "9761\n",
            "9762\n",
            "9763\n",
            "9764\n",
            "9765\n",
            "9766\n",
            "9767\n",
            "9768\n",
            "9769\n",
            "9770\n",
            "9771\n",
            "9772\n",
            "9773\n",
            "9774\n",
            "9775\n",
            "9776\n",
            "9777\n",
            "9778\n",
            "9779\n",
            "9780\n",
            "9781\n",
            "9782\n",
            "9783\n",
            "9784\n",
            "9785\n",
            "9786\n",
            "9787\n",
            "9788\n",
            "9789\n",
            "9790\n",
            "9791\n",
            "9792\n",
            "9793\n",
            "9794\n",
            "9795\n",
            "9796\n",
            "9797\n",
            "9798\n",
            "9799\n",
            "9800\n",
            "9801\n",
            "9802\n",
            "9803\n",
            "9804\n",
            "9805\n",
            "9806\n",
            "9807\n",
            "9808\n",
            "9809\n",
            "9810\n",
            "9811\n",
            "9812\n",
            "9813\n",
            "9814\n",
            "9815\n",
            "9816\n",
            "9817\n",
            "9818\n",
            "9819\n",
            "9820\n",
            "9821\n",
            "9822\n",
            "9823\n",
            "9824\n",
            "9825\n",
            "9826\n",
            "9827\n",
            "9828\n",
            "9829\n",
            "9830\n",
            "9831\n",
            "9832\n",
            "9833\n",
            "9834\n",
            "9835\n",
            "9836\n",
            "9837\n",
            "9838\n",
            "9839\n",
            "9840\n",
            "9841\n",
            "9842\n",
            "9843\n",
            "9844\n",
            "9845\n",
            "9846\n",
            "9847\n",
            "9848\n",
            "9849\n",
            "9850\n",
            "9851\n",
            "9852\n",
            "9853\n",
            "9854\n",
            "9855\n",
            "9856\n",
            "9857\n",
            "9858\n",
            "9859\n",
            "9860\n",
            "9861\n",
            "9862\n",
            "9863\n",
            "9864\n",
            "9865\n",
            "9866\n",
            "9867\n",
            "9868\n",
            "9869\n",
            "9870\n",
            "9871\n",
            "9872\n",
            "9873\n",
            "9874\n",
            "9875\n",
            "9876\n",
            "9877\n",
            "9878\n",
            "9879\n",
            "9880\n",
            "9881\n",
            "9882\n",
            "9883\n",
            "9884\n",
            "9885\n",
            "9886\n",
            "9887\n",
            "9888\n",
            "9889\n",
            "9890\n",
            "9891\n",
            "9892\n",
            "9893\n",
            "9894\n",
            "9895\n",
            "9896\n",
            "9897\n",
            "9898\n",
            "9899\n",
            "9900\n",
            "9901\n",
            "9902\n",
            "9903\n",
            "9904\n",
            "9905\n",
            "9906\n",
            "9907\n",
            "9908\n",
            "9909\n",
            "9910\n",
            "9911\n",
            "9912\n",
            "9913\n",
            "9914\n",
            "9915\n",
            "9916\n",
            "9917\n",
            "9918\n",
            "9919\n",
            "9920\n",
            "9921\n",
            "9922\n",
            "9923\n",
            "9924\n",
            "9925\n",
            "9926\n",
            "9927\n",
            "9928\n",
            "9929\n",
            "9930\n",
            "9931\n",
            "9932\n",
            "9933\n",
            "9934\n",
            "9935\n",
            "9936\n",
            "9937\n",
            "9938\n",
            "9939\n",
            "9940\n",
            "9941\n",
            "9942\n",
            "9943\n",
            "9944\n",
            "9945\n",
            "9946\n",
            "9947\n",
            "9948\n",
            "9949\n",
            "9950\n",
            "9951\n",
            "9952\n",
            "9953\n",
            "9954\n",
            "9955\n",
            "9956\n",
            "9957\n",
            "9958\n",
            "9959\n",
            "9960\n",
            "9961\n",
            "9962\n",
            "9963\n",
            "9964\n",
            "9965\n",
            "9966\n",
            "9967\n",
            "9968\n",
            "9969\n",
            "9970\n",
            "9971\n",
            "9972\n",
            "9973\n",
            "9974\n",
            "9975\n",
            "9976\n",
            "9977\n",
            "9978\n",
            "9979\n",
            "9980\n",
            "9981\n",
            "9982\n",
            "9983\n",
            "9984\n",
            "9985\n",
            "9986\n",
            "9987\n",
            "9988\n",
            "9989\n",
            "9990\n",
            "9991\n",
            "9992\n",
            "9993\n",
            "9994\n",
            "9995\n",
            "9996\n",
            "9997\n",
            "9998\n",
            "9999\n",
            "10000\n",
            "10001\n",
            "10002\n",
            "10003\n",
            "10004\n",
            "10005\n",
            "10006\n",
            "10007\n",
            "10008\n",
            "10009\n",
            "10010\n",
            "10011\n",
            "10012\n",
            "10013\n",
            "10014\n",
            "10015\n",
            "10016\n",
            "10017\n",
            "10018\n",
            "10019\n",
            "10020\n",
            "10021\n",
            "10022\n",
            "10023\n",
            "10024\n",
            "10025\n",
            "10026\n",
            "10027\n",
            "10028\n",
            "10029\n",
            "10030\n",
            "10031\n",
            "10032\n",
            "10033\n",
            "10034\n",
            "10035\n",
            "10036\n",
            "10037\n",
            "10038\n",
            "10039\n",
            "10040\n",
            "10041\n",
            "10042\n",
            "10043\n",
            "10044\n",
            "10045\n",
            "10046\n",
            "10047\n",
            "10048\n",
            "10049\n",
            "10050\n",
            "10051\n",
            "10052\n",
            "10053\n",
            "10054\n",
            "10055\n",
            "10056\n",
            "10057\n",
            "10058\n",
            "10059\n",
            "10060\n",
            "10061\n",
            "10062\n",
            "10063\n",
            "10064\n",
            "10065\n",
            "10066\n",
            "10067\n",
            "10068\n",
            "10069\n",
            "10070\n",
            "10071\n",
            "10072\n",
            "10073\n",
            "10074\n",
            "10075\n",
            "10076\n",
            "10077\n",
            "10078\n",
            "10079\n",
            "10080\n",
            "10081\n",
            "10082\n",
            "10083\n",
            "10084\n",
            "10085\n",
            "10086\n",
            "10087\n",
            "10088\n",
            "10089\n",
            "10090\n",
            "10091\n",
            "10092\n",
            "10093\n",
            "10094\n",
            "10095\n",
            "10096\n",
            "10097\n",
            "10098\n",
            "10099\n",
            "10100\n",
            "10101\n",
            "10102\n",
            "10103\n",
            "10104\n",
            "10105\n",
            "10106\n",
            "10107\n",
            "10108\n",
            "10109\n",
            "10110\n",
            "10111\n",
            "10112\n",
            "10113\n",
            "10114\n",
            "10115\n",
            "10116\n",
            "10117\n",
            "10118\n",
            "10119\n",
            "10120\n",
            "10121\n",
            "10122\n",
            "10123\n",
            "10124\n",
            "10125\n",
            "10126\n",
            "10127\n",
            "10128\n",
            "10129\n",
            "10130\n",
            "10131\n",
            "10132\n",
            "10133\n",
            "10134\n",
            "10135\n",
            "10136\n",
            "10137\n",
            "10138\n",
            "10139\n",
            "10140\n",
            "10141\n",
            "10142\n",
            "10143\n",
            "10144\n",
            "10145\n",
            "10146\n",
            "10147\n",
            "10148\n",
            "10149\n",
            "10150\n",
            "10151\n",
            "10152\n",
            "10153\n",
            "10154\n",
            "10155\n",
            "10156\n",
            "10157\n",
            "10158\n",
            "10159\n",
            "10160\n",
            "10161\n",
            "10162\n",
            "10163\n",
            "10164\n",
            "10165\n",
            "10166\n",
            "10167\n",
            "10168\n",
            "10169\n",
            "10170\n",
            "10171\n",
            "10172\n",
            "10173\n",
            "10174\n",
            "10175\n",
            "10176\n",
            "10177\n",
            "10178\n",
            "10179\n",
            "10180\n",
            "10181\n",
            "10182\n",
            "10183\n",
            "10184\n",
            "10185\n",
            "10186\n",
            "10187\n",
            "10188\n",
            "10189\n",
            "10190\n",
            "10191\n",
            "10192\n",
            "10193\n",
            "10194\n",
            "10195\n",
            "10196\n",
            "10197\n",
            "10198\n",
            "10199\n",
            "10200\n",
            "10201\n",
            "10202\n",
            "10203\n",
            "10204\n",
            "10205\n",
            "10206\n",
            "10207\n",
            "10208\n",
            "10209\n",
            "10210\n",
            "10211\n",
            "10212\n",
            "10213\n",
            "10214\n",
            "10215\n",
            "10216\n",
            "10217\n",
            "10218\n",
            "10219\n",
            "10220\n",
            "10221\n",
            "10222\n",
            "10223\n",
            "10224\n",
            "10225\n",
            "10226\n",
            "10227\n",
            "10228\n",
            "10229\n",
            "10230\n",
            "10231\n",
            "10232\n",
            "10233\n",
            "10234\n",
            "10235\n",
            "10236\n",
            "10237\n",
            "10238\n",
            "10239\n",
            "10240\n",
            "10241\n",
            "10242\n",
            "10243\n",
            "10244\n",
            "10245\n",
            "10246\n",
            "10247\n",
            "10248\n",
            "10249\n",
            "10250\n",
            "10251\n",
            "10252\n",
            "10253\n",
            "10254\n",
            "10255\n",
            "10256\n",
            "10257\n",
            "10258\n",
            "10259\n",
            "10260\n",
            "10261\n",
            "10262\n",
            "10263\n",
            "10264\n",
            "10265\n",
            "10266\n",
            "10267\n",
            "10268\n",
            "10269\n",
            "10270\n",
            "10271\n",
            "10272\n",
            "10273\n",
            "10274\n",
            "10275\n",
            "10276\n",
            "10277\n",
            "10278\n",
            "10279\n",
            "10280\n",
            "10281\n",
            "10282\n",
            "10283\n",
            "10284\n",
            "10285\n",
            "10286\n",
            "10287\n",
            "10288\n",
            "10289\n",
            "10290\n",
            "10291\n",
            "10292\n",
            "10293\n",
            "10294\n",
            "10295\n",
            "10296\n",
            "10297\n",
            "10298\n",
            "10299\n",
            "10300\n",
            "10301\n",
            "10302\n",
            "10303\n",
            "10304\n",
            "10305\n",
            "10306\n",
            "10307\n",
            "10308\n",
            "10309\n",
            "10310\n",
            "10311\n",
            "10312\n",
            "10313\n",
            "10314\n",
            "10315\n",
            "10316\n",
            "10317\n",
            "10318\n",
            "10319\n",
            "10320\n",
            "10321\n",
            "10322\n",
            "10323\n",
            "10324\n",
            "10325\n",
            "10326\n",
            "10327\n",
            "10328\n",
            "10329\n",
            "10330\n",
            "10331\n",
            "10332\n",
            "10333\n",
            "10334\n",
            "10335\n",
            "10336\n",
            "10337\n",
            "10338\n",
            "10339\n",
            "10340\n",
            "10341\n",
            "10342\n",
            "10343\n",
            "10344\n",
            "10345\n",
            "10346\n",
            "10347\n",
            "10348\n",
            "10349\n",
            "10350\n",
            "10351\n",
            "10352\n",
            "10353\n",
            "10354\n",
            "10355\n",
            "10356\n",
            "10357\n",
            "10358\n",
            "10359\n",
            "10360\n",
            "10361\n",
            "10362\n",
            "10363\n",
            "10364\n",
            "10365\n",
            "10366\n",
            "10367\n",
            "10368\n",
            "10369\n",
            "10370\n",
            "10371\n",
            "10372\n",
            "10373\n",
            "10374\n",
            "10375\n",
            "10376\n",
            "10377\n",
            "10378\n",
            "10379\n",
            "10380\n",
            "10381\n",
            "10382\n",
            "10383\n",
            "10384\n",
            "10385\n",
            "10386\n",
            "10387\n",
            "10388\n",
            "10389\n",
            "10390\n",
            "10391\n",
            "10392\n",
            "10393\n",
            "10394\n",
            "10395\n",
            "10396\n",
            "10397\n",
            "10398\n",
            "10399\n",
            "10400\n",
            "10401\n",
            "10402\n",
            "10403\n",
            "10404\n",
            "10405\n",
            "10406\n",
            "10407\n",
            "10408\n",
            "10409\n",
            "10410\n",
            "10411\n",
            "10412\n",
            "10413\n",
            "10414\n",
            "10415\n",
            "10416\n",
            "10417\n",
            "10418\n",
            "10419\n",
            "10420\n",
            "10421\n",
            "10422\n",
            "10423\n",
            "10424\n",
            "10425\n",
            "10426\n",
            "10427\n",
            "10428\n",
            "10429\n",
            "10430\n",
            "10431\n",
            "10432\n",
            "10433\n",
            "10434\n",
            "10435\n",
            "10436\n",
            "10437\n",
            "10438\n",
            "10439\n",
            "10440\n",
            "10441\n",
            "10442\n",
            "10443\n",
            "10444\n",
            "10445\n",
            "10446\n",
            "10447\n",
            "10448\n",
            "10449\n",
            "10450\n",
            "10451\n",
            "10452\n",
            "10453\n",
            "10454\n",
            "10455\n",
            "10456\n",
            "10457\n",
            "10458\n",
            "10459\n",
            "10460\n",
            "10461\n",
            "10462\n",
            "10463\n",
            "10464\n",
            "10465\n",
            "10466\n",
            "10467\n",
            "10468\n",
            "10469\n",
            "10470\n",
            "10471\n",
            "10472\n",
            "10473\n",
            "10474\n",
            "10475\n",
            "10476\n",
            "10477\n",
            "10478\n",
            "10479\n",
            "10480\n",
            "10481\n",
            "10482\n",
            "10483\n",
            "10484\n",
            "10485\n",
            "10486\n",
            "10487\n",
            "10488\n",
            "10489\n",
            "10490\n",
            "10491\n",
            "10492\n",
            "10493\n",
            "10494\n",
            "10495\n",
            "10496\n",
            "10497\n",
            "10498\n",
            "10499\n",
            "10500\n",
            "10501\n",
            "10502\n",
            "10503\n",
            "10504\n",
            "10505\n",
            "10506\n",
            "10507\n",
            "10508\n",
            "10509\n",
            "10510\n",
            "10511\n",
            "10512\n",
            "10513\n",
            "10514\n",
            "10515\n",
            "10516\n",
            "10517\n",
            "10518\n",
            "10519\n",
            "10520\n",
            "10521\n",
            "10522\n",
            "10523\n",
            "10524\n",
            "10525\n",
            "10526\n",
            "10527\n",
            "10528\n",
            "10529\n",
            "10530\n",
            "10531\n",
            "10532\n",
            "10533\n",
            "10534\n",
            "10535\n",
            "10536\n",
            "10537\n",
            "10538\n",
            "10539\n",
            "10540\n",
            "10541\n",
            "10542\n",
            "10543\n",
            "10544\n",
            "10545\n",
            "10546\n",
            "10547\n",
            "10548\n",
            "10549\n",
            "10550\n",
            "10551\n",
            "10552\n",
            "10553\n",
            "10554\n",
            "10555\n",
            "10556\n",
            "10557\n",
            "10558\n",
            "10559\n",
            "10560\n",
            "10561\n",
            "10562\n",
            "10563\n",
            "10564\n",
            "10565\n",
            "10566\n",
            "10567\n",
            "10568\n",
            "10569\n",
            "10570\n",
            "10571\n",
            "10572\n",
            "10573\n",
            "10574\n",
            "10575\n",
            "10576\n",
            "10577\n",
            "10578\n",
            "10579\n",
            "10580\n",
            "10581\n",
            "10582\n",
            "10583\n",
            "10584\n",
            "10585\n",
            "10586\n",
            "10587\n",
            "10588\n",
            "10589\n",
            "10590\n",
            "10591\n",
            "10592\n",
            "10593\n",
            "10594\n",
            "10595\n",
            "10596\n",
            "10597\n",
            "10598\n",
            "10599\n",
            "10600\n",
            "10601\n",
            "10602\n",
            "10603\n",
            "10604\n",
            "10605\n",
            "10606\n",
            "10607\n",
            "10608\n",
            "10609\n",
            "10610\n",
            "10611\n",
            "10612\n",
            "10613\n",
            "10614\n",
            "10615\n",
            "10616\n",
            "10617\n",
            "10618\n",
            "10619\n",
            "10620\n",
            "10621\n",
            "10622\n",
            "10623\n",
            "10624\n",
            "10625\n",
            "10626\n",
            "10627\n",
            "10628\n",
            "10629\n",
            "10630\n",
            "10631\n",
            "10632\n",
            "10633\n",
            "10634\n",
            "10635\n",
            "10636\n",
            "10637\n",
            "10638\n",
            "10639\n",
            "10640\n",
            "10641\n",
            "10642\n",
            "10643\n",
            "10644\n",
            "10645\n",
            "10646\n",
            "10647\n",
            "10648\n",
            "10649\n",
            "10650\n",
            "10651\n",
            "10652\n",
            "10653\n",
            "10654\n",
            "10655\n"
          ]
        }
      ],
      "source": [
        "Y = data[\"Sentiment\"]\n",
        "# data = data.drop(\"Sentiment\", axis=1, inplace=True)\n",
        "\n",
        "\n",
        "dataframe = data.copy()\n",
        "labels = tf.squeeze(tf.constant([dataframe.pop('Sentiment')]), axis=0)\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices((dataframe[\"OriginalTweet\"].values, labels))#.batch(len(data))\n",
        "\n",
        "# dataset = tf.data.Dataset.from_tensor_slices(data.values)\n",
        "train_size = int(0.75 * len(data))\n",
        "val_size = int(0.25 * len(data))\n",
        "\n",
        "\n",
        "# # full_dataset = tf.data.TFRecordDataset(FLAGS.input_file)\n",
        "full_dataset = ds.shuffle(buffer_size=len(data))\n",
        "train_dataset = full_dataset.take(train_size)\n",
        "# # test_dataset = dataset.skip(train_size)\n",
        "val_dataset = train_dataset.skip(val_size)\n",
        "# val_dataset = val_dataset.take(val_size)\n",
        "# # test_dataset = test_dataset.take(test_size)\n",
        "# # train_dataset, test_dataset = dataset.train_test_split(split_fraction=0.75)\n",
        "print(len(train_dataset))\n",
        "# print(train_feat)\n",
        "for idx in range(len(train_dataset)):\n",
        "    for i in train_dataset.take(idx):\n",
        "        print(idx)\n",
        "        train_feat = i[0].numpy()\n",
        "        train_lab = i[1].numpy()\n",
        "        break\n",
        "\n",
        "train = pd.DataFrame([train_feat, train_lab]).T\n",
        "train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
        "train['DATA_COLUMN'] = train['DATA_COLUMN'].str.decode(\"utf-8\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "gbmvOiwaxaw0",
        "outputId": "2032d808-5dd6-4327-9f22-3e96ff39c4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20578\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1bbda707-bba7-475c-959e-a71ce92fe124\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATA_COLUMN</th>\n",
              "      <th>LABEL_COLUMN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>score!! \\r\\r\\n\\r\\r\\ntoiletpaper toiletpapercri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bbda707-bba7-475c-959e-a71ce92fe124')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bbda707-bba7-475c-959e-a71ce92fe124 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bbda707-bba7-475c-959e-a71ce92fe124');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         DATA_COLUMN LABEL_COLUMN\n",
              "0  score!! \\r\\r\\n\\r\\r\\ntoiletpaper toiletpapercri...            0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(val_dataset))\n",
        "for idx in range(len(val_dataset)):\n",
        "  for j in val_dataset.take(idx):\n",
        "      val_feat = j[0].numpy()\n",
        "      val_lab = j[1].numpy()\n",
        "      break\n",
        "\n",
        "val = pd.DataFrame([val_feat, val_lab]).T\n",
        "val.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
        "val['DATA_COLUMN'] = val['DATA_COLUMN'].str.decode(\"utf-8\")\n",
        "val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-S3GUDOxttX"
      },
      "outputs": [],
      "source": [
        "# integer encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# label_encoder = LabelEncoder()\n",
        "\n",
        "def convert_data_to_examples(train, val, DATA_COLUMN, LABEL_COLUMN):\n",
        "  # integer_encoded = label_encoder.fit_transform(train[LABEL_COLUMN]) \n",
        "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[DATA_COLUMN], \n",
        "                                                          text_b = None,\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "  validation_InputExamples = val.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[DATA_COLUMN], \n",
        "                                                          text_b = None,\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
        "  print(train_InputExamples)\n",
        "  return train_InputExamples, validation_InputExamples\n",
        "\n",
        "# train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
        "#                                                                            val, \n",
        "#                                                                            'DATA_COLUMN', \n",
        "#                                                                            'LABEL_COLUMN')\n",
        "  \n",
        "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
        "    features = [] # -> will hold InputFeatures to be converted later\n",
        "\n",
        "    for e in examples:\n",
        "        # Documentation is really strong for this method, so please take a look at it\n",
        "        input_dict = tokenizer.encode_plus(\n",
        "            e.text_a,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length, # truncates if len(s) > max_length\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
        "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def gen():\n",
        "        for f in features:\n",
        "            yield (\n",
        "                {\n",
        "                    \"input_ids\": f.input_ids,\n",
        "                    \"attention_mask\": f.attention_mask,\n",
        "                    \"token_type_ids\": f.token_type_ids,\n",
        "                },\n",
        "                f.label,\n",
        "            )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "        (\n",
        "            {\n",
        "                \"input_ids\": tf.TensorShape([None]),\n",
        "                \"attention_mask\": tf.TensorShape([None]),\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\n",
        "            },\n",
        "            tf.TensorShape([]),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "DATA_COLUMN = 'DATA_COLUMN'\n",
        "LABEL_COLUMN = 'LABEL_COLUMN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M4Yf2kHyHMN",
        "outputId": "e2656b88-bae0-49c0-ecb3-6b5dcff34f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    InputExample(guid=None, text_a='so much about ...\n",
            "dtype: object\n",
            "<FlatMapDataset element_spec=({'input_ids': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, val, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "print(train_data)\n",
        "train_data = train_data.shuffle(100).batch(16).repeat(2)\n",
        "\n",
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
        "validation_data = validation_data.batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c8DcbRMJyQix",
        "outputId": "cdfb6bd8-bd96-491c-e1a3-81dab3d0aa4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, None, None), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, None, None), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, None, None), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-886e9f96a3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (1,) where an element of shape () was expected.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1048, in generator_py_func\n    f\"`generator` yielded an element of shape {ret_array.shape} \"\n\nTypeError: `generator` yielded an element of shape (1,) where an element of shape () was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_6]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (1,) where an element of shape () was expected.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1048, in generator_py_func\n    f\"`generator` yielded an element of shape {ret_array.shape} \"\n\nTypeError: `generator` yielded an element of shape (1,) where an element of shape () was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_87954660]"
          ]
        }
      ],
      "source": [
        "print(train_data.batch(16))\n",
        "model.trainable = True\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "\n",
        "model.fit(train_data, epochs=3, verbose = 1, validation_data=validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPKJdtho36Y8"
      },
      "outputs": [],
      "source": [
        "# tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
        "# tf_outputs = model(tf_batch)\n",
        "# tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
        "# labels = ['Negative','Positive']\n",
        "# label = tf.argmax(tf_predictions, axis=1)\n",
        "# label = label.numpy()\n",
        "# for i in range(len(pred_sentences)):\n",
        "#   print(pred_sentences[i], \": \\n\", labels[label[i]])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTx+xXPce6wQTmGxnv2qi+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a89b3ed0c15c4aa3af82f15902e1eb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b93941568a9845e1afcb9573e378a886",
              "IPY_MODEL_d9eb02e90852485eaeb1247ede433e63",
              "IPY_MODEL_5f1464887c534609b62210b5f69ce59e"
            ],
            "layout": "IPY_MODEL_65c3c13e452047c7b865d6857ff101a3"
          }
        },
        "b93941568a9845e1afcb9573e378a886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6445feabecef43b2bc9bdf3bb3390869",
            "placeholder": "​",
            "style": "IPY_MODEL_646f6aeb67f943cc81e1c95cd91b3e99",
            "value": "Downloading: 100%"
          }
        },
        "d9eb02e90852485eaeb1247ede433e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6a9a036879d4af787df77af6c9e43aa",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_795a4b0e9ec044c9af2873cbbb681e65",
            "value": 440473133
          }
        },
        "5f1464887c534609b62210b5f69ce59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4c02b97d36413d811f4fffc281c196",
            "placeholder": "​",
            "style": "IPY_MODEL_11fc3b7ea8594688a5b87ebb092a7521",
            "value": " 420M/420M [00:10&lt;00:00, 63.4MB/s]"
          }
        },
        "65c3c13e452047c7b865d6857ff101a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6445feabecef43b2bc9bdf3bb3390869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646f6aeb67f943cc81e1c95cd91b3e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6a9a036879d4af787df77af6c9e43aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795a4b0e9ec044c9af2873cbbb681e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f4c02b97d36413d811f4fffc281c196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11fc3b7ea8594688a5b87ebb092a7521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}